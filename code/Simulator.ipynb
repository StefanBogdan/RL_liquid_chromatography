{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from torch import optim, tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mayavi import mlab\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = pd.read_csv('../data/GilarSample.csv')\n",
    "# GilarSample\n",
    "# Peterpeptides\n",
    "# Roca\n",
    "# Peter32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(lr, iteration, num_episodes, steps=10, decay_factor=0.8):\n",
    "    if iteration % (num_episodes // steps) == 0:\n",
    "        return lr * decay_factor\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_field(exp, N = 200):\n",
    "    phis = np.linspace(0, 1, N)\n",
    "    losses = np.zeros((N, N))\n",
    "    j = 0\n",
    "    for phi1 in phis:\n",
    "        i = 0\n",
    "        for phi2 in phis:\n",
    "            exp.reset()\n",
    "            exp.run_all([phi1, phi2], [0.25, 3000000])\n",
    "            losses[i, j] = exp.loss()\n",
    "            i += 1\n",
    "        j += 1\n",
    "    X, Y = np.meshgrid(phis, phis)\n",
    "    \n",
    "    return X, Y, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=10.0)\n",
    "pol = Policy(2, sigma_max = 0.2)\n",
    "taus = [.25, 3000000]\n",
    "losses, best_program, mus, sigmas, n_pars, samples, mu_grads, sigma_grads = reinforce(\n",
    "        exp, \n",
    "        pol, \n",
    "        taus, \n",
    "        num_episodes=3000, \n",
    "        batch_size=10,\n",
    "        optim=lambda a, b: torch.optim.SGD(a, b, momentum=0.65),\n",
    "        lr=.1, \n",
    "        print_every=100,\n",
    "        lr_decay=lambda a, b, c: step_decay(a, b, c, steps=4, decay_factor=0.5),\n",
    "        baseline=0.55,\n",
    "        max_norm = 1.,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.reset()\n",
    "exp.run_all(pol.mu.detach().numpy(), taus)\n",
    "exp.print_analytes(rc=(7, 5))\n",
    "exp.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus[:, 0], label='Mu: phi1')\n",
    "plt.plot(mus[:, 1], label='Mu: phi2')\n",
    "#plt.plot(mus[:, 2], label='Mu: phi3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas[:, 0], label='Sigma: phi1')\n",
    "plt.plot(sigmas[:, 1], label='Sigma: phi2')\n",
    "#plt.plot(sigmas[:, 2], label='Sigma: phi3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.reset()\n",
    "exp.run_all(best_program.numpy(), taus)\n",
    "exp.print_analytes(rc=(7, 5), title=\"Best Result\")\n",
    "exp.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Loss_field = loss_field(exp, N = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.contourf(X, Y, Loss_field, levels=100)\n",
    "plt.colorbar()\n",
    "\n",
    "line, = plt.plot(mus[:, 0], mus[:, 1], color='k')\n",
    "scat = plt.scatter(samples[:, 0], samples[:, 1], c='r', s=3)\n",
    "\n",
    "def update(num, mu, samples, line, scat):\n",
    "    line.set_data(mu[num-2:num, 0], mu[num-2:num, 1])\n",
    "    line.axes.axis([0, 1, 0, 1])\n",
    "    scat.set_offsets(samples[(num-2)*10: num*10 - 10, :])\n",
    "    return line,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, len(mus[:, 0]), fargs=[mus, samples, line, scat],\n",
    "                              interval=10, blit=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossess = []\n",
    "for phi in np.linspace(0,.4, 500):\n",
    "    exp.reset()\n",
    "    exp.run_all([phi, 0.368], [.25, 3000])\n",
    "    lossess.append(exp.loss())\n",
    "plt.plot(np.linspace(0,.4, 500), lossess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, 1)\n",
    "plt.xlabel(\"phi1\")\n",
    "\n",
    "plt.ylabel(\"phi2\")\n",
    "plt.contourf(X, Y, Loss_field, levels=100)\n",
    "plt.colorbar()\n",
    "\n",
    "n = 1998\n",
    "patch = patches.Arrow(mus[n, 0], mus[n, 1], mu_grads[n, 0], mu_grads[n, 1], width=0.02, color='k')\n",
    "ax.add_patch(patch)\n",
    "plt.scatter(samples[n*10:n*10+10, 0], samples[n*10:n*10+10:, 1], c='r', s=5, label='Samples')\n",
    "plt.scatter(mus[n, 0], mus[n, 1], c='b', s=20, label='current mu')\n",
    "plt.scatter(mus[n + 1, 0], mus[n + 1, 1], c='w', s=20, label='next mu')\n",
    "plt.title(f\"sigmas:{sigmas[n,:]}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, 1)\n",
    "plt.contourf(X, Y, Loss_field, levels=100)\n",
    "plt.colorbar()\n",
    "\n",
    "patch = patches.Arrow(mus[0, 0], mus[0, 1], mu_grads[0, 0], mu_grads[0, 1], width=0.02, color='k')\n",
    "scat1 = plt.scatter(samples[:, 0], samples[:, 1], c='r', s=5)\n",
    "scat2 = plt.scatter(mus[:, 0], mus[:, 1], c='b', s=20)\n",
    "def init():\n",
    "    ax.add_patch(patch)\n",
    "    return patch,\n",
    "\n",
    "def update(num, mu, samples, scat1, scat2, ax):\n",
    "    ax.patches.pop(0)\n",
    "    patch = patches.Arrow(mus[num-2, 0], mus[num-2, 1], mu_grads[num-2, 0], mu_grads[num-2, 1], width=0.01, color='k')\n",
    "    ax.add_patch(patch)\n",
    "    scat1.set_offsets(samples[(num-2)*10: num*10, :])\n",
    "    scat2.set_offsets(mu[num-2: num, :])\n",
    "    return scat1,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, len(mus[:, 0]), fargs=[mus, samples, scat1, scat2, ax],\n",
    "                              interval=10000, blit=False, init_func=init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = -1\n",
    "mlab.surf(X.T[:N, :N], Y.T[:N, :N], Loss_field.T[:N, :N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "plt.contourf(X, Y, Loss_field, levels=100)\n",
    "plt.scatter(samples[n*10:10+10*n ,0], samples[n*10:10+10*n,1], s=1.,c='r')\n",
    "plt.arrow(mus[n,0], mus[n,1], mu_grads[n,0], mu_grads[n,1], length_includes_head=True, head_width=0.04, head_length=0.2)\n",
    "plt.scatter(mus[n:n+2, 0], mus[n:n+2, 1])\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = np.linspace(0, 1, 1000)\n",
    "losses = []\n",
    "for phi1 in phis:\n",
    "    exp.reset()\n",
    "    exp.run_all([0.2, phi1], [0.25, 3000000])\n",
    "    losses.append(exp.loss())\n",
    "plt.plot(losses[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(X, Y, Loss_field, levels=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_time = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=None)\n",
    "pol_time = PolicyTime(2, sigma_max = .2)\n",
    "losses_time, best_program_time, mus_time, sigmas_time, n_par_time = reinforce_delta_tau(\n",
    "        exp_time, \n",
    "        pol_time,\n",
    "        num_episodes=5000, \n",
    "        batch_size=10,\n",
    "        optim=torch.optim.SGD,\n",
    "        lr=.1, \n",
    "        print_every=100,\n",
    "        lr_decay=lambda a, b, c: step_decay(a, b, c, steps=5, decay_factor=0.65),\n",
    "        baseline=0.7,\n",
    "        max_norm=1.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_time.reset()\n",
    "exp_time.run_all(pol_time.mu.detach().numpy()[:2], [0.25, 3000000])\n",
    "exp_time.print_analytes(rc=(7, 5))\n",
    "exp_time.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_time.reset()\n",
    "exp_time.run_all(best_program_time[0], best_program_time[1])\n",
    "exp_time.print_analytes(rc=(7, 5))\n",
    "exp_time.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus_time[:, 0], label='Mu: 0')\n",
    "plt.plot(mus_time[:, 1], label='Mu: 1')\n",
    "plt.plot(mus_time[:, 2], label='Mu: 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas_time[:, 0], label='Sigma: 0')\n",
    "plt.plot(sigmas_time[:, 1], label='Sigma: 1')\n",
    "plt.plot(sigmas_time[:, 2], label='Sigma: 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=10.0)\n",
    "results = []\n",
    "positions = []\n",
    "taus = [.25, 3000000]\n",
    "for n in range(300):\n",
    "\n",
    "    pol = Policy(2, sigma_max = 0.2)\n",
    "\n",
    "    losses, best_program, mus, sigmas, n_pars, samples, mu_grads, sigma_grads = reinforce(\n",
    "            exp, \n",
    "            pol, \n",
    "            taus, \n",
    "            num_episodes=3000, \n",
    "            batch_size=10,\n",
    "            optim=lambda a, b: torch.optim.SGD(a, b, momentum=0.65),\n",
    "            lr=.1, \n",
    "            print_every=2999,\n",
    "            lr_decay=lambda a, b, c: step_decay(a, b, c, steps=4, decay_factor=0.5),\n",
    "            baseline=0.55,\n",
    "            max_norm = 1.,\n",
    "            #beta = 0.1\n",
    "        )\n",
    "    exp.reset()\n",
    "    exp.run_all(pol.mu.detach().numpy(), taus)\n",
    "    results.append(exp.loss())\n",
    "    positions.append(pol.mu.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results, bins=100)\n",
    "plt.title(\"Peter32, global min: 0.47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=10.0)\n",
    "pol = Policy(2, sigma_max = 0.2)\n",
    "taus = [.25, 3000000]\n",
    "base_dic = {}\n",
    "for base in np.linspace(-1.5, 1.5, 20):\n",
    "    r = 0\n",
    "    for n in range(10):\n",
    "        pol = Policy(2, sigma_max = 0.2)\n",
    "\n",
    "        losses, best_program, mus, sigmas, n_pars, samples, mu_grads, sigma_grads = reinforce(\n",
    "                exp, \n",
    "                pol, \n",
    "                taus, \n",
    "                num_episodes=3000, \n",
    "                batch_size=10,\n",
    "                optim=lambda a, b: torch.optim.SGD(a, b, momentum=0.9),\n",
    "                lr=.1, \n",
    "                print_every=2999,\n",
    "                lr_decay=lambda a, b, c: step_decay(a, b, c, steps=4, decay_factor=0.5),\n",
    "                baseline=base,\n",
    "                max_norm = 1.,\n",
    "                #beta = 0.1\n",
    "            )\n",
    "        exp.reset()\n",
    "        exp.run_all(pol.mu.detach().numpy(), taus)\n",
    "        r += exp.loss()\n",
    "    base_dic[base] = r/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=10.0)\n",
    "pol = Policy(2, sigma_max = 0.2)\n",
    "taus = [.25, 3000000]\n",
    "mom_dic = {}\n",
    "for base in np.linspace(0., 1., 100):\n",
    "    r = 0\n",
    "    for n in range(10):\n",
    "        pol = Policy(2, sigma_max = 0.2)\n",
    "\n",
    "        losses, best_program, mus, sigmas, n_pars, samples, mu_grads, sigma_grads = reinforce(\n",
    "                exp, \n",
    "                pol, \n",
    "                taus, \n",
    "                num_episodes=3000, \n",
    "                batch_size=10,\n",
    "                optim=lambda a, b: torch.optim.SGD(a, b, momentum=base),\n",
    "                lr=.1, \n",
    "                print_every=2999,\n",
    "                lr_decay=lambda a, b, c: step_decay(a, b, c, steps=4, decay_factor=0.5),\n",
    "                baseline=0.4,\n",
    "                max_norm = 1.,\n",
    "                #beta = 0.1\n",
    "            )\n",
    "        exp.reset()\n",
    "        exp.run_all(pol.mu.detach().numpy(), taus)\n",
    "        r += exp.loss()\n",
    "    mom_dic[base] = r/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Loss: 0.2852055336550113, epoch: 2999/3000\n",
      "Loss: 0.29259608188942104, epoch: 2999/3000\n",
      "Loss: 0.2893002022962836, epoch: 2999/3000\n",
      "Loss: 0.28906887897076083, epoch: 2999/3000\n",
      "Loss: 0.2894069957821531, epoch: 2999/3000\n",
      "Loss: 0.2843167524690778, epoch: 2999/3000\n",
      "Loss: 0.2865874671017776, epoch: 2999/3000\n",
      "Loss: 0.2840773413255688, epoch: 2999/3000\n",
      "Loss: 0.29015899198121703, epoch: 2999/3000\n",
      "Loss: 0.28713279057034974, epoch: 2999/3000\n",
      "2\n",
      "Loss: 0.2433500697652752, epoch: 2999/3000\n",
      "Loss: 0.24903077534566945, epoch: 2999/3000\n",
      "Loss: 0.2711005110970969, epoch: 2999/3000\n",
      "Loss: 0.25013398978828527, epoch: 2999/3000\n",
      "Loss: 0.26025238391956046, epoch: 2999/3000\n",
      "Loss: 0.2565933474897162, epoch: 2999/3000\n",
      "Loss: 0.23794384122699097, epoch: 2999/3000\n",
      "Loss: 0.24669296356669432, epoch: 2999/3000\n",
      "Loss: 0.23965576992751417, epoch: 2999/3000\n",
      "Loss: 0.2584717639659456, epoch: 2999/3000\n",
      "3\n",
      "Loss: 0.20000671685279095, epoch: 2999/3000\n",
      "Loss: 0.20389882824285363, epoch: 2999/3000\n",
      "Loss: 0.19543189137277864, epoch: 2999/3000\n",
      "Loss: 0.19903803464521758, epoch: 2999/3000\n",
      "Loss: 0.19751696602010924, epoch: 2999/3000\n",
      "Loss: 0.1734529529394146, epoch: 2999/3000\n",
      "Loss: 0.19935543890060295, epoch: 2999/3000\n",
      "Loss: 0.1932448445977735, epoch: 2999/3000\n",
      "Loss: 0.20235966642121705, epoch: 2999/3000\n",
      "Loss: 0.20292771112945013, epoch: 2999/3000\n",
      "4\n",
      "Loss: 0.15424164600127652, epoch: 2999/3000\n",
      "Loss: 0.17479937596256526, epoch: 2999/3000\n",
      "Loss: 0.15589396775043324, epoch: 2999/3000\n",
      "Loss: 0.1774531595614567, epoch: 2999/3000\n",
      "Loss: 0.15807714686849644, epoch: 2999/3000\n",
      "Loss: 0.1711847126677106, epoch: 2999/3000\n",
      "Loss: 0.14573764049494456, epoch: 2999/3000\n",
      "Loss: 0.15214791204980413, epoch: 2999/3000\n",
      "Loss: 0.13616016878581721, epoch: 2999/3000\n",
      "Loss: 0.1586018294667838, epoch: 2999/3000\n",
      "5\n",
      "Loss: 0.1726580564086256, epoch: 2999/3000\n",
      "Loss: 0.13626448741444377, epoch: 2999/3000\n",
      "Loss: 0.14182456248883743, epoch: 2999/3000\n",
      "Loss: 0.15546016999993278, epoch: 2999/3000\n",
      "Loss: 0.14751920564144883, epoch: 2999/3000\n",
      "Loss: 0.15901053085616668, epoch: 2999/3000\n",
      "Loss: 0.14431765903850802, epoch: 2999/3000\n",
      "Loss: 0.19198705535329735, epoch: 2999/3000\n",
      "Loss: 0.14289529407996196, epoch: 2999/3000\n",
      "Loss: 0.16340265503129622, epoch: 2999/3000\n",
      "6\n",
      "Loss: 0.15612431915530506, epoch: 2999/3000\n",
      "Loss: 0.15873372713820552, epoch: 2999/3000\n",
      "Loss: 0.14657228150323207, epoch: 2999/3000\n",
      "Loss: 0.15799331839827194, epoch: 2999/3000\n",
      "Loss: 0.15704868633072183, epoch: 2999/3000\n",
      "Loss: 0.17446652762218678, epoch: 2999/3000\n",
      "Loss: 0.1855790138447823, epoch: 2999/3000\n",
      "Loss: 0.17419459752444807, epoch: 2999/3000\n",
      "Loss: 0.17340706334649095, epoch: 2999/3000\n",
      "Loss: 0.16094252555191968, epoch: 2999/3000\n",
      "7\n",
      "Loss: 0.18654433425540562, epoch: 2999/3000\n",
      "Loss: 0.16303411658993755, epoch: 2999/3000\n",
      "Loss: 0.16142315299943488, epoch: 2999/3000\n",
      "Loss: 0.16841318481136885, epoch: 2999/3000\n",
      "Loss: 0.18006337750390256, epoch: 2999/3000\n",
      "Loss: 0.16068972890885536, epoch: 2999/3000\n",
      "Loss: 0.17313696716756144, epoch: 2999/3000\n",
      "Loss: 0.14606245494153977, epoch: 2999/3000\n",
      "Loss: 0.14610405260873577, epoch: 2999/3000\n",
      "Loss: 0.1722356326353743, epoch: 2999/3000\n",
      "8\n",
      "Loss: 0.1554020307229736, epoch: 2999/3000\n",
      "Loss: 0.16029286098420148, epoch: 2999/3000\n",
      "Loss: 0.16162209967423438, epoch: 2999/3000\n",
      "Loss: 0.18763264383544329, epoch: 2999/3000\n",
      "Loss: 0.11099268630194613, epoch: 2999/3000\n",
      "Loss: 0.1165537320082084, epoch: 2999/3000\n",
      "Loss: 0.14944571754249777, epoch: 2999/3000\n",
      "Loss: 0.14873517414660048, epoch: 2999/3000\n",
      "Loss: 0.17058500620273676, epoch: 2999/3000\n",
      "Loss: 0.1742042533376104, epoch: 2999/3000\n",
      "9\n",
      "Loss: 0.16036697251657375, epoch: 2999/3000\n",
      "Loss: 0.17573846595861706, epoch: 2999/3000\n",
      "Loss: 0.19500436630831772, epoch: 2999/3000\n",
      "Loss: 0.16414353699899126, epoch: 2999/3000\n",
      "Loss: 0.16485373182235197, epoch: 2999/3000\n",
      "Loss: 0.14398694994407255, epoch: 2999/3000\n",
      "Loss: 0.20062094752953996, epoch: 2999/3000\n",
      "Loss: 0.16902380639778924, epoch: 2999/3000\n",
      "Loss: 0.1656776496444165, epoch: 2999/3000\n",
      "Loss: 0.16894473182080175, epoch: 2999/3000\n",
      "10\n",
      "Loss: 0.17739477647349236, epoch: 2999/3000\n",
      "Loss: 0.1701721696437133, epoch: 2999/3000\n",
      "Loss: 0.17500305289837162, epoch: 2999/3000\n",
      "Loss: 0.15346822883330813, epoch: 2999/3000\n",
      "Loss: 0.14341578128510052, epoch: 2999/3000\n",
      "Loss: 0.14239142524252205, epoch: 2999/3000\n",
      "Loss: 0.17422579255191975, epoch: 2999/3000\n",
      "Loss: 0.1518273491687868, epoch: 2999/3000\n",
      "Loss: 0.15833199462237948, epoch: 2999/3000\n",
      "Loss: 0.16019194856334626, epoch: 2999/3000\n"
     ]
    }
   ],
   "source": [
    "exp = ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, grad='iso', run_time=10.0)\n",
    "results_n = []\n",
    "for n in range(1,11):\n",
    "    taus = np.ones(n) * 1/n\n",
    "    result = []\n",
    "    print(n)\n",
    "    for i in range(10):\n",
    "        pol = Policy(n, sigma_max = 0.2)\n",
    "        \n",
    "        reinforce(\n",
    "                exp, \n",
    "                pol, \n",
    "                taus, \n",
    "                num_episodes=3000, \n",
    "                batch_size=10,\n",
    "                optim=lambda a, b: torch.optim.SGD(a, b, momentum=0.65),\n",
    "                lr=.1, \n",
    "                print_every=2999,\n",
    "                lr_decay=lambda a, b, c: step_decay(a, b, c, steps=4, decay_factor=0.5),\n",
    "                baseline=0.55,\n",
    "                max_norm = 1.,\n",
    "                #beta = 0.1\n",
    "            )\n",
    "        exp.reset()\n",
    "        if n == 1:\n",
    "            exp.run_all([pol.mu.detach().tolist()], taus)\n",
    "        else:\n",
    "            exp.run_all(pol.mu.detach().numpy(), taus)\n",
    "        result.append(exp.loss())\n",
    "    results_n.append(result)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Expected loss')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(range(1, 11), np.array(results_n).mean(axis=1))\n",
    "plt.title(\"Expected loss vs Number of paramaters(GilarSample)\")\n",
    "plt.xlabel(\"N\")\n",
    "plt.ylabel(\"Expected loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
