{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from separation_utility import *\n",
    "from torch import optim, tensor, Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mayavi import mlab\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alists = []\n",
    "alists.append(pd.read_csv(f'../data/GilarSample.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Roca.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Controlmix2.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_field(exp, taus, N = 200):\n",
    "    phis = np.linspace(0, 1, N)\n",
    "    losses = np.zeros((N, N))\n",
    "    j = 0\n",
    "    for phi1 in phis:\n",
    "        i = 0\n",
    "        for phi2 in phis:\n",
    "            exp.reset()\n",
    "            exp.run_all([phi1, phi2], taus)\n",
    "            losses[i, j] = exp.loss()\n",
    "            i += 1\n",
    "        j += 1\n",
    "    X, Y = np.meshgrid(phis, phis)\n",
    "    \n",
    "    return X, Y, losses\n",
    "\n",
    "def average_over_equal_intervals(arr, interval):\n",
    "    return np.mean(arr.reshape(-1, interval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.5827106322805464, epoch: 1000/200000\n"
     ]
    }
   ],
   "source": [
    "taus = [.25, .25, 10]\n",
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 100),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(100, 100),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(100, 30),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(30, 60),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(60, 120),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(taus), hidden=100, in_dim=120, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "losses = reinforce_gen(\n",
    "    alists = alists, \n",
    "    policy = pol, \n",
    "    delta_taus = taus, \n",
    "    num_episodes = 200000, \n",
    "    batch_size = 10, \n",
    "    lr = .05, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b, momentum=0.65),\n",
    "    lr_decay_factor= 0.5,\n",
    "    lr_milestones=1000,\n",
    "    print_every = 1000,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.7,\n",
    "    max_rand_analytes = 30,\n",
    "    min_rand_analytes = 10,\n",
    "    rand_prob = 0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 200000, 2000),average_over_equal_intervals(losses[0], 100))\n",
    "plt.title(\"Loss (average of 500 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, sig = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "exp.run_all(mu.detach().numpy(), taus)\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Gen)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_gen(\n",
    "        alist=alists[i], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=3000, \n",
    "        batch_size=10, \n",
    "        lr=.1, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=500,\n",
    "        print_every=500,\n",
    "        baseline=0.65,\n",
    "        max_norm=1.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(mus[-1,:], taus)\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Iso)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(B, taus)\n",
    "exp.print_analytes(title=f\"Best Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = RhoTime(n_steps=3, hidden=5, in_dim=3, sigma_max=.3, sigma_min=.02)\n",
    "        )\n",
    "losses = reinforce_delta_tau_gen(\n",
    "    alists = alists, \n",
    "    policy = pol,\n",
    "    num_episodes = 10000, \n",
    "    batch_size = 10, \n",
    "    lr = .1, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "    lr_decay_factor= 0.75,\n",
    "    lr_milestones=1000,\n",
    "    print_every = 100,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.2,\n",
    "    max_rand_analytes = 35,\n",
    "    min_rand_analytes = 18,\n",
    "    rand_prob = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 200000, 200),average_over_equal_intervals(losses[0], 1000))\n",
    "plt.title(\"Loss [variable delta tau] (average of 1000 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, _ = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "mu = mu.tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_delta_tau_gen(\n",
    "        alist=alists[i], \n",
    "        policy=pol,\n",
    "        num_episodes=5000, \n",
    "        batch_size=10, \n",
    "        lr=.1, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=500,\n",
    "        print_every=500,\n",
    "        baseline=0.65,\n",
    "        max_norm=1.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu = mus[-1].tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
