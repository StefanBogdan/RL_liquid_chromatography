{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from separation_utility import *\n",
    "import torch\n",
    "from torch import optim, tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alists = []\n",
    "alists.append(pd.read_csv('../data/GilarSample.csv'))\n",
    "alists.append(pd.read_csv('../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv('../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv('../data/Roca.csv'))\n",
    "alists.append(pd.read_csv('../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv('../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv('../data/Controlmix2.csv'))\n",
    "alists.append(pd.read_csv('../data/Gooding.csv'))\n",
    "# GilarSample - 8 analytes\n",
    "# Peterpeptides - 32 analytes\n",
    "# Roca - 14 analytes\n",
    "# Peter32 - 32 analytes\n",
    "# Eosin - 20 analytes\n",
    "# Alizarin - 16 analytes\n",
    "# Controlmix2 - 17 analytes\n",
    "# Gooding - 872 analytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Performance vs n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/Thesis/code/chromatography.py:276: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return delta_tau_phi * (1 + self.k(phi)) / self.k(phi)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2c14cd2017e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpol_50_50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mdelta_taus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_taus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m         loss_100, _ = reinforce_gen(\n",
      "\u001b[0;32m~/Thesis/code/separation_utility.py\u001b[0m in \u001b[0;36mreinforce_gen\u001b[0;34m(policy, delta_taus, alists, random_alist, test_alist, num_episodes, sample_size, batch_size, lr, optim, lr_decay_factor, lr_milestones, rand_prob, max_rand_analytes, min_rand_analytes, print_every, baseline, max_norm, beta, weights, h, run_time)\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstr_programs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_taus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m             \u001b[0mexpected_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mlog_prob_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Thesis/code/chromatography.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    450\u001b[0m         return (\n\u001b[1;32m    451\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mplacement_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meven_space_positions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moverlap_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         )\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Thesis/code/chromatography.py\u001b[0m in \u001b[0;36moverlap_error\u001b[0;34m(mu, sigma)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     overlap_area += (\n\u001b[0;32m--> 120\u001b[0;31m         (1.0 - (np.fabs(cdf(x1, mu_2, sigma_2) - cdf(x1, mu_1, sigma_1))\\\n\u001b[0m\u001b[1;32m    121\u001b[0m         + np.fabs(cdf(x2, mu_2, sigma_2) - cdf(x2, mu_1, sigma_1)))).sum()\n\u001b[1;32m    122\u001b[0m     )\n",
      "\u001b[0;32m~/Thesis/code/chromatography.py\u001b[0m in \u001b[0;36mcdf\u001b[0;34m(x, mu, sigma)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 7\n",
    "M = 15\n",
    "\n",
    "losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "losses_100 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "for n in range(0, N):\n",
    "    print(n)\n",
    "    delta_taus = np.ones(n + 1) * 1/(n + 1)\n",
    "    \n",
    "    for i in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {i}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        pol_100 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            random_alist = alist_train, \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "        loss_100, _ = reinforce_gen(\n",
    "            random_alist = all_analytes, \n",
    "            test_alist = None,\n",
    "            policy = pol_100, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        losses_50_50[n,i] = loss\n",
    "        test_losses_50_50[n,i] = loss_test\n",
    "        losses_100[n,i] = loss_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez_compressed(\"../results/general_perf_vs_n_steps\", losses_50_50=losses_50_50, test_losses_50_50=test_losses_50_50, losses_100=losses_100)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_losses_50\", losses_50_50=losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_test_losses_50_50\", test_losses_50_50=test_losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_losses_100\", losses_100=losses_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs number of analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 5\n",
    "M = 30\n",
    "\n",
    "losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "losses_100 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for n in range(N):\n",
    "    for i in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {i}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        pol_100 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus,\n",
    "            min_rand_analytes = 8 * (n + 1),\n",
    "            max_rand_analytes = 8 * (n + 1),\n",
    "            **kwargs\n",
    "        )\n",
    "        loss_100, _ = reinforce_gen(\n",
    "            alists = [all_analytes], \n",
    "            test_alist = None,\n",
    "            policy = pol_100, \n",
    "            delta_taus = delta_taus,\n",
    "            min_rand_analytes = 8 * (n + 1),\n",
    "            max_rand_analytes = 8 * (n + 1),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_50_50[n,i] = loss\n",
    "        test_losses_50_50[n,i] = loss_test\n",
    "        losses_100[n,i] = loss_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_losses_50\", losses_50_50=losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_test_losses_50_50\", test_losses_50_50=test_losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_losses_100\", losses_100=losses_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs architecture DeepSet(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "activations = [nn.ELU, nn.ReLU, nn.Tanh]\n",
    "width = [5, 10, 20]\n",
    "kwargs = {\n",
    "    'num_episodes' : 1, #25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 9\n",
    "M = 20\n",
    "\n",
    "losses_deep_set = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_deep_set = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for i in range(N):\n",
    "    print(f\"{i}\")\n",
    "    for m in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {m}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                PermEqui2_max(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                PermEqui2_max(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(width[i % 3], 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_deep_set[i, m] = loss\n",
    "        test_losses_deep_set[i, m] = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_deep_set_arch_loss_50_50\", losses_50_50=losses_deep_set)\n",
    "np.savez_compressed(\"../results/general_perf_deep_set_arch_test_losses_50_50\", test_losses_50_50=test_losses_deep_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs architecture Program(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoReLU(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = F.relu(self.fc_mu_1(x))\n",
    "        sigma = F.relu(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoELU(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = F.elu(self.fc_mu_1(x))\n",
    "        sigma = F.elu(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoTanh(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = torch.tanh(self.fc_mu_1(x))\n",
    "        sigma = torch.tanh(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "activations = [nn.ELU, nn.ReLU, nn.Tanh]\n",
    "width = [5, 10, 20]\n",
    "Rhos = [RhoELU, RhoReLU, RhoTanh]\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 9\n",
    "M = 20\n",
    "\n",
    "losses_rho = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_rho = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for i in range(N):\n",
    "    print(f\"{i}\")\n",
    "    for m in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {m}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                nn.Linear(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                Rhos[i // 3](n_steps=len(delta_taus), hidden=width[i % 3], in_dim=width[i % 3], sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_rho[i, m] = loss\n",
    "        test_losses_rho[i, m] = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_rho_arch_loss_50_50\", losses_50_50=losses_rho)\n",
    "np.savez_compressed(\"../results/general_perf_rho_arch_test_losses_50_50\", test_losses_50_50=test_losses_rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of results + Fine Tuning (not in training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-137844995d9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_analytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lnk0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m kwargs = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'num_episodes'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m25_000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists[3:], sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "kwargs_ft = {\n",
    "    'num_episodes' : 6000, \n",
    "    'sample_size':  10, \n",
    "    'lr': .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor': .75,\n",
    "    'lr_milestones':  1000,\n",
    "    'print_every':  6001,\n",
    "    'baseline': 0.55,\n",
    "    'max_norm': 1.5,\n",
    "    'beta': .0,\n",
    "    'weights': [1., 1.],\n",
    "    'h': .001,\n",
    "    'run_time' : 1.  \n",
    "}\n",
    "N = 300\n",
    "\n",
    "# Experiments\n",
    "exp_8 = ExperimentAnalytes(k0 = alists[0].k0.values, S = alists[0].S.values, h=0.001, run_time=1.0)\n",
    "exp_16 = ExperimentAnalytes(k0 = alists[1].k0.values, S = alists[1].S.values, h=0.001, run_time=1.0)\n",
    "exp_32 = ExperimentAnalytes(k0 = alists[2].k0.values, S = alists[2].S.values, h=0.001, run_time=1.0)\n",
    "# Final Results \n",
    "dist_8 = np.zeros((N,))\n",
    "dist_16 = np.zeros((N,))\n",
    "dist_32 = np.zeros((N,))\n",
    "dist_ft_8 = np.zeros((N,))\n",
    "dist_ft_16 = np.zeros((N,))\n",
    "dist_ft_32 = np.zeros((N,))\n",
    "\n",
    "for n in range(0, N):\n",
    "    delta_taus = np.ones(10) * 1/(10)\n",
    "    print(f\"{n}\")\n",
    "    #Policies\n",
    "    pol = PolicyGeneral(\n",
    "        phi = nn.Sequential(\n",
    "            PermEqui2_max(2, 5),\n",
    "            nn.Tanh(),\n",
    "            PermEqui2_max(5, 5),\n",
    "            nn.Tanh(),\n",
    "            PermEqui2_max(5, 5),\n",
    "            nn.Tanh(),\n",
    "        ),\n",
    "        rho = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Tanh(),\n",
    "            Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01, non_linearity=torch.tanh),\n",
    "        )\n",
    "    )\n",
    "    # Run Exp\n",
    "    reinforce_gen(\n",
    "        alists = [], \n",
    "        random_alist = all_analytes,\n",
    "        test_alist = None,\n",
    "        policy = pol, \n",
    "        delta_taus = delta_taus, \n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    mu_8, _ = pol.forward(torch.tensor(alists[0][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    mu_16, _ = pol.forward(torch.tensor(alists[1][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    mu_32, _ = pol.forward(torch.tensor(alists[2][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    exp_8.reset()\n",
    "    exp_16.reset()\n",
    "    exp_32.reset()\n",
    "    \n",
    "    exp_8.run_all(mu_8.tolist(), delta_taus)\n",
    "    exp_16.run_all(mu_16.tolist(), delta_taus)\n",
    "    exp_32.run_all(mu_32.tolist(), delta_taus)\n",
    "    dist_8[n] = exp_8.loss()\n",
    "    dist_16[n] = exp_16.loss()\n",
    "    dist_32[n] = exp_32.loss()\n",
    "    \n",
    "    _,_,mu_8,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[0], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    _,_,mu_16,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[1], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    _,_,mu_32,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[2], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    exp_8.reset()\n",
    "    exp_8.run_all(mu_8[-1], delta_taus)\n",
    "    exp_16.reset()\n",
    "    exp_16.run_all(mu_16[-1], delta_taus)\n",
    "    exp_32.reset()\n",
    "    exp_32.run_all(mu_32[-1], delta_taus)\n",
    "    \n",
    "    dist_ft_8[n] = exp_8.loss()\n",
    "    dist_ft_16[n] = exp_16.loss()\n",
    "    dist_ft_32[n] = exp_32.loss()\n",
    "\n",
    "(\n",
    "    np.savez_compressed(\n",
    "        \"../results/general_dist_not_in_train\", \n",
    "        dist_8=dist_8, \n",
    "        dist_16=dist_16, \n",
    "        dist_32=dist_32, \n",
    "        dist_ft_8=dist_ft_8, \n",
    "        dist_ft_16=dist_ft_16, \n",
    "        dist_ft_32=dist_ft_32, \n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of results + Fine Tuning (in training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : .8,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "kwargs_ft = {\n",
    "    'num_episodes' : 6000, \n",
    "    'sample_size':  10, \n",
    "    'lr': .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor': .75,\n",
    "    'lr_milestones':  1000,\n",
    "    'print_every':  6001,\n",
    "    'baseline': 0.55,\n",
    "    'max_norm': 1.5,\n",
    "    'beta': .0,\n",
    "    'weights': [1., 1.],\n",
    "    'h': .001,\n",
    "    'run_time' : 1.  \n",
    "}\n",
    "N = 300\n",
    "\n",
    "# Experiments\n",
    "exp_8 = ExperimentAnalytes(k0 = alists[0].k0.values, S = alists[0].S.values, h=0.001, run_time=1.0)\n",
    "exp_16 = ExperimentAnalytes(k0 = alists[1].k0.values, S = alists[1].S.values, h=0.001, run_time=1.0)\n",
    "exp_32 = ExperimentAnalytes(k0 = alists[2].k0.values, S = alists[2].S.values, h=0.001, run_time=1.0)\n",
    "# Final Results \n",
    "dist_8 = np.zeros((N,))\n",
    "dist_16 = np.zeros((N,))\n",
    "dist_32 = np.zeros((N,))\n",
    "dist_ft_8 = np.zeros((N,))\n",
    "dist_ft_16 = np.zeros((N,))\n",
    "dist_ft_32 = np.zeros((N,))\n",
    "\n",
    "for n in range(0, N):\n",
    "    delta_taus = np.ones(10) * 1/(10)\n",
    "    print(f\"{n}\")\n",
    "    #Policies\n",
    "    pol = PolicyGeneral(\n",
    "        phi = nn.Sequential(\n",
    "            PermEqui2_max(2, 5),\n",
    "            nn.Tanh(),\n",
    "            PermEqui2_max(5, 5),\n",
    "            nn.Tanh(),\n",
    "            PermEqui2_max(5, 5),\n",
    "            nn.Tanh(),\n",
    "        ),\n",
    "        rho = nn.Sequential(\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.Tanh(),\n",
    "            Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01, non_linearity=torch.tanh),\n",
    "        )\n",
    "    )\n",
    "    # Run Exp\n",
    "    reinforce_gen(\n",
    "        alists = alists[0:3], \n",
    "        random_alist = all_analytes,\n",
    "        test_alist = None,\n",
    "        policy = pol, \n",
    "        delta_taus = delta_taus, \n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    mu_8, _ = pol.forward(torch.tensor(alists[0][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    mu_16, _ = pol.forward(torch.tensor(alists[1][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    mu_32, _ = pol.forward(torch.tensor(alists[2][['S', 'lnk0']].values, dtype=torch.float32))\n",
    "    exp_8.reset()\n",
    "    exp_16.reset()\n",
    "    exp_32.reset()\n",
    "    \n",
    "    exp_8.run_all(mu_8.tolist(), delta_taus)\n",
    "    exp_16.run_all(mu_16.tolist(), delta_taus)\n",
    "    exp_32.run_all(mu_32.tolist(), delta_taus)\n",
    "    dist_8[n] = exp_8.loss()\n",
    "    dist_16[n] = exp_16.loss()\n",
    "    dist_32[n] = exp_32.loss()\n",
    "    \n",
    "        \n",
    "    _,_,mu_8,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[0], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    _,_,mu_16,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[1], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    _,_,mu_32,_,_ = reinforce_single_from_gen(\n",
    "        alist = alists[2], \n",
    "        policy= pol, \n",
    "        delta_taus= delta_taus,   \n",
    "        **kwargs_ft\n",
    "    )\n",
    "    \n",
    "    exp_8.reset()\n",
    "    exp_8.run_all(mu_8[-1], delta_taus)\n",
    "    exp_16.reset()\n",
    "    exp_16.run_all(mu_16[-1], delta_taus)\n",
    "    exp_32.reset()\n",
    "    exp_32.run_all(mu_32[-1], delta_taus)\n",
    "    \n",
    "    dist_ft_8[n] = exp_8.loss()\n",
    "    dist_ft_16[n] = exp_16.loss()\n",
    "    dist_ft_32[n] = exp_32.loss()\n",
    "    \n",
    "\n",
    "(\n",
    "    np.savez_compressed(\n",
    "        \"../results/general_dist_in_train\", \n",
    "        dist_8=dist_8, \n",
    "        dist_16=dist_16, \n",
    "        dist_32=dist_32, \n",
    "        dist_ft_8=dist_ft_8, \n",
    "        dist_ft_16=dist_ft_16, \n",
    "        dist_ft_32=dist_ft_32, \n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
