{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from separation_utility import *\n",
    "from torch import optim, tensor\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alists = []\n",
    "alists.append(pd.read_csv(f'../data/GilarSample.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Roca.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Controlmix2.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_field(exp, taus, N = 200):\n",
    "    phis = np.linspace(0, 1, N)\n",
    "    losses = np.zeros((N, N))\n",
    "    j = 0\n",
    "    for phi1 in phis:\n",
    "        i = 0\n",
    "        for phi2 in phis:\n",
    "            exp.reset()\n",
    "            exp.run_all([phi1, phi2], taus)\n",
    "            losses[i, j] = exp.loss()\n",
    "            i += 1\n",
    "        j += 1\n",
    "    X, Y = np.meshgrid(phis, phis)\n",
    "    \n",
    "    return X, Y, losses\n",
    "\n",
    "def average_over_equal_intervals(arr, interval):\n",
    "    return np.mean(arr.reshape(-1, interval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/Thesis/code/chromatography.py:250: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return delta_tau_phi * (1 + self.k(phi)) / self.k(phi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4030468970902817, epoch: 20000/20000\n",
      "Loss: 0.5169691473367679, epoch: 100/2000\n",
      "Loss: 0.507738990448791, epoch: 200/2000\n",
      "Loss: 0.5007827904090174, epoch: 300/2000\n",
      "Loss: 0.5240758422062577, epoch: 400/2000\n",
      "Loss: 0.4994911578994783, epoch: 500/2000\n",
      "Loss: 0.5017388527503364, epoch: 600/2000\n",
      "Loss: 0.2603477173950704, epoch: 700/2000\n",
      "Loss: 0.3098511163328784, epoch: 800/2000\n",
      "Loss: 0.29809759696839844, epoch: 900/2000\n",
      "Loss: 0.22547046457459122, epoch: 1000/2000\n",
      "Loss: 0.23987654567750138, epoch: 1100/2000\n",
      "Loss: 0.26525608822673785, epoch: 1200/2000\n",
      "Loss: 0.22628237415482072, epoch: 1300/2000\n",
      "Loss: 0.2445938398011717, epoch: 1400/2000\n",
      "Loss: 0.23825156886402796, epoch: 1500/2000\n",
      "Loss: 0.2234275821037061, epoch: 1600/2000\n",
      "Loss: 0.20286648643034066, epoch: 1700/2000\n",
      "Loss: 0.20623322537282252, epoch: 1800/2000\n",
      "Loss: 0.30389252627392466, epoch: 1900/2000\n",
      "Loss: 0.1961650241528139, epoch: 2000/2000\n",
      "Loss: 1.7813370965294202, epoch: 20000/20000\n",
      "Loss: 0.288586346959544, epoch: 100/2000\n",
      "Loss: 0.2583644022472416, epoch: 200/2000\n",
      "Loss: 0.24034013347638378, epoch: 300/2000\n",
      "Loss: 0.23931489588088498, epoch: 400/2000\n",
      "Loss: 0.3066463555481181, epoch: 500/2000\n",
      "Loss: 0.22067112269915606, epoch: 600/2000\n",
      "Loss: 0.19957683915030766, epoch: 700/2000\n",
      "Loss: 0.20814192736438786, epoch: 800/2000\n",
      "Loss: 0.15409845064044161, epoch: 900/2000\n",
      "Loss: 0.17725913040577126, epoch: 1000/2000\n",
      "Loss: 0.16127809993523545, epoch: 1100/2000\n",
      "Loss: 0.16045121110654753, epoch: 1200/2000\n",
      "Loss: 0.141785194342859, epoch: 1300/2000\n",
      "Loss: 0.1697079473596414, epoch: 1400/2000\n",
      "Loss: 0.12432698944609717, epoch: 1500/2000\n",
      "Loss: 0.19550925950275505, epoch: 1600/2000\n",
      "Loss: 0.14019823471824902, epoch: 1700/2000\n",
      "Loss: 0.12284713586785287, epoch: 1800/2000\n",
      "Loss: 0.14227628281088028, epoch: 1900/2000\n",
      "Loss: 0.16669144797489704, epoch: 2000/2000\n",
      "Loss: 1.8817336785279188, epoch: 20000/20000\n",
      "Loss: 0.937279150620739, epoch: 100/2000\n",
      "Loss: 0.8800405461818391, epoch: 200/2000\n",
      "Loss: 0.9859007522773574, epoch: 300/2000\n",
      "Loss: 0.808635415622686, epoch: 400/2000\n",
      "Loss: 0.745640401416356, epoch: 500/2000\n",
      "Loss: 0.8851244299950978, epoch: 600/2000\n",
      "Loss: 0.8810644576933738, epoch: 700/2000\n",
      "Loss: 0.8271053262084964, epoch: 800/2000\n",
      "Loss: 0.511859510837197, epoch: 900/2000\n",
      "Loss: 0.36215421145262905, epoch: 1000/2000\n",
      "Loss: 0.2983763723465806, epoch: 1100/2000\n",
      "Loss: 0.3044563102026174, epoch: 1200/2000\n",
      "Loss: 0.24705272562974495, epoch: 1300/2000\n",
      "Loss: 0.2543619934635533, epoch: 1400/2000\n",
      "Loss: 0.21434582696785412, epoch: 1500/2000\n",
      "Loss: 0.22623071788322885, epoch: 1600/2000\n",
      "Loss: 0.2239446354776565, epoch: 1700/2000\n",
      "Loss: 0.16397038749035603, epoch: 1800/2000\n",
      "Loss: 0.2789927223740337, epoch: 1900/2000\n",
      "Loss: 0.4838623552916796, epoch: 2000/2000\n",
      "Loss: 1.1208788313378313, epoch: 20000/20000\n",
      "Loss: 0.2663785992526383, epoch: 100/2000\n",
      "Loss: 0.22355113794860992, epoch: 200/2000\n",
      "Loss: 0.286333268215055, epoch: 300/2000\n",
      "Loss: 0.15198815920907935, epoch: 400/2000\n",
      "Loss: 0.16088883145413993, epoch: 500/2000\n",
      "Loss: 0.16122708887333947, epoch: 600/2000\n",
      "Loss: 0.2382803096423119, epoch: 700/2000\n",
      "Loss: 0.16822983753482307, epoch: 800/2000\n",
      "Loss: 0.238899940741398, epoch: 900/2000\n",
      "Loss: 0.28695689074625735, epoch: 1000/2000\n",
      "Loss: 0.20993301504501755, epoch: 1100/2000\n",
      "Loss: 0.24699896410759187, epoch: 1200/2000\n",
      "Loss: 0.20354126325675778, epoch: 1300/2000\n",
      "Loss: 0.1565372259162156, epoch: 1400/2000\n",
      "Loss: 0.18618174610918706, epoch: 1500/2000\n",
      "Loss: 0.14251542529616468, epoch: 1600/2000\n",
      "Loss: 0.14055745814381565, epoch: 1700/2000\n",
      "Loss: 0.1614784209279157, epoch: 1800/2000\n",
      "Loss: 0.1542624863640294, epoch: 1900/2000\n",
      "Loss: 0.1530458814703204, epoch: 2000/2000\n",
      "Loss: 0.4842767425256266, epoch: 20000/20000\n",
      "Loss: 0.24796941290444896, epoch: 100/2000\n",
      "Loss: 0.23297638038875784, epoch: 200/2000\n",
      "Loss: 0.31709314614219075, epoch: 300/2000\n",
      "Loss: 0.21379811119997222, epoch: 400/2000\n",
      "Loss: 0.32879402561186233, epoch: 500/2000\n",
      "Loss: 0.2191138250873983, epoch: 600/2000\n",
      "Loss: 0.36303449827920564, epoch: 700/2000\n",
      "Loss: 0.20207608197001425, epoch: 800/2000\n",
      "Loss: 0.23486162105777675, epoch: 900/2000\n",
      "Loss: 0.20688632277903132, epoch: 1000/2000\n",
      "Loss: 0.221406749893502, epoch: 1100/2000\n",
      "Loss: 0.21525002885437053, epoch: 1200/2000\n",
      "Loss: 0.21292670943191, epoch: 1300/2000\n",
      "Loss: 0.2575590354379797, epoch: 1400/2000\n",
      "Loss: 0.24043504824349027, epoch: 1500/2000\n",
      "Loss: 0.22405694436370135, epoch: 1600/2000\n",
      "Loss: 0.21569415542333048, epoch: 1700/2000\n",
      "Loss: 0.2238385352243543, epoch: 1800/2000\n",
      "Loss: 0.24650387402782514, epoch: 1900/2000\n",
      "Loss: 0.1678007350620268, epoch: 2000/2000\n",
      "Loss: 0.8166742301094448, epoch: 20000/20000\n",
      "Loss: 0.26683556115340823, epoch: 100/2000\n",
      "Loss: 0.2623202609734123, epoch: 200/2000\n",
      "Loss: 0.2383596918688952, epoch: 300/2000\n",
      "Loss: 0.234921413654498, epoch: 400/2000\n",
      "Loss: 0.2287228717939019, epoch: 500/2000\n",
      "Loss: 0.22237566995189811, epoch: 600/2000\n",
      "Loss: 0.23050511013435399, epoch: 700/2000\n",
      "Loss: 0.22282154246125868, epoch: 800/2000\n",
      "Loss: 0.22577404459853145, epoch: 900/2000\n",
      "Loss: 0.2290340194476442, epoch: 1000/2000\n",
      "Loss: 0.20919556807175183, epoch: 1100/2000\n",
      "Loss: 0.22268594493888982, epoch: 1200/2000\n",
      "Loss: 0.22275044498622307, epoch: 1300/2000\n",
      "Loss: 0.22391727679798895, epoch: 1400/2000\n",
      "Loss: 0.23755291590948793, epoch: 1500/2000\n",
      "Loss: 0.23137323337999377, epoch: 1600/2000\n",
      "Loss: 0.224922974789978, epoch: 1700/2000\n",
      "Loss: 0.22176204441733663, epoch: 1800/2000\n",
      "Loss: 0.24067716626692218, epoch: 1900/2000\n",
      "Loss: 0.21078066572441873, epoch: 2000/2000\n",
      "Loss: 1.019643845270582, epoch: 20000/20000\n",
      "Loss: 0.30261098107677353, epoch: 100/2000\n",
      "Loss: 0.2243054902207951, epoch: 200/2000\n",
      "Loss: 0.18840819706998577, epoch: 300/2000\n",
      "Loss: 0.1713340327605847, epoch: 400/2000\n",
      "Loss: 0.20411695371033986, epoch: 500/2000\n",
      "Loss: 0.19252297845859828, epoch: 600/2000\n",
      "Loss: 0.235021922970534, epoch: 700/2000\n",
      "Loss: 0.2755612519315026, epoch: 800/2000\n",
      "Loss: 0.3021371776614995, epoch: 900/2000\n",
      "Loss: 0.27316687774006104, epoch: 1000/2000\n",
      "Loss: 0.27145683763897066, epoch: 1100/2000\n",
      "Loss: 0.2834958817829446, epoch: 1200/2000\n",
      "Loss: 0.24558881759387038, epoch: 1300/2000\n",
      "Loss: 0.2430331680036733, epoch: 1400/2000\n",
      "Loss: 0.23160347692944522, epoch: 1500/2000\n",
      "Loss: 0.2463781688972262, epoch: 1600/2000\n",
      "Loss: 0.20782906257032757, epoch: 1700/2000\n",
      "Loss: 0.185909774433348, epoch: 1800/2000\n",
      "Loss: 0.17199280471307204, epoch: 1900/2000\n",
      "Loss: 0.13437666745111712, epoch: 2000/2000\n",
      "Loss: 0.6642640242233977, epoch: 20000/20000\n",
      "Loss: 0.23687875590128038, epoch: 100/2000\n",
      "Loss: 0.23111343737673037, epoch: 200/2000\n",
      "Loss: 0.2352409168111788, epoch: 300/2000\n",
      "Loss: 0.21025351124645092, epoch: 400/2000\n",
      "Loss: 0.1922996348561531, epoch: 500/2000\n",
      "Loss: 0.1778079311975387, epoch: 600/2000\n",
      "Loss: 0.1975733334911706, epoch: 700/2000\n",
      "Loss: 0.18643123763273015, epoch: 800/2000\n",
      "Loss: 0.16969151666610982, epoch: 900/2000\n",
      "Loss: 0.16964013625868576, epoch: 1000/2000\n",
      "Loss: 0.16107857078733853, epoch: 1100/2000\n",
      "Loss: 0.1661507165663564, epoch: 1200/2000\n",
      "Loss: 0.14951974288510053, epoch: 1300/2000\n",
      "Loss: 0.13953095605873334, epoch: 1400/2000\n",
      "Loss: 0.1452017774016923, epoch: 1500/2000\n",
      "Loss: 0.1552172121152084, epoch: 1600/2000\n",
      "Loss: 0.14772314882693105, epoch: 1700/2000\n",
      "Loss: 0.1428321567859171, epoch: 1800/2000\n",
      "Loss: 0.13993395945815207, epoch: 1900/2000\n",
      "Loss: 0.15497496983736145, epoch: 2000/2000\n",
      "Loss: 1.0285694925686593, epoch: 20000/20000\n",
      "Loss: 0.19782110754768603, epoch: 100/2000\n",
      "Loss: 0.12878304158640116, epoch: 200/2000\n",
      "Loss: 0.14787621842107207, epoch: 300/2000\n",
      "Loss: 0.16113801646446485, epoch: 400/2000\n",
      "Loss: 0.5216372230033107, epoch: 500/2000\n",
      "Loss: 0.15111555151653366, epoch: 600/2000\n",
      "Loss: 0.21543277752516854, epoch: 700/2000\n",
      "Loss: 0.23217169100454876, epoch: 800/2000\n",
      "Loss: 0.1512901651151486, epoch: 900/2000\n",
      "Loss: 0.2275286998924499, epoch: 1000/2000\n",
      "Loss: 0.12164435362638044, epoch: 1100/2000\n",
      "Loss: 0.13425086786712026, epoch: 1200/2000\n",
      "Loss: 0.11849013169105824, epoch: 1300/2000\n",
      "Loss: 0.12108014565668364, epoch: 1400/2000\n",
      "Loss: 0.17807255102775765, epoch: 1500/2000\n",
      "Loss: 0.14073036099915676, epoch: 1600/2000\n",
      "Loss: 0.16440798971533174, epoch: 1700/2000\n",
      "Loss: 0.1591062520624839, epoch: 1800/2000\n",
      "Loss: 0.23592457175053533, epoch: 1900/2000\n",
      "Loss: 0.2805911341875239, epoch: 2000/2000\n",
      "Loss: 1.9011440169295877, epoch: 20000/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18809147810397878, epoch: 100/2000\n",
      "Loss: 0.18225412583476147, epoch: 200/2000\n",
      "Loss: 0.19244668605813395, epoch: 300/2000\n",
      "Loss: 0.18093442836283305, epoch: 400/2000\n",
      "Loss: 0.15754673227879185, epoch: 500/2000\n",
      "Loss: 0.17805622083646008, epoch: 600/2000\n",
      "Loss: 0.156967013571856, epoch: 700/2000\n",
      "Loss: 0.14041596772103082, epoch: 800/2000\n",
      "Loss: 0.12691275409753142, epoch: 900/2000\n",
      "Loss: 0.19456009340069982, epoch: 1000/2000\n",
      "Loss: 0.126934404230362, epoch: 1100/2000\n",
      "Loss: 0.12751456716969067, epoch: 1200/2000\n",
      "Loss: 0.13102280006370357, epoch: 1300/2000\n",
      "Loss: 0.11620051967623435, epoch: 1400/2000\n",
      "Loss: 0.11356217611979325, epoch: 1500/2000\n",
      "Loss: 0.12704196817942676, epoch: 1600/2000\n",
      "Loss: 0.16366109652157862, epoch: 1700/2000\n",
      "Loss: 0.12849349746878663, epoch: 1800/2000\n",
      "Loss: 0.12754505645282485, epoch: 1900/2000\n",
      "Loss: 0.18540940688774632, epoch: 2000/2000\n",
      "Loss: 0.4150051381934273, epoch: 20000/20000\n",
      "Loss: 0.5051699138481506, epoch: 100/2000\n",
      "Loss: 0.25259014681313213, epoch: 200/2000\n",
      "Loss: 0.2323792499353048, epoch: 300/2000\n",
      "Loss: 0.22505936893284556, epoch: 400/2000\n",
      "Loss: 0.2612090782567585, epoch: 500/2000\n",
      "Loss: 0.2920564874717654, epoch: 600/2000\n",
      "Loss: 0.21410490406271804, epoch: 700/2000\n",
      "Loss: 0.3148294120241807, epoch: 800/2000\n",
      "Loss: 0.21419979127264455, epoch: 900/2000\n",
      "Loss: 0.19471991577268272, epoch: 1000/2000\n",
      "Loss: 0.19384442312176675, epoch: 1100/2000\n",
      "Loss: 0.19703992224301783, epoch: 1200/2000\n",
      "Loss: 0.19964395290179693, epoch: 1300/2000\n",
      "Loss: 0.21075506511187325, epoch: 1400/2000\n",
      "Loss: 0.19613057368540168, epoch: 1500/2000\n",
      "Loss: 0.22636353775880802, epoch: 1600/2000\n",
      "Loss: 0.19909127548816366, epoch: 1700/2000\n",
      "Loss: 0.18874251902125805, epoch: 1800/2000\n",
      "Loss: 0.1818558085141336, epoch: 1900/2000\n",
      "Loss: 0.20520944149075868, epoch: 2000/2000\n",
      "Loss: 1.8930635710054773, epoch: 20000/20000\n",
      "Loss: 0.3318773549684818, epoch: 100/2000\n",
      "Loss: 0.3312397149187429, epoch: 200/2000\n",
      "Loss: 0.21602079133367233, epoch: 300/2000\n",
      "Loss: 0.12535902021902207, epoch: 400/2000\n",
      "Loss: 0.2113531457217749, epoch: 500/2000\n",
      "Loss: 0.1348642977093937, epoch: 600/2000\n",
      "Loss: 0.2721060264850582, epoch: 700/2000\n",
      "Loss: 0.20261882742544657, epoch: 800/2000\n",
      "Loss: 0.263403255098163, epoch: 900/2000\n",
      "Loss: 0.18451945934842445, epoch: 1000/2000\n",
      "Loss: 0.21731300517787133, epoch: 1100/2000\n",
      "Loss: 0.19008718909915429, epoch: 1200/2000\n",
      "Loss: 0.15428473381101265, epoch: 1300/2000\n",
      "Loss: 0.13698451700878933, epoch: 1400/2000\n",
      "Loss: 0.12363394868547081, epoch: 1500/2000\n",
      "Loss: 0.16047003931891735, epoch: 1600/2000\n",
      "Loss: 0.20183521057094564, epoch: 1700/2000\n",
      "Loss: 0.17297361420384688, epoch: 1800/2000\n",
      "Loss: 0.21042161709164117, epoch: 1900/2000\n",
      "Loss: 0.1973375277058446, epoch: 2000/2000\n",
      "Loss: 0.3830764816564228, epoch: 20000/20000\n",
      "Loss: 0.14801612528595348, epoch: 100/2000\n",
      "Loss: 0.2436522839032751, epoch: 200/2000\n",
      "Loss: 0.15955819579092323, epoch: 300/2000\n",
      "Loss: 0.17157020921286179, epoch: 400/2000\n",
      "Loss: 0.1824763328048778, epoch: 500/2000\n",
      "Loss: 0.2534919974187683, epoch: 600/2000\n",
      "Loss: 0.19288045713627983, epoch: 700/2000\n",
      "Loss: 0.2678110554647084, epoch: 800/2000\n",
      "Loss: 0.2852588963521235, epoch: 900/2000\n",
      "Loss: 0.22510381311735342, epoch: 1000/2000\n",
      "Loss: 0.26363761623904675, epoch: 1100/2000\n",
      "Loss: 0.24648943578795174, epoch: 1200/2000\n",
      "Loss: 0.2112169826936269, epoch: 1300/2000\n",
      "Loss: 0.224209663221017, epoch: 1400/2000\n",
      "Loss: 0.1544194537858209, epoch: 1500/2000\n",
      "Loss: 0.13359287716674811, epoch: 1600/2000\n",
      "Loss: 0.1275686893788519, epoch: 1700/2000\n",
      "Loss: 0.10718326384063093, epoch: 1800/2000\n",
      "Loss: 0.12506103984296366, epoch: 1900/2000\n",
      "Loss: 0.1479653033547966, epoch: 2000/2000\n",
      "Loss: 0.4526734956000231, epoch: 20000/20000\n",
      "Loss: 0.23178369935257942, epoch: 100/2000\n",
      "Loss: 0.32851033318925976, epoch: 200/2000\n",
      "Loss: 0.21114213732044346, epoch: 300/2000\n",
      "Loss: 0.26378953812655864, epoch: 400/2000\n",
      "Loss: 0.18978403239609426, epoch: 500/2000\n",
      "Loss: 0.19782864783849233, epoch: 600/2000\n",
      "Loss: 0.2831900250789549, epoch: 700/2000\n",
      "Loss: 0.18094779998995433, epoch: 800/2000\n",
      "Loss: 0.1988094378691335, epoch: 900/2000\n",
      "Loss: 0.1958389292232428, epoch: 1000/2000\n",
      "Loss: 0.206565958454141, epoch: 1100/2000\n",
      "Loss: 0.18586146027449407, epoch: 1200/2000\n",
      "Loss: 0.26543554620613413, epoch: 1300/2000\n",
      "Loss: 0.2143830001524229, epoch: 1400/2000\n",
      "Loss: 0.20523766956862882, epoch: 1500/2000\n",
      "Loss: 0.18994534372032307, epoch: 1600/2000\n",
      "Loss: 0.21938093347636722, epoch: 1700/2000\n",
      "Loss: 0.18956593961825338, epoch: 1800/2000\n",
      "Loss: 0.2172200336049545, epoch: 1900/2000\n",
      "Loss: 0.19925698963535565, epoch: 2000/2000\n",
      "Loss: 1.5227318767059728, epoch: 20000/20000\n",
      "Loss: 0.2527975911061261, epoch: 100/2000\n",
      "Loss: 0.1656200212707434, epoch: 200/2000\n",
      "Loss: 0.2091706788234152, epoch: 300/2000\n",
      "Loss: 0.332225255584382, epoch: 400/2000\n",
      "Loss: 0.2857242843674334, epoch: 500/2000\n",
      "Loss: 0.16810156359246572, epoch: 600/2000\n",
      "Loss: 0.2302839900304916, epoch: 700/2000\n",
      "Loss: 0.22012014175875141, epoch: 800/2000\n",
      "Loss: 0.20887555859074566, epoch: 900/2000\n",
      "Loss: 0.24650978426575332, epoch: 1000/2000\n",
      "Loss: 0.17675372972737668, epoch: 1100/2000\n",
      "Loss: 0.156560915200279, epoch: 1200/2000\n",
      "Loss: 0.18502356162768274, epoch: 1300/2000\n",
      "Loss: 0.10924229332195427, epoch: 1400/2000\n",
      "Loss: 0.14092524644343857, epoch: 1500/2000\n",
      "Loss: 0.10102998167334647, epoch: 1600/2000\n",
      "Loss: 0.10905380435802173, epoch: 1700/2000\n",
      "Loss: 0.1680458357781192, epoch: 1800/2000\n",
      "Loss: 0.157610156176858, epoch: 1900/2000\n",
      "Loss: 0.14352284105692553, epoch: 2000/2000\n",
      "Loss: 0.48470919913538335, epoch: 20000/20000\n",
      "Loss: 0.4689897066130583, epoch: 100/2000\n",
      "Loss: 0.21715384643513555, epoch: 200/2000\n",
      "Loss: 0.2197603673373743, epoch: 300/2000\n",
      "Loss: 0.23431851286738356, epoch: 400/2000\n",
      "Loss: 0.23064904997255345, epoch: 500/2000\n",
      "Loss: 0.27463979725815346, epoch: 600/2000\n",
      "Loss: 0.2349252313655475, epoch: 700/2000\n",
      "Loss: 0.22771391428448626, epoch: 800/2000\n",
      "Loss: 0.2233145655420604, epoch: 900/2000\n",
      "Loss: 0.2219304724272268, epoch: 1000/2000\n",
      "Loss: 0.30261686125098397, epoch: 1100/2000\n",
      "Loss: 0.2847338100924786, epoch: 1200/2000\n",
      "Loss: 0.20095128021463635, epoch: 1300/2000\n",
      "Loss: 0.2189423513515761, epoch: 1400/2000\n",
      "Loss: 0.2107730945929041, epoch: 1500/2000\n",
      "Loss: 0.22143196197649878, epoch: 1600/2000\n",
      "Loss: 0.20701463083460067, epoch: 1700/2000\n",
      "Loss: 0.20995285132349975, epoch: 1800/2000\n",
      "Loss: 0.19367799914196324, epoch: 1900/2000\n",
      "Loss: 0.21498147578207974, epoch: 2000/2000\n",
      "Loss: 0.6230353876459103, epoch: 20000/20000\n",
      "Loss: 0.18382981980750138, epoch: 100/2000\n",
      "Loss: 0.16859101720626926, epoch: 200/2000\n",
      "Loss: 0.16982820169141724, epoch: 300/2000\n",
      "Loss: 0.1692653218778705, epoch: 400/2000\n",
      "Loss: 0.2185901903364736, epoch: 500/2000\n",
      "Loss: 0.17677424942543732, epoch: 600/2000\n",
      "Loss: 0.15762662314329443, epoch: 700/2000\n",
      "Loss: 0.1504594793108968, epoch: 800/2000\n",
      "Loss: 0.1570412899090148, epoch: 900/2000\n",
      "Loss: 0.13910533483209758, epoch: 1000/2000\n",
      "Loss: 0.16543073241774403, epoch: 1100/2000\n",
      "Loss: 0.13622587524564037, epoch: 1200/2000\n",
      "Loss: 0.12216449935142362, epoch: 1300/2000\n",
      "Loss: 0.13051623924257244, epoch: 1400/2000\n",
      "Loss: 0.1275347057402227, epoch: 1500/2000\n",
      "Loss: 0.14974029780137324, epoch: 1600/2000\n",
      "Loss: 0.11068167081225873, epoch: 1700/2000\n",
      "Loss: 0.10585995075624328, epoch: 1800/2000\n",
      "Loss: 0.1706430254690477, epoch: 1900/2000\n",
      "Loss: 0.18640728499935713, epoch: 2000/2000\n",
      "Loss: 1.0310419710772203, epoch: 20000/20000\n",
      "Loss: 0.19927941257525209, epoch: 100/2000\n",
      "Loss: 0.1771892475732904, epoch: 200/2000\n",
      "Loss: 0.16414345623261709, epoch: 300/2000\n",
      "Loss: 0.1428596236122079, epoch: 400/2000\n",
      "Loss: 0.1438438997307076, epoch: 500/2000\n",
      "Loss: 0.15432812135057922, epoch: 600/2000\n",
      "Loss: 0.1841904806314735, epoch: 700/2000\n",
      "Loss: 0.1514206234933568, epoch: 800/2000\n",
      "Loss: 0.16556895192738647, epoch: 900/2000\n",
      "Loss: 0.15245033433792216, epoch: 1000/2000\n",
      "Loss: 0.1732540292351802, epoch: 1100/2000\n",
      "Loss: 0.11987558509005265, epoch: 1200/2000\n",
      "Loss: 0.13994685330506257, epoch: 1300/2000\n",
      "Loss: 0.15982203793723085, epoch: 1400/2000\n",
      "Loss: 0.23540463618452243, epoch: 1500/2000\n",
      "Loss: 0.20880356608742243, epoch: 1600/2000\n",
      "Loss: 0.15517121610613846, epoch: 1700/2000\n",
      "Loss: 0.10084838669803468, epoch: 1800/2000\n",
      "Loss: 0.12649938642057293, epoch: 1900/2000\n",
      "Loss: 0.12682445204147702, epoch: 2000/2000\n",
      "Loss: 0.7172066827385056, epoch: 20000/20000\n",
      "Loss: 0.19215506283955647, epoch: 100/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18829540031749184, epoch: 200/2000\n",
      "Loss: 0.18414021104412406, epoch: 300/2000\n",
      "Loss: 0.17311253989106634, epoch: 400/2000\n",
      "Loss: 0.15522537088228322, epoch: 500/2000\n",
      "Loss: 0.17145762244396662, epoch: 600/2000\n",
      "Loss: 0.16594431430788428, epoch: 700/2000\n",
      "Loss: 0.17285655851571735, epoch: 800/2000\n",
      "Loss: 0.19291842596279274, epoch: 900/2000\n",
      "Loss: 0.19746557381503785, epoch: 1000/2000\n",
      "Loss: 0.14997475442208602, epoch: 1100/2000\n",
      "Loss: 0.14929254550055768, epoch: 1200/2000\n",
      "Loss: 0.13758844227646108, epoch: 1300/2000\n",
      "Loss: 0.13182675300648725, epoch: 1400/2000\n",
      "Loss: 0.14408632133528684, epoch: 1500/2000\n",
      "Loss: 0.1521652308653678, epoch: 1600/2000\n",
      "Loss: 0.131682654114789, epoch: 1700/2000\n",
      "Loss: 0.13578934594218375, epoch: 1800/2000\n",
      "Loss: 0.14262675081288365, epoch: 1900/2000\n",
      "Loss: 0.13780034052910992, epoch: 2000/2000\n",
      "Loss: 1.8733367619303074, epoch: 20000/20000\n",
      "Loss: 0.34107503314471754, epoch: 100/2000\n",
      "Loss: 0.3063082399517322, epoch: 200/2000\n",
      "Loss: 0.26534403936884005, epoch: 300/2000\n",
      "Loss: 0.16189268264303452, epoch: 400/2000\n",
      "Loss: 0.14323089596191557, epoch: 500/2000\n",
      "Loss: 0.2348824605004995, epoch: 600/2000\n",
      "Loss: 0.2358265400564544, epoch: 700/2000\n",
      "Loss: 0.17257066140006377, epoch: 800/2000\n",
      "Loss: 0.2579473732505369, epoch: 900/2000\n",
      "Loss: 0.14820066775321777, epoch: 1000/2000\n",
      "Loss: 0.1230137378837776, epoch: 1100/2000\n",
      "Loss: 0.13226889670417832, epoch: 1200/2000\n",
      "Loss: 0.13910173031745596, epoch: 1300/2000\n",
      "Loss: 0.14233608921597005, epoch: 1400/2000\n",
      "Loss: 0.1682381229915445, epoch: 1500/2000\n",
      "Loss: 0.21351134486547582, epoch: 1600/2000\n",
      "Loss: 0.21995155841369224, epoch: 1700/2000\n",
      "Loss: 0.1699465469881783, epoch: 1800/2000\n",
      "Loss: 0.1659292889454937, epoch: 1900/2000\n",
      "Loss: 0.15304005426390357, epoch: 2000/2000\n",
      "Loss: 0.4288458108461142, epoch: 20000/20000\n",
      "Loss: 0.26993587685574527, epoch: 100/2000\n",
      "Loss: 0.23997021079603137, epoch: 200/2000\n",
      "Loss: 0.23435917069941245, epoch: 300/2000\n",
      "Loss: 0.25714272195614585, epoch: 400/2000\n",
      "Loss: 0.2449764129986422, epoch: 500/2000\n",
      "Loss: 0.3417786361926321, epoch: 600/2000\n",
      "Loss: 0.22203395703404513, epoch: 700/2000\n",
      "Loss: 0.25899364413149695, epoch: 800/2000\n",
      "Loss: 0.20344052376292762, epoch: 900/2000\n",
      "Loss: 0.21814032282571488, epoch: 1000/2000\n",
      "Loss: 0.243101723701631, epoch: 1100/2000\n",
      "Loss: 0.31242659179160437, epoch: 1200/2000\n",
      "Loss: 0.3002372242247344, epoch: 1300/2000\n",
      "Loss: 0.2849079740293734, epoch: 1400/2000\n",
      "Loss: 0.21495762850206868, epoch: 1500/2000\n",
      "Loss: 0.266901470453206, epoch: 1600/2000\n",
      "Loss: 0.2325211093243662, epoch: 1700/2000\n",
      "Loss: 0.23653424734178005, epoch: 1800/2000\n",
      "Loss: 0.22800140218875936, epoch: 1900/2000\n",
      "Loss: 0.19992156741651348, epoch: 2000/2000\n",
      "Loss: 1.897287495236077, epoch: 20000/20000\n",
      "Loss: 0.5018443115234291, epoch: 100/2000\n",
      "Loss: 0.22348787047171506, epoch: 200/2000\n",
      "Loss: 0.41273707798046627, epoch: 300/2000\n",
      "Loss: 0.17435061417894382, epoch: 400/2000\n",
      "Loss: 0.1210711892853926, epoch: 500/2000\n",
      "Loss: 0.17761538188328768, epoch: 600/2000\n",
      "Loss: 0.17544519742742332, epoch: 700/2000\n",
      "Loss: 0.19467280276313478, epoch: 800/2000\n",
      "Loss: 0.15262185995410893, epoch: 900/2000\n",
      "Loss: 0.3199979417209146, epoch: 1000/2000\n",
      "Loss: 0.2053477055223542, epoch: 1100/2000\n",
      "Loss: 0.17037242565715277, epoch: 1200/2000\n",
      "Loss: 0.1500323665851613, epoch: 1300/2000\n",
      "Loss: 0.16496920890244077, epoch: 1400/2000\n",
      "Loss: 0.16428295063410697, epoch: 1500/2000\n",
      "Loss: 0.1189411004941848, epoch: 1600/2000\n",
      "Loss: 0.14088132792721236, epoch: 1700/2000\n",
      "Loss: 0.17726050716042613, epoch: 1800/2000\n",
      "Loss: 0.249622777312532, epoch: 1900/2000\n",
      "Loss: 0.19517950552368485, epoch: 2000/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/Thesis/code/chromatography.py:250: RuntimeWarning: overflow encountered in true_divide\n",
      "  return delta_tau_phi * (1 + self.k(phi)) / self.k(phi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.496698711957057, epoch: 20000/20000\n",
      "Loss: 0.2675341176284668, epoch: 100/2000\n",
      "Loss: 0.19999011754705998, epoch: 200/2000\n",
      "Loss: 0.19460545572514718, epoch: 300/2000\n",
      "Loss: 0.2176222391960152, epoch: 400/2000\n",
      "Loss: 0.21267556331027043, epoch: 500/2000\n",
      "Loss: 0.2661110043998379, epoch: 600/2000\n",
      "Loss: 0.2950393543370105, epoch: 700/2000\n",
      "Loss: 0.4620367072779089, epoch: 800/2000\n",
      "Loss: 0.35648190844289235, epoch: 900/2000\n",
      "Loss: 0.3846020421826666, epoch: 1000/2000\n",
      "Loss: 0.22579677950998972, epoch: 1100/2000\n",
      "Loss: 0.19030089200149344, epoch: 1200/2000\n",
      "Loss: 0.18601993417882956, epoch: 1300/2000\n",
      "Loss: 0.2312089769252989, epoch: 1400/2000\n",
      "Loss: 0.21168497998862615, epoch: 1500/2000\n",
      "Loss: 0.19539468638629598, epoch: 1600/2000\n",
      "Loss: 0.21172795728427113, epoch: 1700/2000\n",
      "Loss: 0.22022611565777583, epoch: 1800/2000\n",
      "Loss: 0.2500915171401647, epoch: 1900/2000\n",
      "Loss: 0.18779753356665585, epoch: 2000/2000\n",
      "Loss: 0.9338551220050105, epoch: 20000/20000\n",
      "Loss: 0.5126584653884111, epoch: 100/2000\n",
      "Loss: 0.5151343984647022, epoch: 200/2000\n",
      "Loss: 0.49762798404839276, epoch: 300/2000\n",
      "Loss: 0.521215443539907, epoch: 400/2000\n",
      "Loss: 0.5204004376860146, epoch: 500/2000\n",
      "Loss: 0.2376127307116886, epoch: 600/2000\n",
      "Loss: 0.2311394699049513, epoch: 700/2000\n",
      "Loss: 0.23912351058277265, epoch: 800/2000\n",
      "Loss: 0.21103225879036852, epoch: 900/2000\n",
      "Loss: 0.4020474346023975, epoch: 1000/2000\n",
      "Loss: 0.23114009673834368, epoch: 1100/2000\n",
      "Loss: 0.22167625477110303, epoch: 1200/2000\n",
      "Loss: 0.2131180316185815, epoch: 1300/2000\n",
      "Loss: 0.22139996491500594, epoch: 1400/2000\n",
      "Loss: 0.22147243812973114, epoch: 1500/2000\n",
      "Loss: 0.22413293854312166, epoch: 1600/2000\n",
      "Loss: 0.301283666548397, epoch: 1700/2000\n",
      "Loss: 0.2441195143325094, epoch: 1800/2000\n",
      "Loss: 0.2606729315008997, epoch: 1900/2000\n",
      "Loss: 0.22666082611663887, epoch: 2000/2000\n",
      "Loss: 1.8955959321675606, epoch: 20000/20000\n",
      "Loss: 0.18645605450815067, epoch: 100/2000\n",
      "Loss: 0.38749532632394784, epoch: 200/2000\n",
      "Loss: 0.2594322132265185, epoch: 300/2000\n",
      "Loss: 0.175967243201033, epoch: 400/2000\n",
      "Loss: 0.1433990913439506, epoch: 500/2000\n",
      "Loss: 0.1589295543669493, epoch: 600/2000\n",
      "Loss: 0.15567377405666477, epoch: 700/2000\n",
      "Loss: 0.14651595640117315, epoch: 800/2000\n",
      "Loss: 0.22493081790788588, epoch: 900/2000\n",
      "Loss: 0.2127103348138339, epoch: 1000/2000\n",
      "Loss: 0.18977203153772498, epoch: 1100/2000\n",
      "Loss: 0.15959911625246628, epoch: 1200/2000\n",
      "Loss: 0.14371719422620252, epoch: 1300/2000\n",
      "Loss: 0.1331245458391189, epoch: 1400/2000\n",
      "Loss: 0.14449545629072527, epoch: 1500/2000\n",
      "Loss: 0.1474979998585609, epoch: 1600/2000\n",
      "Loss: 0.17833955103481364, epoch: 1700/2000\n",
      "Loss: 0.17197586641392149, epoch: 1800/2000\n",
      "Loss: 0.18648781689227562, epoch: 1900/2000\n",
      "Loss: 0.18342405779575724, epoch: 2000/2000\n",
      "Loss: 1.0339174038116623, epoch: 20000/20000\n",
      "Loss: 0.30110383646377087, epoch: 100/2000\n",
      "Loss: 0.25252967777268504, epoch: 200/2000\n",
      "Loss: 0.26293802324916216, epoch: 300/2000\n",
      "Loss: 0.2537386019151752, epoch: 400/2000\n",
      "Loss: 0.2387572497692735, epoch: 500/2000\n",
      "Loss: 0.2388277892243121, epoch: 600/2000\n",
      "Loss: 0.21635093971817615, epoch: 700/2000\n",
      "Loss: 0.20440961690210777, epoch: 800/2000\n",
      "Loss: 0.2039636242032265, epoch: 900/2000\n",
      "Loss: 0.21051060724985918, epoch: 1000/2000\n",
      "Loss: 0.15162421266971296, epoch: 1100/2000\n",
      "Loss: 0.1571668826589629, epoch: 1200/2000\n",
      "Loss: 0.21456297646196343, epoch: 1300/2000\n",
      "Loss: 0.2532060118272582, epoch: 1400/2000\n",
      "Loss: 0.2537572381698904, epoch: 1500/2000\n",
      "Loss: 0.17197869658633372, epoch: 1600/2000\n",
      "Loss: 0.21863136129160982, epoch: 1700/2000\n",
      "Loss: 0.30630797081294225, epoch: 1800/2000\n",
      "Loss: 0.2511534892156921, epoch: 1900/2000\n",
      "Loss: 0.26905452665780116, epoch: 2000/2000\n",
      "Loss: 0.743417602454851, epoch: 20000/20000\n",
      "Loss: 0.25077580046467507, epoch: 100/2000\n",
      "Loss: 0.17808808585472863, epoch: 200/2000\n",
      "Loss: 0.22610005501440317, epoch: 300/2000\n",
      "Loss: 0.17157315961802205, epoch: 400/2000\n",
      "Loss: 0.19860577474708524, epoch: 500/2000\n",
      "Loss: 0.2452876067970288, epoch: 600/2000\n",
      "Loss: 0.13016298276807559, epoch: 700/2000\n",
      "Loss: 0.2942868843962433, epoch: 800/2000\n",
      "Loss: 0.16697710742886157, epoch: 900/2000\n",
      "Loss: 0.18577212172357596, epoch: 1000/2000\n",
      "Loss: 0.17153104236019381, epoch: 1100/2000\n",
      "Loss: 0.16219906093870454, epoch: 1200/2000\n",
      "Loss: 0.15004813629498784, epoch: 1300/2000\n",
      "Loss: 0.18414284913418194, epoch: 1400/2000\n",
      "Loss: 0.1784164173348847, epoch: 1500/2000\n",
      "Loss: 0.14041583620801218, epoch: 1600/2000\n",
      "Loss: 0.15014228983327477, epoch: 1700/2000\n",
      "Loss: 0.18553445045367872, epoch: 1800/2000\n",
      "Loss: 0.20738220216047343, epoch: 1900/2000\n",
      "Loss: 0.18079462134402766, epoch: 2000/2000\n",
      "Loss: 0.46176485840142084, epoch: 20000/20000\n",
      "Loss: 0.23171401162684177, epoch: 100/2000\n",
      "Loss: 0.2365253751672764, epoch: 200/2000\n",
      "Loss: 0.23011545441830247, epoch: 300/2000\n",
      "Loss: 0.2059936051078604, epoch: 400/2000\n",
      "Loss: 0.260706730447288, epoch: 500/2000\n",
      "Loss: 0.2332087172114982, epoch: 600/2000\n",
      "Loss: 0.21661293338238424, epoch: 700/2000\n",
      "Loss: 0.21400169441957284, epoch: 800/2000\n",
      "Loss: 0.22335591790268666, epoch: 900/2000\n",
      "Loss: 0.21242513789754636, epoch: 1000/2000\n",
      "Loss: 0.19982260570188798, epoch: 1100/2000\n",
      "Loss: 0.20336237195548307, epoch: 1200/2000\n",
      "Loss: 0.2429006743665231, epoch: 1300/2000\n",
      "Loss: 0.19652138919637316, epoch: 1400/2000\n",
      "Loss: 0.21256758316561827, epoch: 1500/2000\n",
      "Loss: 0.22956658264265578, epoch: 1600/2000\n",
      "Loss: 0.20010991083094667, epoch: 1700/2000\n",
      "Loss: 0.20006322707700414, epoch: 1800/2000\n",
      "Loss: 0.2122710090438345, epoch: 1900/2000\n",
      "Loss: 0.21708489747562854, epoch: 2000/2000\n",
      "Loss: 0.6089822295589742, epoch: 20000/20000\n",
      "Loss: 0.20142631758036025, epoch: 100/2000\n",
      "Loss: 0.18424380853864483, epoch: 200/2000\n",
      "Loss: 0.17467802707425126, epoch: 300/2000\n",
      "Loss: 0.16194503401955557, epoch: 400/2000\n",
      "Loss: 0.17479939136774508, epoch: 500/2000\n",
      "Loss: 0.17366881273288068, epoch: 600/2000\n",
      "Loss: 0.19929812957022544, epoch: 700/2000\n",
      "Loss: 0.19131837030848947, epoch: 800/2000\n",
      "Loss: 0.15193004096542406, epoch: 900/2000\n",
      "Loss: 0.15860446301644768, epoch: 1000/2000\n",
      "Loss: 0.155437613217326, epoch: 1100/2000\n",
      "Loss: 0.14407041720720914, epoch: 1200/2000\n",
      "Loss: 0.16136883358896434, epoch: 1300/2000\n",
      "Loss: 0.13235000025306182, epoch: 1400/2000\n",
      "Loss: 0.13123726634002755, epoch: 1500/2000\n",
      "Loss: 0.1344318894138112, epoch: 1600/2000\n",
      "Loss: 0.14140768765612005, epoch: 1700/2000\n",
      "Loss: 0.15026472942992078, epoch: 1800/2000\n",
      "Loss: 0.13262230965894878, epoch: 1900/2000\n",
      "Loss: 0.15950114352033962, epoch: 2000/2000\n",
      "Loss: 0.8652223966587446, epoch: 20000/20000\n",
      "Loss: 0.1614961723902264, epoch: 100/2000\n",
      "Loss: 0.24195034203791893, epoch: 200/2000\n",
      "Loss: 0.22500202139199493, epoch: 300/2000\n",
      "Loss: 0.23222786283007096, epoch: 400/2000\n",
      "Loss: 0.24399009291017898, epoch: 500/2000\n",
      "Loss: 0.15822028501754962, epoch: 600/2000\n",
      "Loss: 0.21530803995862385, epoch: 700/2000\n",
      "Loss: 0.15147315586791593, epoch: 800/2000\n",
      "Loss: 0.23337980731798846, epoch: 900/2000\n",
      "Loss: 0.19836508197692918, epoch: 1000/2000\n",
      "Loss: 0.12823934318130942, epoch: 1100/2000\n",
      "Loss: 0.11019229676462314, epoch: 1200/2000\n",
      "Loss: 0.1286304228474355, epoch: 1300/2000\n",
      "Loss: 0.1986313261355769, epoch: 1400/2000\n",
      "Loss: 0.1105755561026143, epoch: 1500/2000\n",
      "Loss: 0.14259274380058742, epoch: 1600/2000\n",
      "Loss: 0.13038859780431888, epoch: 1700/2000\n",
      "Loss: 0.12349990297758599, epoch: 1800/2000\n",
      "Loss: 0.12472566982993047, epoch: 1900/2000\n",
      "Loss: 0.11501987733518974, epoch: 2000/2000\n",
      "Loss: 0.9474255913206024, epoch: 20000/20000\n",
      "Loss: 0.24286867721077127, epoch: 100/2000\n",
      "Loss: 0.21013852920356063, epoch: 200/2000\n",
      "Loss: 0.20110892965217478, epoch: 300/2000\n",
      "Loss: 0.18917547389763026, epoch: 400/2000\n",
      "Loss: 0.4241127377522769, epoch: 500/2000\n",
      "Loss: 0.18808752934300416, epoch: 600/2000\n",
      "Loss: 0.29125477637220576, epoch: 700/2000\n",
      "Loss: 0.14420626732496772, epoch: 800/2000\n",
      "Loss: 0.1389158940473556, epoch: 900/2000\n",
      "Loss: 0.1857601650367039, epoch: 1000/2000\n",
      "Loss: 0.12041556109891076, epoch: 1100/2000\n",
      "Loss: 0.10580877408716971, epoch: 1200/2000\n",
      "Loss: 0.1045824429287853, epoch: 1300/2000\n",
      "Loss: 0.20627269675657342, epoch: 1400/2000\n",
      "Loss: 0.11322874041925823, epoch: 1500/2000\n",
      "Loss: 0.12799322513266756, epoch: 1600/2000\n",
      "Loss: 0.1847277750379184, epoch: 1700/2000\n",
      "Loss: 0.16898777757461475, epoch: 1800/2000\n",
      "Loss: 0.29198505895295146, epoch: 1900/2000\n",
      "Loss: 0.1874619880127366, epoch: 2000/2000\n",
      "Loss: 0.4241786514578457, epoch: 20000/20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.20520034048422203, epoch: 100/2000\n",
      "Loss: 0.18217505862065636, epoch: 200/2000\n",
      "Loss: 0.23541919389304597, epoch: 300/2000\n",
      "Loss: 0.2501897251601691, epoch: 400/2000\n",
      "Loss: 0.27410779387520595, epoch: 500/2000\n",
      "Loss: 0.2696065721153847, epoch: 600/2000\n",
      "Loss: 0.2742242427114591, epoch: 700/2000\n",
      "Loss: 0.19697203549464984, epoch: 800/2000\n",
      "Loss: 0.30700348981869385, epoch: 900/2000\n",
      "Loss: 0.29952146595573437, epoch: 1000/2000\n",
      "Loss: 0.26506182527764205, epoch: 1100/2000\n",
      "Loss: 0.28713328192390264, epoch: 1200/2000\n",
      "Loss: 0.29027370910047007, epoch: 1300/2000\n",
      "Loss: 0.15928754524238425, epoch: 1400/2000\n",
      "Loss: 0.1631191896428231, epoch: 1500/2000\n",
      "Loss: 0.15566159581503672, epoch: 1600/2000\n",
      "Loss: 0.18418223190753588, epoch: 1700/2000\n",
      "Loss: 0.1405815962972026, epoch: 1800/2000\n",
      "Loss: 0.14824155987643783, epoch: 1900/2000\n",
      "Loss: 0.1587848985573554, epoch: 2000/2000\n",
      "Loss: 0.5096229896221696, epoch: 20000/20000\n",
      "Loss: 0.22345246510001943, epoch: 100/2000\n",
      "Loss: 0.16017754543774712, epoch: 200/2000\n",
      "Loss: 0.17672969359183538, epoch: 300/2000\n",
      "Loss: 0.168276237573252, epoch: 400/2000\n",
      "Loss: 0.1603876411535951, epoch: 500/2000\n",
      "Loss: 0.13717933528446474, epoch: 600/2000\n",
      "Loss: 0.18011795544073664, epoch: 700/2000\n",
      "Loss: 0.12368642424809646, epoch: 800/2000\n",
      "Loss: 0.2634512524458403, epoch: 900/2000\n",
      "Loss: 0.19886758931279416, epoch: 1000/2000\n",
      "Loss: 0.1378642912811548, epoch: 1100/2000\n",
      "Loss: 0.1855195658349213, epoch: 1200/2000\n",
      "Loss: 0.12984612691671674, epoch: 1300/2000\n",
      "Loss: 0.14117917045971834, epoch: 1400/2000\n",
      "Loss: 0.12458943476519886, epoch: 1500/2000\n",
      "Loss: 0.15093194746444308, epoch: 1600/2000\n",
      "Loss: 0.11052809830114345, epoch: 1700/2000\n",
      "Loss: 0.14077359658118463, epoch: 1800/2000\n",
      "Loss: 0.14072993618353027, epoch: 1900/2000\n",
      "Loss: 0.14997488055948308, epoch: 2000/2000\n",
      "Loss: 0.5323088288817938, epoch: 20000/20000\n",
      "Loss: 0.28878810330549626, epoch: 100/2000\n",
      "Loss: 0.16417002242266437, epoch: 200/2000\n",
      "Loss: 0.18026043818957796, epoch: 300/2000\n",
      "Loss: 0.20217820367528283, epoch: 400/2000\n",
      "Loss: 0.10957365907603822, epoch: 500/2000\n",
      "Loss: 0.11850463061540417, epoch: 600/2000\n",
      "Loss: 0.21711495569339556, epoch: 700/2000\n",
      "Loss: 0.1121057283208752, epoch: 800/2000\n",
      "Loss: 0.296768421853519, epoch: 900/2000\n",
      "Loss: 0.24337927024862888, epoch: 1000/2000\n",
      "Loss: 0.21377238392314388, epoch: 1100/2000\n",
      "Loss: 0.20369387055642477, epoch: 1200/2000\n",
      "Loss: 0.2184416025515981, epoch: 1300/2000\n",
      "Loss: 0.22460008554164315, epoch: 1400/2000\n",
      "Loss: 0.13354858494093125, epoch: 1500/2000\n",
      "Loss: 0.13677890482211136, epoch: 1600/2000\n",
      "Loss: 0.230567526726487, epoch: 1700/2000\n",
      "Loss: 0.2354890945936504, epoch: 1800/2000\n",
      "Loss: 0.20845819074325575, epoch: 1900/2000\n",
      "Loss: 0.19745095703930282, epoch: 2000/2000\n",
      "Loss: 0.5254834545098925, epoch: 20000/20000\n",
      "Loss: 0.24229875961673666, epoch: 100/2000\n",
      "Loss: 0.2116949459473807, epoch: 200/2000\n",
      "Loss: 0.3647112426790622, epoch: 300/2000\n",
      "Loss: 0.20423128847555505, epoch: 400/2000\n",
      "Loss: 0.44016820307643734, epoch: 500/2000\n",
      "Loss: 0.20900759467602628, epoch: 600/2000\n",
      "Loss: 0.25969701249937255, epoch: 700/2000\n",
      "Loss: 0.24777819820966088, epoch: 800/2000\n",
      "Loss: 0.2258905285550011, epoch: 900/2000\n",
      "Loss: 0.3824375598381213, epoch: 1000/2000\n",
      "Loss: 0.22741154338804487, epoch: 1100/2000\n",
      "Loss: 0.2791679783663955, epoch: 1200/2000\n",
      "Loss: 0.21040104984571859, epoch: 1300/2000\n",
      "Loss: 0.21157144419419355, epoch: 1400/2000\n",
      "Loss: 0.23784070939985097, epoch: 1500/2000\n",
      "Loss: 0.16929527059404875, epoch: 1600/2000\n",
      "Loss: 0.1683106923265398, epoch: 1700/2000\n",
      "Loss: 0.2402377682715653, epoch: 1800/2000\n",
      "Loss: 0.23029685699340097, epoch: 1900/2000\n",
      "Loss: 0.26138663779777427, epoch: 2000/2000\n",
      "Loss: 1.5580528810890801, epoch: 20000/20000\n",
      "Loss: 0.2808398737581934, epoch: 100/2000\n",
      "Loss: 0.2794823328111667, epoch: 200/2000\n",
      "Loss: 0.273448069645354, epoch: 300/2000\n",
      "Loss: 0.2248490741393792, epoch: 400/2000\n",
      "Loss: 0.19942301778565938, epoch: 500/2000\n",
      "Loss: 0.1908098105731614, epoch: 600/2000\n",
      "Loss: 0.16265493236969814, epoch: 700/2000\n",
      "Loss: 0.1897342290194102, epoch: 800/2000\n",
      "Loss: 0.21608196619879946, epoch: 900/2000\n",
      "Loss: 0.1600480611505525, epoch: 1000/2000\n",
      "Loss: 0.15797782099034824, epoch: 1100/2000\n",
      "Loss: 0.23836608286893038, epoch: 1200/2000\n",
      "Loss: 0.16261751177353595, epoch: 1300/2000\n",
      "Loss: 0.1409329989252613, epoch: 1400/2000\n",
      "Loss: 0.14497946067545725, epoch: 1500/2000\n",
      "Loss: 0.12277352340911563, epoch: 1600/2000\n",
      "Loss: 0.11775532960172949, epoch: 1700/2000\n",
      "Loss: 0.19465948006572206, epoch: 1800/2000\n",
      "Loss: 0.13043574425087356, epoch: 1900/2000\n",
      "Loss: 0.1388830190307766, epoch: 2000/2000\n",
      "Loss: 1.7865215133933074, epoch: 20000/20000\n",
      "Loss: 0.2778472529071229, epoch: 100/2000\n",
      "Loss: 0.2193988161026071, epoch: 200/2000\n",
      "Loss: 0.3114934027179172, epoch: 300/2000\n",
      "Loss: 0.1564553398685216, epoch: 400/2000\n",
      "Loss: 0.16374189421072063, epoch: 500/2000\n",
      "Loss: 0.13551934293333354, epoch: 600/2000\n",
      "Loss: 0.1744269619868617, epoch: 700/2000\n",
      "Loss: 0.2566985161359792, epoch: 800/2000\n",
      "Loss: 0.17047928892359893, epoch: 900/2000\n",
      "Loss: 0.1335007711469724, epoch: 1000/2000\n",
      "Loss: 0.12240113728118278, epoch: 1100/2000\n",
      "Loss: 0.11999278895997478, epoch: 1200/2000\n",
      "Loss: 0.11557856269065217, epoch: 1300/2000\n",
      "Loss: 0.22722973149040754, epoch: 1400/2000\n",
      "Loss: 0.19351181873132406, epoch: 1500/2000\n",
      "Loss: 0.13570680082460762, epoch: 1600/2000\n",
      "Loss: 0.1115845998687254, epoch: 1700/2000\n",
      "Loss: 0.10562629281494237, epoch: 1800/2000\n",
      "Loss: 0.11356334290734638, epoch: 1900/2000\n",
      "Loss: 0.10317189846193067, epoch: 2000/2000\n",
      "Loss: 0.5437889782685759, epoch: 20000/20000\n",
      "Loss: 0.24148551724648176, epoch: 100/2000\n",
      "Loss: 0.22767515930742324, epoch: 200/2000\n",
      "Loss: 0.26758783616984766, epoch: 300/2000\n",
      "Loss: 0.17141762440604383, epoch: 400/2000\n",
      "Loss: 0.331366555847489, epoch: 500/2000\n",
      "Loss: 0.25338623022441176, epoch: 600/2000\n",
      "Loss: 0.2395760208322137, epoch: 700/2000\n",
      "Loss: 0.24295011018790275, epoch: 800/2000\n",
      "Loss: 0.2515086766972624, epoch: 900/2000\n",
      "Loss: 0.2597024303636995, epoch: 1000/2000\n",
      "Loss: 0.22207840765416864, epoch: 1100/2000\n",
      "Loss: 0.23057841288555223, epoch: 1200/2000\n",
      "Loss: 0.2237686812823064, epoch: 1300/2000\n",
      "Loss: 0.1747487265363276, epoch: 1400/2000\n",
      "Loss: 0.2409429352854447, epoch: 1500/2000\n",
      "Loss: 0.25567976441980544, epoch: 1600/2000\n",
      "Loss: 0.20660451990460382, epoch: 1700/2000\n",
      "Loss: 0.2345265348517105, epoch: 1800/2000\n",
      "Loss: 0.16902980866736433, epoch: 1900/2000\n",
      "Loss: 0.13071400401868855, epoch: 2000/2000\n",
      "Loss: 0.5316893566730513, epoch: 20000/20000\n",
      "Loss: 0.25055324863782935, epoch: 100/2000\n",
      "Loss: 0.22189477992288814, epoch: 200/2000\n",
      "Loss: 0.19343019986633866, epoch: 300/2000\n",
      "Loss: 0.20663701865909592, epoch: 400/2000\n",
      "Loss: 0.20138438318367569, epoch: 500/2000\n",
      "Loss: 0.14263702640882053, epoch: 600/2000\n",
      "Loss: 0.22552559243572184, epoch: 700/2000\n",
      "Loss: 0.1965473422452823, epoch: 800/2000\n",
      "Loss: 0.30757202710945303, epoch: 900/2000\n",
      "Loss: 0.16121800115821697, epoch: 1000/2000\n",
      "Loss: 0.15737397946938683, epoch: 1100/2000\n",
      "Loss: 0.13502715940899204, epoch: 1200/2000\n",
      "Loss: 0.13333576118653226, epoch: 1300/2000\n",
      "Loss: 0.16000762030421786, epoch: 1400/2000\n",
      "Loss: 0.1929250681806341, epoch: 1500/2000\n",
      "Loss: 0.14091148160859973, epoch: 1600/2000\n",
      "Loss: 0.1600676648152034, epoch: 1700/2000\n",
      "Loss: 0.13761504735851307, epoch: 1800/2000\n",
      "Loss: 0.14969385760414805, epoch: 1900/2000\n",
      "Loss: 0.15856204026522389, epoch: 2000/2000\n",
      "Loss: 0.3481320389842771, epoch: 20000/20000\n",
      "Loss: 0.2759275282267928, epoch: 100/2000\n",
      "Loss: 0.25445088489700973, epoch: 200/2000\n",
      "Loss: 0.22790651777353776, epoch: 300/2000\n",
      "Loss: 0.23893230568061075, epoch: 400/2000\n",
      "Loss: 0.23638546434776836, epoch: 500/2000\n",
      "Loss: 0.224167523236417, epoch: 600/2000\n",
      "Loss: 0.208191636257409, epoch: 700/2000\n",
      "Loss: 0.22181001041530748, epoch: 800/2000\n",
      "Loss: 0.4337808272461675, epoch: 900/2000\n",
      "Loss: 0.21012795057275988, epoch: 1000/2000\n",
      "Loss: 0.21491046713166737, epoch: 1100/2000\n",
      "Loss: 0.19752970109305945, epoch: 1200/2000\n",
      "Loss: 0.2207613312967768, epoch: 1300/2000\n",
      "Loss: 0.2628652510429189, epoch: 1400/2000\n",
      "Loss: 0.21715548630532738, epoch: 1500/2000\n",
      "Loss: 0.21319434662179848, epoch: 1600/2000\n",
      "Loss: 0.21227878640925493, epoch: 1700/2000\n",
      "Loss: 0.23061077276093514, epoch: 1800/2000\n",
      "Loss: 0.219594170527961, epoch: 1900/2000\n",
      "Loss: 0.20401949660355956, epoch: 2000/2000\n",
      "Loss: 0.44557785032336, epoch: 20000/20000\n",
      "Loss: 0.26119237019057306, epoch: 100/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.23522102574054463, epoch: 200/2000\n",
      "Loss: 0.24665250385335297, epoch: 300/2000\n",
      "Loss: 0.19849107980915226, epoch: 400/2000\n",
      "Loss: 0.23920353477494544, epoch: 500/2000\n",
      "Loss: 0.203590065983904, epoch: 600/2000\n",
      "Loss: 0.2773278021970444, epoch: 700/2000\n",
      "Loss: 0.32617663056765595, epoch: 800/2000\n",
      "Loss: 0.2632875742899804, epoch: 900/2000\n",
      "Loss: 0.2182682278562731, epoch: 1000/2000\n",
      "Loss: 0.2252726635849187, epoch: 1100/2000\n",
      "Loss: 0.24862327285278943, epoch: 1200/2000\n",
      "Loss: 0.24254760437749195, epoch: 1300/2000\n",
      "Loss: 0.3062679594504557, epoch: 1400/2000\n",
      "Loss: 0.2495810280791987, epoch: 1500/2000\n",
      "Loss: 0.21644062059480457, epoch: 1600/2000\n",
      "Loss: 0.2245730149128345, epoch: 1700/2000\n",
      "Loss: 0.22122190058241933, epoch: 1800/2000\n",
      "Loss: 0.21074829901175982, epoch: 1900/2000\n",
      "Loss: 0.2248999558862403, epoch: 2000/2000\n",
      "Loss: 0.6537083973260203, epoch: 20000/20000\n",
      "Loss: 0.3488064782790869, epoch: 100/2000\n",
      "Loss: 0.3099653602421818, epoch: 200/2000\n",
      "Loss: 0.20816161070418854, epoch: 300/2000\n",
      "Loss: 0.18748496973119075, epoch: 400/2000\n",
      "Loss: 0.14331203470487258, epoch: 500/2000\n",
      "Loss: 0.18907732496118504, epoch: 600/2000\n",
      "Loss: 0.3249775160998054, epoch: 700/2000\n",
      "Loss: 0.20580898759259117, epoch: 800/2000\n",
      "Loss: 0.18221616826616877, epoch: 900/2000\n",
      "Loss: 0.21301135576832664, epoch: 1000/2000\n",
      "Loss: 0.21340895859517253, epoch: 1100/2000\n",
      "Loss: 0.19769718736133896, epoch: 1200/2000\n",
      "Loss: 0.1388056238774903, epoch: 1300/2000\n",
      "Loss: 0.1392070633560723, epoch: 1400/2000\n",
      "Loss: 0.19422525506701896, epoch: 1500/2000\n",
      "Loss: 0.152500700110654, epoch: 1600/2000\n",
      "Loss: 0.14488119228784938, epoch: 1700/2000\n",
      "Loss: 0.1548998871330628, epoch: 1800/2000\n",
      "Loss: 0.16229944819299288, epoch: 1900/2000\n",
      "Loss: 0.1887232969807319, epoch: 2000/2000\n",
      "Loss: 1.0471319015147265, epoch: 20000/20000\n",
      "Loss: 0.26466228478510984, epoch: 100/2000\n",
      "Loss: 0.20731320513934168, epoch: 200/2000\n",
      "Loss: 0.20738216248812233, epoch: 300/2000\n",
      "Loss: 0.22154353953831057, epoch: 400/2000\n",
      "Loss: 0.22988372130937065, epoch: 500/2000\n",
      "Loss: 0.26411225288646706, epoch: 600/2000\n",
      "Loss: 0.2199032806316754, epoch: 700/2000\n",
      "Loss: 0.1673013618272866, epoch: 800/2000\n",
      "Loss: 0.21036150131938966, epoch: 900/2000\n",
      "Loss: 0.19784179505178362, epoch: 1000/2000\n",
      "Loss: 0.20909821652566563, epoch: 1100/2000\n",
      "Loss: 0.26566138087845664, epoch: 1200/2000\n",
      "Loss: 0.2770186689593973, epoch: 1300/2000\n",
      "Loss: 0.19166629774905677, epoch: 1400/2000\n",
      "Loss: 0.20152056081784897, epoch: 1500/2000\n",
      "Loss: 0.1576834754846971, epoch: 1600/2000\n",
      "Loss: 0.16653998675077486, epoch: 1700/2000\n",
      "Loss: 0.14557549193722097, epoch: 1800/2000\n",
      "Loss: 0.17821758840024682, epoch: 1900/2000\n",
      "Loss: 0.15782518511131066, epoch: 2000/2000\n",
      "Loss: 0.4022164234220016, epoch: 20000/20000\n",
      "Loss: 0.2296975985629485, epoch: 100/2000\n",
      "Loss: 0.17523573956752128, epoch: 200/2000\n",
      "Loss: 0.20957765239639067, epoch: 300/2000\n",
      "Loss: 0.23564414446289778, epoch: 400/2000\n",
      "Loss: 0.3387455405804218, epoch: 500/2000\n",
      "Loss: 0.2433147111821469, epoch: 600/2000\n",
      "Loss: 0.21474444990371513, epoch: 700/2000\n",
      "Loss: 0.2227571017539851, epoch: 800/2000\n",
      "Loss: 0.2471843002377891, epoch: 900/2000\n",
      "Loss: 0.26522274718896205, epoch: 1000/2000\n",
      "Loss: 0.23794198682449377, epoch: 1100/2000\n",
      "Loss: 0.24865017142956006, epoch: 1200/2000\n",
      "Loss: 0.23816743541882, epoch: 1300/2000\n",
      "Loss: 0.2406592067830966, epoch: 1400/2000\n",
      "Loss: 0.24303720668788725, epoch: 1500/2000\n",
      "Loss: 0.2500468494996013, epoch: 1600/2000\n",
      "Loss: 0.2374140145000005, epoch: 1700/2000\n",
      "Loss: 0.2101680968183084, epoch: 1800/2000\n",
      "Loss: 0.2153426397797066, epoch: 1900/2000\n",
      "Loss: 0.24790047409943453, epoch: 2000/2000\n",
      "Loss: 1.8772129645434519, epoch: 20000/20000\n",
      "Loss: 0.12524266153547514, epoch: 100/2000\n",
      "Loss: 0.17753041522562957, epoch: 200/2000\n",
      "Loss: 0.18492554362351799, epoch: 300/2000\n",
      "Loss: 0.14700632366773042, epoch: 400/2000\n",
      "Loss: 0.18565967815350354, epoch: 500/2000\n",
      "Loss: 0.26615309630021444, epoch: 600/2000\n",
      "Loss: 0.22473097607551687, epoch: 700/2000\n",
      "Loss: 0.3387661952298623, epoch: 800/2000\n",
      "Loss: 0.21566247128846588, epoch: 900/2000\n",
      "Loss: 0.12954587192985864, epoch: 1000/2000\n",
      "Loss: 0.13092409791323512, epoch: 1100/2000\n",
      "Loss: 0.17521941485259468, epoch: 1200/2000\n",
      "Loss: 0.1463356033183743, epoch: 1300/2000\n",
      "Loss: 0.22604480892260098, epoch: 1400/2000\n",
      "Loss: 0.15775208519646494, epoch: 1500/2000\n",
      "Loss: 0.13068044292192857, epoch: 1600/2000\n",
      "Loss: 0.11291951642442988, epoch: 1700/2000\n",
      "Loss: 0.13355037975164083, epoch: 1800/2000\n",
      "Loss: 0.11025892042947567, epoch: 1900/2000\n",
      "Loss: 0.11191967360928201, epoch: 2000/2000\n",
      "Loss: 0.3912437644643245, epoch: 20000/20000\n",
      "Loss: 0.25182947352236706, epoch: 100/2000\n",
      "Loss: 0.22317839031003467, epoch: 200/2000\n",
      "Loss: 0.18822367004417861, epoch: 300/2000\n",
      "Loss: 0.2349646610173047, epoch: 400/2000\n",
      "Loss: 0.32550753172126456, epoch: 500/2000\n",
      "Loss: 0.23495798810345567, epoch: 600/2000\n",
      "Loss: 0.2157497585658997, epoch: 700/2000\n",
      "Loss: 0.17603674962584484, epoch: 800/2000\n",
      "Loss: 0.2390097939910712, epoch: 900/2000\n",
      "Loss: 0.22698398719680862, epoch: 1000/2000\n",
      "Loss: 0.12809009773578772, epoch: 1100/2000\n",
      "Loss: 0.13922990313284003, epoch: 1200/2000\n",
      "Loss: 0.13523944960772466, epoch: 1300/2000\n",
      "Loss: 0.12592413061097463, epoch: 1400/2000\n",
      "Loss: 0.15596761892474414, epoch: 1500/2000\n",
      "Loss: 0.16629195150708237, epoch: 1600/2000\n",
      "Loss: 0.19080357930528263, epoch: 1700/2000\n",
      "Loss: 0.204676660894133, epoch: 1800/2000\n",
      "Loss: 0.15050762051075356, epoch: 1900/2000\n",
      "Loss: 0.22550086651300733, epoch: 2000/2000\n",
      "Loss: 1.0115776371145002, epoch: 20000/20000\n",
      "Loss: 0.127572607730127, epoch: 100/2000\n",
      "Loss: 0.1415928486067814, epoch: 200/2000\n",
      "Loss: 0.2343966360736653, epoch: 300/2000\n",
      "Loss: 0.20764252264288094, epoch: 400/2000\n",
      "Loss: 0.14715025084789754, epoch: 500/2000\n",
      "Loss: 0.14576186576671207, epoch: 600/2000\n",
      "Loss: 0.14353919546583313, epoch: 700/2000\n",
      "Loss: 0.1852778546984168, epoch: 800/2000\n",
      "Loss: 0.16531571390732716, epoch: 900/2000\n",
      "Loss: 0.13683781192516062, epoch: 1000/2000\n",
      "Loss: 0.18951031047433942, epoch: 1100/2000\n",
      "Loss: 0.1819471107288964, epoch: 1200/2000\n",
      "Loss: 0.11529421912174051, epoch: 1300/2000\n",
      "Loss: 0.12250733699338652, epoch: 1400/2000\n",
      "Loss: 0.16114982022440608, epoch: 1500/2000\n",
      "Loss: 0.1812486774444873, epoch: 1600/2000\n",
      "Loss: 0.15734948255942868, epoch: 1700/2000\n",
      "Loss: 0.21398803210202066, epoch: 1800/2000\n",
      "Loss: 0.13958620174367495, epoch: 1900/2000\n",
      "Loss: 0.1663618055241954, epoch: 2000/2000\n",
      "Loss: 1.0270796994265994, epoch: 20000/20000\n",
      "Loss: 0.15791804910811671, epoch: 100/2000\n",
      "Loss: 0.15655317667641833, epoch: 200/2000\n",
      "Loss: 0.16245352419735817, epoch: 300/2000\n",
      "Loss: 0.1814150455296272, epoch: 400/2000\n",
      "Loss: 0.15758235597091946, epoch: 500/2000\n",
      "Loss: 0.15785895386000118, epoch: 600/2000\n",
      "Loss: 0.14814028677731375, epoch: 700/2000\n",
      "Loss: 0.15378235588001601, epoch: 800/2000\n",
      "Loss: 0.13921924556581367, epoch: 900/2000\n",
      "Loss: 0.1616818036267092, epoch: 1000/2000\n",
      "Loss: 0.1344086006880157, epoch: 1100/2000\n",
      "Loss: 0.12311022732375683, epoch: 1200/2000\n",
      "Loss: 0.14706697326416346, epoch: 1300/2000\n",
      "Loss: 0.12622627805552306, epoch: 1400/2000\n",
      "Loss: 0.12270408948508105, epoch: 1500/2000\n",
      "Loss: 0.13983202960270996, epoch: 1600/2000\n",
      "Loss: 0.12066689944506863, epoch: 1700/2000\n",
      "Loss: 0.11888594753225497, epoch: 1800/2000\n",
      "Loss: 0.15879169996414025, epoch: 1900/2000\n",
      "Loss: 0.17107066983067698, epoch: 2000/2000\n",
      "Loss: 1.8189561684027855, epoch: 20000/20000\n",
      "Loss: 0.4264776750203307, epoch: 100/2000\n",
      "Loss: 0.36842270504095187, epoch: 200/2000\n",
      "Loss: 0.33460676666390243, epoch: 300/2000\n",
      "Loss: 0.2740505613618219, epoch: 400/2000\n",
      "Loss: 0.497198662155302, epoch: 500/2000\n",
      "Loss: 0.2766615783981289, epoch: 600/2000\n",
      "Loss: 0.14115307301987995, epoch: 700/2000\n",
      "Loss: 0.16492284375854377, epoch: 800/2000\n",
      "Loss: 0.16466264206634834, epoch: 900/2000\n",
      "Loss: 0.17504295105607454, epoch: 1000/2000\n",
      "Loss: 0.14650258846055447, epoch: 1100/2000\n",
      "Loss: 0.19562146158659505, epoch: 1200/2000\n",
      "Loss: 0.15926467022549673, epoch: 1300/2000\n",
      "Loss: 0.16886204052511627, epoch: 1400/2000\n",
      "Loss: 0.21222273486687956, epoch: 1500/2000\n",
      "Loss: 0.17475585251123793, epoch: 1600/2000\n",
      "Loss: 0.14279164532036678, epoch: 1700/2000\n",
      "Loss: 0.15417352416416258, epoch: 1800/2000\n",
      "Loss: 0.25627975436924566, epoch: 1900/2000\n",
      "Loss: 0.21986617588368182, epoch: 2000/2000\n",
      "Loss: 0.6463060683286115, epoch: 20000/20000\n",
      "Loss: 0.346519739600272, epoch: 100/2000\n",
      "Loss: 0.18258719187732936, epoch: 200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13156992950014987, epoch: 300/2000\n",
      "Loss: 0.14092098938505132, epoch: 400/2000\n",
      "Loss: 0.1919726931801478, epoch: 500/2000\n",
      "Loss: 0.23054112204555594, epoch: 600/2000\n",
      "Loss: 0.16626174152363796, epoch: 700/2000\n",
      "Loss: 0.15137437751174576, epoch: 800/2000\n",
      "Loss: 0.18440768630914686, epoch: 900/2000\n",
      "Loss: 0.12740980422048998, epoch: 1000/2000\n",
      "Loss: 0.10167242664286855, epoch: 1100/2000\n",
      "Loss: 0.1504731668041996, epoch: 1200/2000\n",
      "Loss: 0.11921892539710377, epoch: 1300/2000\n",
      "Loss: 0.14774978416057247, epoch: 1400/2000\n",
      "Loss: 0.1311694460788037, epoch: 1500/2000\n",
      "Loss: 0.1592828516462128, epoch: 1600/2000\n",
      "Loss: 0.16440131547503345, epoch: 1700/2000\n",
      "Loss: 0.14174810367030308, epoch: 1800/2000\n",
      "Loss: 0.1432426969742558, epoch: 1900/2000\n",
      "Loss: 0.13266068392934846, epoch: 2000/2000\n",
      "Loss: 0.43874691730365784, epoch: 20000/20000\n",
      "Loss: 0.14416931882778922, epoch: 100/2000\n",
      "Loss: 0.1714526604961442, epoch: 200/2000\n",
      "Loss: 0.17704330772670876, epoch: 300/2000\n",
      "Loss: 0.13875837789212958, epoch: 400/2000\n",
      "Loss: 0.11629219921435427, epoch: 500/2000\n",
      "Loss: 0.16472838540279983, epoch: 600/2000\n",
      "Loss: 0.13480845405948344, epoch: 700/2000\n",
      "Loss: 0.3076045475873664, epoch: 800/2000\n",
      "Loss: 0.29652011244151677, epoch: 900/2000\n",
      "Loss: 0.18820162712100724, epoch: 1000/2000\n",
      "Loss: 0.14513961029467976, epoch: 1100/2000\n",
      "Loss: 0.13258232619248628, epoch: 1200/2000\n",
      "Loss: 0.14605148589953013, epoch: 1300/2000\n",
      "Loss: 0.11929336287545148, epoch: 1400/2000\n",
      "Loss: 0.12683318866359344, epoch: 1500/2000\n",
      "Loss: 0.11902631133174668, epoch: 1600/2000\n",
      "Loss: 0.14768043820892826, epoch: 1700/2000\n",
      "Loss: 0.2006227246163938, epoch: 1800/2000\n",
      "Loss: 0.15271738837329402, epoch: 1900/2000\n",
      "Loss: 0.1731530552978989, epoch: 2000/2000\n",
      "Loss: 0.42529634616977174, epoch: 20000/20000\n",
      "Loss: 0.31597266333862317, epoch: 100/2000\n",
      "Loss: 0.43469499345020396, epoch: 200/2000\n",
      "Loss: 0.25377925039870763, epoch: 300/2000\n",
      "Loss: 0.3413922908794053, epoch: 400/2000\n",
      "Loss: 0.2825115351637012, epoch: 500/2000\n",
      "Loss: 0.2613867903597126, epoch: 600/2000\n",
      "Loss: 0.20770739107573988, epoch: 700/2000\n",
      "Loss: 0.17781240480372362, epoch: 800/2000\n",
      "Loss: 0.28864054620947266, epoch: 900/2000\n",
      "Loss: 0.29910369732368447, epoch: 1000/2000\n",
      "Loss: 0.27718835655963814, epoch: 1100/2000\n",
      "Loss: 0.2709340052631576, epoch: 1200/2000\n",
      "Loss: 0.14401051199910303, epoch: 1300/2000\n",
      "Loss: 0.24678595399366404, epoch: 1400/2000\n",
      "Loss: 0.16825938143109237, epoch: 1500/2000\n",
      "Loss: 0.14873595458806738, epoch: 1600/2000\n",
      "Loss: 0.25219852693075445, epoch: 1700/2000\n",
      "Loss: 0.1560672869114824, epoch: 1800/2000\n",
      "Loss: 0.14724062276017724, epoch: 1900/2000\n",
      "Loss: 0.1486914717026397, epoch: 2000/2000\n",
      "Loss: 0.6741732945162489, epoch: 20000/20000\n",
      "Loss: 0.18983174047940618, epoch: 100/2000\n",
      "Loss: 0.1276654609700721, epoch: 200/2000\n",
      "Loss: 0.11273591330034123, epoch: 300/2000\n",
      "Loss: 0.15652321662687643, epoch: 400/2000\n",
      "Loss: 0.16759710501657096, epoch: 500/2000\n",
      "Loss: 0.13587637786145484, epoch: 600/2000\n",
      "Loss: 0.1443238194356406, epoch: 700/2000\n",
      "Loss: 0.16081071255135804, epoch: 800/2000\n",
      "Loss: 0.17056250950415203, epoch: 900/2000\n",
      "Loss: 0.207329459529474, epoch: 1000/2000\n",
      "Loss: 0.15263508772774437, epoch: 1100/2000\n",
      "Loss: 0.16951318735418078, epoch: 1200/2000\n",
      "Loss: 0.22493986435696564, epoch: 1300/2000\n",
      "Loss: 0.14831203686182384, epoch: 1400/2000\n",
      "Loss: 0.1650166503821637, epoch: 1500/2000\n",
      "Loss: 0.13933100719092864, epoch: 1600/2000\n",
      "Loss: 0.13391918248705376, epoch: 1700/2000\n",
      "Loss: 0.13901360337162208, epoch: 1800/2000\n",
      "Loss: 0.1441869016321026, epoch: 1900/2000\n",
      "Loss: 0.19607916852363322, epoch: 2000/2000\n",
      "Loss: 0.5198160972491224, epoch: 20000/20000\n",
      "Loss: 0.22917074120610845, epoch: 100/2000\n",
      "Loss: 0.21921553615462813, epoch: 200/2000\n",
      "Loss: 0.19733271628489918, epoch: 300/2000\n",
      "Loss: 0.19875586780075552, epoch: 400/2000\n",
      "Loss: 0.18197061741233916, epoch: 500/2000\n",
      "Loss: 0.1845633908763485, epoch: 600/2000\n",
      "Loss: 0.2203885824307541, epoch: 700/2000\n",
      "Loss: 0.25660568832767894, epoch: 800/2000\n",
      "Loss: 0.19495634087511035, epoch: 900/2000\n",
      "Loss: 0.1973983078899576, epoch: 1000/2000\n",
      "Loss: 0.16258076324822285, epoch: 1100/2000\n",
      "Loss: 0.2007850331992484, epoch: 1200/2000\n",
      "Loss: 0.16736177489587323, epoch: 1300/2000\n",
      "Loss: 0.22301652286216633, epoch: 1400/2000\n",
      "Loss: 0.17482891199856063, epoch: 1500/2000\n",
      "Loss: 0.18253876757949677, epoch: 1600/2000\n",
      "Loss: 0.20443828438116615, epoch: 1700/2000\n",
      "Loss: 0.14654224474237448, epoch: 1800/2000\n",
      "Loss: 0.20075667674648798, epoch: 1900/2000\n",
      "Loss: 0.24343092052141518, epoch: 2000/2000\n",
      "Loss: 0.46923783050813955, epoch: 20000/20000\n",
      "Loss: 0.22616794991128794, epoch: 100/2000\n",
      "Loss: 0.2012620757915701, epoch: 200/2000\n",
      "Loss: 0.2099237644656368, epoch: 300/2000\n",
      "Loss: 0.21290805975806, epoch: 400/2000\n",
      "Loss: 0.36809020081742316, epoch: 500/2000\n",
      "Loss: 0.24344513214086846, epoch: 600/2000\n",
      "Loss: 0.2566304812665408, epoch: 700/2000\n",
      "Loss: 0.22668172846280502, epoch: 800/2000\n",
      "Loss: 0.33223638884460427, epoch: 900/2000\n",
      "Loss: 0.2628678586955619, epoch: 1000/2000\n",
      "Loss: 0.24020833706534614, epoch: 1100/2000\n",
      "Loss: 0.23802789168404162, epoch: 1200/2000\n",
      "Loss: 0.2108877718165063, epoch: 1300/2000\n",
      "Loss: 0.30778894601742557, epoch: 1400/2000\n",
      "Loss: 0.25850310751786937, epoch: 1500/2000\n",
      "Loss: 0.23264807198009949, epoch: 1600/2000\n",
      "Loss: 0.22086436340719837, epoch: 1700/2000\n",
      "Loss: 0.2241602273127839, epoch: 1800/2000\n",
      "Loss: 0.22249638695866142, epoch: 1900/2000\n",
      "Loss: 0.25878155653032137, epoch: 2000/2000\n",
      "Loss: 0.8354242854101723, epoch: 20000/20000\n",
      "Loss: 0.37366846251207925, epoch: 100/2000\n",
      "Loss: 0.27208165835216774, epoch: 200/2000\n",
      "Loss: 0.2504234889770851, epoch: 300/2000\n",
      "Loss: 0.21946439427731695, epoch: 400/2000\n",
      "Loss: 0.20660059593554897, epoch: 500/2000\n",
      "Loss: 0.15677509426077268, epoch: 600/2000\n",
      "Loss: 0.15288492113776653, epoch: 700/2000\n",
      "Loss: 0.1827354485451445, epoch: 800/2000\n",
      "Loss: 0.15834163809722918, epoch: 900/2000\n",
      "Loss: 0.2208522577610562, epoch: 1000/2000\n",
      "Loss: 0.16931945474916624, epoch: 1100/2000\n",
      "Loss: 0.17141685030707238, epoch: 1200/2000\n",
      "Loss: 0.20796248300835846, epoch: 1300/2000\n",
      "Loss: 0.1705571070635808, epoch: 1400/2000\n",
      "Loss: 0.17300055624418834, epoch: 1500/2000\n",
      "Loss: 0.14725490084028203, epoch: 1600/2000\n",
      "Loss: 0.14172567312355874, epoch: 1700/2000\n",
      "Loss: 0.13001537016880987, epoch: 1800/2000\n",
      "Loss: 0.1509181468120741, epoch: 1900/2000\n",
      "Loss: 0.13550375612621685, epoch: 2000/2000\n",
      "Loss: 0.8437443386497568, epoch: 20000/20000\n",
      "Loss: 0.2160066803767185, epoch: 100/2000\n",
      "Loss: 0.23996368809484933, epoch: 200/2000\n",
      "Loss: 0.17170859235047037, epoch: 300/2000\n",
      "Loss: 0.14262500811718146, epoch: 400/2000\n",
      "Loss: 0.2081187440799333, epoch: 500/2000\n",
      "Loss: 0.20220187399449646, epoch: 600/2000\n",
      "Loss: 0.14626139424535128, epoch: 700/2000\n",
      "Loss: 0.18240373687025782, epoch: 800/2000\n",
      "Loss: 0.1450415354220504, epoch: 900/2000\n",
      "Loss: 0.2967949162261069, epoch: 1000/2000\n",
      "Loss: 0.27628393594581596, epoch: 1100/2000\n",
      "Loss: 0.25208840942217575, epoch: 1200/2000\n",
      "Loss: 0.2770811539756788, epoch: 1300/2000\n",
      "Loss: 0.24832590880559283, epoch: 1400/2000\n",
      "Loss: 0.24362704076917044, epoch: 1500/2000\n",
      "Loss: 0.20843788017788034, epoch: 1600/2000\n",
      "Loss: 0.1705414266350767, epoch: 1700/2000\n",
      "Loss: 0.12450550648285244, epoch: 1800/2000\n",
      "Loss: 0.13023573671067748, epoch: 1900/2000\n",
      "Loss: 0.15586042897306907, epoch: 2000/2000\n",
      "Loss: 0.6206152720272327, epoch: 20000/20000\n",
      "Loss: 0.20753936005925983, epoch: 100/2000\n",
      "Loss: 0.2145231839583123, epoch: 200/2000\n",
      "Loss: 0.14863428421789732, epoch: 300/2000\n",
      "Loss: 0.1711852111586122, epoch: 400/2000\n",
      "Loss: 0.16864687864197997, epoch: 500/2000\n",
      "Loss: 0.17308730403220754, epoch: 600/2000\n",
      "Loss: 0.1750757655897542, epoch: 700/2000\n",
      "Loss: 0.15390778583062187, epoch: 800/2000\n",
      "Loss: 0.17955206048903635, epoch: 900/2000\n",
      "Loss: 0.1533358667960913, epoch: 1000/2000\n",
      "Loss: 0.15385738364936413, epoch: 1100/2000\n",
      "Loss: 0.16411606587653377, epoch: 1200/2000\n",
      "Loss: 0.14010972155294116, epoch: 1300/2000\n",
      "Loss: 0.1427630296798852, epoch: 1400/2000\n",
      "Loss: 0.11597405175110154, epoch: 1500/2000\n",
      "Loss: 0.13802371836397873, epoch: 1600/2000\n",
      "Loss: 0.14946293254790533, epoch: 1700/2000\n",
      "Loss: 0.15134730733533164, epoch: 1800/2000\n",
      "Loss: 0.14058790006112362, epoch: 1900/2000\n",
      "Loss: 0.13668675383927692, epoch: 2000/2000\n",
      "Loss: 0.4538187047455131, epoch: 20000/20000\n",
      "Loss: 0.18682080687276315, epoch: 100/2000\n",
      "Loss: 0.15937471067185696, epoch: 200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.18282700623131415, epoch: 300/2000\n",
      "Loss: 0.13029484862409066, epoch: 400/2000\n",
      "Loss: 0.2074860267661367, epoch: 500/2000\n",
      "Loss: 0.1583964038956625, epoch: 600/2000\n",
      "Loss: 0.15143726127970297, epoch: 700/2000\n",
      "Loss: 0.17415325166668713, epoch: 800/2000\n",
      "Loss: 0.15491667523065217, epoch: 900/2000\n",
      "Loss: 0.2397127616838683, epoch: 1000/2000\n",
      "Loss: 0.18349260707858342, epoch: 1100/2000\n",
      "Loss: 0.13842688348593307, epoch: 1200/2000\n",
      "Loss: 0.12179281309512802, epoch: 1300/2000\n",
      "Loss: 0.22252087830283376, epoch: 1400/2000\n",
      "Loss: 0.15840019854741624, epoch: 1500/2000\n",
      "Loss: 0.19512944494289514, epoch: 1600/2000\n",
      "Loss: 0.2263850815880967, epoch: 1700/2000\n",
      "Loss: 0.24080184640636912, epoch: 1800/2000\n",
      "Loss: 0.2547519572926033, epoch: 1900/2000\n",
      "Loss: 0.24617485107390946, epoch: 2000/2000\n",
      "Loss: 0.569923524436482, epoch: 20000/20000\n",
      "Loss: 0.16964159001317491, epoch: 100/2000\n",
      "Loss: 0.2210728292082325, epoch: 200/2000\n",
      "Loss: 0.18969343333793426, epoch: 300/2000\n",
      "Loss: 0.20303969134194708, epoch: 400/2000\n",
      "Loss: 0.2126423873468263, epoch: 500/2000\n",
      "Loss: 0.16589129590852955, epoch: 600/2000\n",
      "Loss: 0.28710372211997137, epoch: 700/2000\n",
      "Loss: 0.2883394874109031, epoch: 800/2000\n",
      "Loss: 0.14742846238663793, epoch: 900/2000\n",
      "Loss: 0.1894123195200919, epoch: 1000/2000\n",
      "Loss: 0.192525153190252, epoch: 1100/2000\n",
      "Loss: 0.2038549632915235, epoch: 1200/2000\n",
      "Loss: 0.1816136735112655, epoch: 1300/2000\n",
      "Loss: 0.24543824866915812, epoch: 1400/2000\n",
      "Loss: 0.2120129702316565, epoch: 1500/2000\n",
      "Loss: 0.14637134415944728, epoch: 1600/2000\n",
      "Loss: 0.2097983813216541, epoch: 1700/2000\n",
      "Loss: 0.17703776978794067, epoch: 1800/2000\n",
      "Loss: 0.17327751037796654, epoch: 1900/2000\n",
      "Loss: 0.15528823136538894, epoch: 2000/2000\n",
      "Loss: 1.9011503001948173, epoch: 20000/20000\n",
      "Loss: 0.3270648585484735, epoch: 100/2000\n",
      "Loss: 0.3241596388684561, epoch: 200/2000\n",
      "Loss: 0.23332437149139432, epoch: 300/2000\n",
      "Loss: 0.1296986976883347, epoch: 400/2000\n",
      "Loss: 0.3101817039670287, epoch: 500/2000\n",
      "Loss: 0.14228879197473085, epoch: 600/2000\n",
      "Loss: 0.31257263558756326, epoch: 700/2000\n",
      "Loss: 0.2170415165519767, epoch: 800/2000\n",
      "Loss: 0.1337656931056255, epoch: 900/2000\n",
      "Loss: 0.14437887947639896, epoch: 1000/2000\n",
      "Loss: 0.10755996745140169, epoch: 1100/2000\n",
      "Loss: 0.11455571821870987, epoch: 1200/2000\n",
      "Loss: 0.10111276108856619, epoch: 1300/2000\n",
      "Loss: 0.12542449951841234, epoch: 1400/2000\n",
      "Loss: 0.1704591811250011, epoch: 1500/2000\n",
      "Loss: 0.2911553302379916, epoch: 1600/2000\n",
      "Loss: 0.24398821941843885, epoch: 1700/2000\n",
      "Loss: 0.19133721200145887, epoch: 1800/2000\n",
      "Loss: 0.1614611557494269, epoch: 1900/2000\n",
      "Loss: 0.14249592394365457, epoch: 2000/2000\n",
      "Loss: 0.8624497408391886, epoch: 20000/20000\n",
      "Loss: 0.23216390291115277, epoch: 100/2000\n",
      "Loss: 0.22025019124854667, epoch: 200/2000\n",
      "Loss: 0.4481715814817071, epoch: 300/2000\n",
      "Loss: 0.2903816744608353, epoch: 400/2000\n",
      "Loss: 0.23699135129607152, epoch: 500/2000\n",
      "Loss: 0.158112818006598, epoch: 600/2000\n",
      "Loss: 0.12244837399888678, epoch: 700/2000\n",
      "Loss: 0.2354207243982011, epoch: 800/2000\n",
      "Loss: 0.20863874569625226, epoch: 900/2000\n",
      "Loss: 0.22113624862184428, epoch: 1000/2000\n",
      "Loss: 0.20978352474224388, epoch: 1100/2000\n",
      "Loss: 0.1692846791001526, epoch: 1200/2000\n",
      "Loss: 0.11369143315044491, epoch: 1300/2000\n",
      "Loss: 0.13786025293826487, epoch: 1400/2000\n",
      "Loss: 0.1906803644043422, epoch: 1500/2000\n",
      "Loss: 0.11526442011081624, epoch: 1600/2000\n",
      "Loss: 0.12671557685351245, epoch: 1700/2000\n",
      "Loss: 0.10294681889074135, epoch: 1800/2000\n",
      "Loss: 0.1871873193779369, epoch: 1900/2000\n",
      "Loss: 0.18620824110634362, epoch: 2000/2000\n",
      "Loss: 0.544767572711557, epoch: 20000/20000\n",
      "Loss: 0.21302191268325582, epoch: 100/2000\n",
      "Loss: 0.2233776215374112, epoch: 200/2000\n",
      "Loss: 0.2048831749845872, epoch: 300/2000\n",
      "Loss: 0.15399121853234005, epoch: 400/2000\n",
      "Loss: 0.17924763195332435, epoch: 500/2000\n",
      "Loss: 0.11943777297704014, epoch: 600/2000\n",
      "Loss: 0.1964528793979837, epoch: 700/2000\n",
      "Loss: 0.15042511329207084, epoch: 800/2000\n",
      "Loss: 0.20848687862612897, epoch: 900/2000\n",
      "Loss: 0.22730606734577977, epoch: 1000/2000\n",
      "Loss: 0.18389093911948956, epoch: 1100/2000\n",
      "Loss: 0.20570398517208122, epoch: 1200/2000\n",
      "Loss: 0.1469430171412076, epoch: 1300/2000\n",
      "Loss: 0.20122427747084548, epoch: 1400/2000\n",
      "Loss: 0.2317840811996014, epoch: 1500/2000\n",
      "Loss: 0.19739690054778264, epoch: 1600/2000\n",
      "Loss: 0.22935445445835714, epoch: 1700/2000\n",
      "Loss: 0.1991194764881976, epoch: 1800/2000\n",
      "Loss: 0.1932858791755027, epoch: 1900/2000\n",
      "Loss: 0.1166535436036703, epoch: 2000/2000\n",
      "Loss: 0.6860875105488624, epoch: 20000/20000\n",
      "Loss: 0.19776876180969793, epoch: 100/2000\n",
      "Loss: 0.20795202318656486, epoch: 200/2000\n",
      "Loss: 0.21794592642265437, epoch: 300/2000\n",
      "Loss: 0.17402533803819026, epoch: 400/2000\n",
      "Loss: 0.17947742093710467, epoch: 500/2000\n",
      "Loss: 0.1648741734535613, epoch: 600/2000\n",
      "Loss: 0.1694161575206653, epoch: 700/2000\n",
      "Loss: 0.14921913304524032, epoch: 800/2000\n",
      "Loss: 0.15046556887091453, epoch: 900/2000\n",
      "Loss: 0.16029102447216592, epoch: 1000/2000\n",
      "Loss: 0.1378330084037128, epoch: 1100/2000\n",
      "Loss: 0.12202100851472766, epoch: 1200/2000\n",
      "Loss: 0.14125186129940379, epoch: 1300/2000\n",
      "Loss: 0.13403204198189672, epoch: 1400/2000\n",
      "Loss: 0.13274928478603662, epoch: 1500/2000\n",
      "Loss: 0.17611837420928128, epoch: 1600/2000\n",
      "Loss: 0.12652773861458044, epoch: 1700/2000\n",
      "Loss: 0.12652917295752192, epoch: 1800/2000\n",
      "Loss: 0.16233417459044533, epoch: 1900/2000\n",
      "Loss: 0.16184015966441573, epoch: 2000/2000\n",
      "Loss: 0.5985490251360673, epoch: 20000/20000\n",
      "Loss: 0.1965592654694544, epoch: 100/2000\n",
      "Loss: 0.18633982364583612, epoch: 200/2000\n",
      "Loss: 0.1851181558374485, epoch: 300/2000\n",
      "Loss: 0.1638032688788813, epoch: 400/2000\n",
      "Loss: 0.15291625995216324, epoch: 500/2000\n",
      "Loss: 0.1670409129143533, epoch: 600/2000\n",
      "Loss: 0.13835439971638056, epoch: 700/2000\n",
      "Loss: 0.1418131766449028, epoch: 800/2000\n",
      "Loss: 0.18522661760772346, epoch: 900/2000\n",
      "Loss: 0.17744631533289812, epoch: 1000/2000\n",
      "Loss: 0.21248488753243197, epoch: 1100/2000\n",
      "Loss: 0.21058433215527575, epoch: 1200/2000\n",
      "Loss: 0.17187756965286094, epoch: 1300/2000\n",
      "Loss: 0.18414804584811578, epoch: 1400/2000\n",
      "Loss: 0.16951548985273168, epoch: 1500/2000\n",
      "Loss: 0.21655917829753676, epoch: 1600/2000\n",
      "Loss: 0.1815408711506438, epoch: 1700/2000\n",
      "Loss: 0.20198673843412, epoch: 1800/2000\n",
      "Loss: 0.2540602000629292, epoch: 1900/2000\n",
      "Loss: 0.15090351357837567, epoch: 2000/2000\n",
      "Loss: 1.732880193746776, epoch: 20000/20000\n",
      "Loss: 0.25796534882710376, epoch: 100/2000\n",
      "Loss: 0.21710695222573967, epoch: 200/2000\n",
      "Loss: 0.2206132474333696, epoch: 300/2000\n",
      "Loss: 0.14933597757234915, epoch: 400/2000\n",
      "Loss: 0.27983892433577473, epoch: 500/2000\n",
      "Loss: 0.1346134140670737, epoch: 600/2000\n",
      "Loss: 0.1186180226930684, epoch: 700/2000\n",
      "Loss: 0.13492852384812998, epoch: 800/2000\n",
      "Loss: 0.12296457396088019, epoch: 900/2000\n",
      "Loss: 0.13270430639842828, epoch: 1000/2000\n",
      "Loss: 0.11014381210109869, epoch: 1100/2000\n",
      "Loss: 0.1333891068784542, epoch: 1200/2000\n",
      "Loss: 0.1896949910519255, epoch: 1300/2000\n",
      "Loss: 0.20342829306648133, epoch: 1400/2000\n",
      "Loss: 0.18623634425213267, epoch: 1500/2000\n",
      "Loss: 0.18169894072201107, epoch: 1600/2000\n",
      "Loss: 0.1341957754065803, epoch: 1700/2000\n",
      "Loss: 0.1439758245204583, epoch: 1800/2000\n",
      "Loss: 0.11155904828135117, epoch: 1900/2000\n",
      "Loss: 0.13202713864667912, epoch: 2000/2000\n",
      "Loss: 0.7510530719978983, epoch: 20000/20000\n",
      "Loss: 0.17449190237523415, epoch: 100/2000\n",
      "Loss: 0.18252576080575256, epoch: 200/2000\n",
      "Loss: 0.18515390634745996, epoch: 300/2000\n",
      "Loss: 0.1826928984477021, epoch: 400/2000\n",
      "Loss: 0.17171897406751024, epoch: 500/2000\n",
      "Loss: 0.1732124971500713, epoch: 600/2000\n",
      "Loss: 0.13288867133910495, epoch: 700/2000\n",
      "Loss: 0.12685351632596667, epoch: 800/2000\n",
      "Loss: 0.1162718163206985, epoch: 900/2000\n",
      "Loss: 0.1678263828526176, epoch: 1000/2000\n",
      "Loss: 0.15753975504508091, epoch: 1100/2000\n",
      "Loss: 0.1923211308108901, epoch: 1200/2000\n",
      "Loss: 0.210774050351871, epoch: 1300/2000\n",
      "Loss: 0.23962373935836112, epoch: 1400/2000\n",
      "Loss: 0.18883378145929705, epoch: 1500/2000\n",
      "Loss: 0.23936095816836112, epoch: 1600/2000\n",
      "Loss: 0.2326838003508299, epoch: 1700/2000\n",
      "Loss: 0.22458760080764112, epoch: 1800/2000\n",
      "Loss: 0.17803453070107547, epoch: 1900/2000\n",
      "Loss: 0.23119687622728566, epoch: 2000/2000\n",
      "Loss: 0.44726314860084526, epoch: 20000/20000\n",
      "Loss: 0.2806868678710298, epoch: 100/2000\n",
      "Loss: 0.21451996139821836, epoch: 200/2000\n",
      "Loss: 0.29097765248792806, epoch: 300/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.27849550983112326, epoch: 400/2000\n",
      "Loss: 0.24647075974194896, epoch: 500/2000\n",
      "Loss: 0.31234966967299127, epoch: 600/2000\n",
      "Loss: 0.22315613858155828, epoch: 700/2000\n",
      "Loss: 0.2331520236686157, epoch: 800/2000\n",
      "Loss: 0.23378536907173858, epoch: 900/2000\n",
      "Loss: 0.36700929157978357, epoch: 1000/2000\n",
      "Loss: 0.27872614377494537, epoch: 1100/2000\n",
      "Loss: 0.24323632851001253, epoch: 1200/2000\n",
      "Loss: 0.21028316447009487, epoch: 1300/2000\n",
      "Loss: 0.2598333128761773, epoch: 1400/2000\n",
      "Loss: 0.21330964507477068, epoch: 1500/2000\n",
      "Loss: 0.22404994224189506, epoch: 1600/2000\n",
      "Loss: 0.23039462719667814, epoch: 1700/2000\n",
      "Loss: 0.22756432874640747, epoch: 1800/2000\n",
      "Loss: 0.22514095868259854, epoch: 1900/2000\n",
      "Loss: 0.20367754249109865, epoch: 2000/2000\n",
      "Loss: 1.8608081126178875, epoch: 20000/20000\n",
      "Loss: 0.2485665749718325, epoch: 100/2000\n",
      "Loss: 0.20865985781770452, epoch: 200/2000\n",
      "Loss: 0.15959774820551167, epoch: 300/2000\n",
      "Loss: 0.14791509858410917, epoch: 400/2000\n",
      "Loss: 0.1914439482838449, epoch: 500/2000\n",
      "Loss: 0.2602646778039156, epoch: 600/2000\n",
      "Loss: 0.18796312659351624, epoch: 700/2000\n",
      "Loss: 0.2722716156222254, epoch: 800/2000\n",
      "Loss: 0.26101795258117744, epoch: 900/2000\n",
      "Loss: 0.1931670257989643, epoch: 1000/2000\n",
      "Loss: 0.25474807854695974, epoch: 1100/2000\n",
      "Loss: 0.1825506564640643, epoch: 1200/2000\n",
      "Loss: 0.1460532443185747, epoch: 1300/2000\n",
      "Loss: 0.15035317153780503, epoch: 1400/2000\n",
      "Loss: 0.20812078646684493, epoch: 1500/2000\n",
      "Loss: 0.1801879420635534, epoch: 1600/2000\n",
      "Loss: 0.17026816326902078, epoch: 1700/2000\n",
      "Loss: 0.1870752748036465, epoch: 1800/2000\n",
      "Loss: 0.15738289719036547, epoch: 1900/2000\n",
      "Loss: 0.23930332645078667, epoch: 2000/2000\n",
      "Loss: 0.49422742490111826, epoch: 20000/20000\n",
      "Loss: 0.3448142669141727, epoch: 100/2000\n",
      "Loss: 0.32883732635304586, epoch: 200/2000\n",
      "Loss: 0.202642065951601, epoch: 300/2000\n",
      "Loss: 0.20542294390287713, epoch: 400/2000\n",
      "Loss: 0.20145272316966517, epoch: 500/2000\n",
      "Loss: 0.31301500715231456, epoch: 600/2000\n",
      "Loss: 0.31093338644018914, epoch: 700/2000\n",
      "Loss: 0.1791165172741774, epoch: 800/2000\n",
      "Loss: 0.21380404682985454, epoch: 900/2000\n",
      "Loss: 0.28198693464189356, epoch: 1000/2000\n",
      "Loss: 0.2562904718721063, epoch: 1100/2000\n",
      "Loss: 0.1843141188137964, epoch: 1200/2000\n",
      "Loss: 0.17871369912843407, epoch: 1300/2000\n",
      "Loss: 0.19549100277250084, epoch: 1400/2000\n",
      "Loss: 0.21721942072627795, epoch: 1500/2000\n",
      "Loss: 0.27347295548165984, epoch: 1600/2000\n",
      "Loss: 0.2022165783676552, epoch: 1700/2000\n",
      "Loss: 0.24133032113953684, epoch: 1800/2000\n",
      "Loss: 0.21907587705751683, epoch: 1900/2000\n",
      "Loss: 0.2216145139639484, epoch: 2000/2000\n",
      "Loss: 0.45295113955504684, epoch: 20000/20000\n",
      "Loss: 0.17578251657309546, epoch: 100/2000\n",
      "Loss: 0.13456349162795816, epoch: 200/2000\n",
      "Loss: 0.16664741254849985, epoch: 300/2000\n",
      "Loss: 0.22310333496792523, epoch: 400/2000\n",
      "Loss: 0.15540929219423427, epoch: 500/2000\n",
      "Loss: 0.1859742637479586, epoch: 600/2000\n",
      "Loss: 0.2626916517475365, epoch: 700/2000\n",
      "Loss: 0.21205888203497114, epoch: 800/2000\n",
      "Loss: 0.2296478205195735, epoch: 900/2000\n",
      "Loss: 0.2738961203823162, epoch: 1000/2000\n",
      "Loss: 0.1189470864031982, epoch: 1100/2000\n",
      "Loss: 0.2420656328080839, epoch: 1200/2000\n",
      "Loss: 0.14771007928325403, epoch: 1300/2000\n",
      "Loss: 0.17836191576331656, epoch: 1400/2000\n",
      "Loss: 0.19455230687527938, epoch: 1500/2000\n",
      "Loss: 0.23101826661486316, epoch: 1600/2000\n",
      "Loss: 0.27514194720720486, epoch: 1700/2000\n",
      "Loss: 0.27729968100914365, epoch: 1800/2000\n",
      "Loss: 0.21939357747249738, epoch: 1900/2000\n",
      "Loss: 0.16854772049723804, epoch: 2000/2000\n",
      "Loss: 1.7491564032115918, epoch: 20000/20000\n",
      "Loss: 0.21724663884980183, epoch: 100/2000\n",
      "Loss: 0.18940545951559393, epoch: 200/2000\n",
      "Loss: 0.22407390724139473, epoch: 300/2000\n",
      "Loss: 0.36224934960824967, epoch: 400/2000\n",
      "Loss: 0.24929031198686583, epoch: 500/2000\n",
      "Loss: 0.2963754634405194, epoch: 600/2000\n",
      "Loss: 0.22078893159311042, epoch: 700/2000\n",
      "Loss: 0.17826343591074137, epoch: 800/2000\n",
      "Loss: 0.13174710282797686, epoch: 900/2000\n",
      "Loss: 0.13383805944887003, epoch: 1000/2000\n",
      "Loss: 0.10463364235886655, epoch: 1100/2000\n",
      "Loss: 0.1316591158322881, epoch: 1200/2000\n",
      "Loss: 0.10655064200895972, epoch: 1300/2000\n",
      "Loss: 0.12037776886450476, epoch: 1400/2000\n",
      "Loss: 0.13645491552810698, epoch: 1500/2000\n",
      "Loss: 0.24362357184727174, epoch: 1600/2000\n",
      "Loss: 0.1054094350500819, epoch: 1700/2000\n",
      "Loss: 0.11086788168234159, epoch: 1800/2000\n",
      "Loss: 0.18542240571498703, epoch: 1900/2000\n",
      "Loss: 0.19682427962894597, epoch: 2000/2000\n",
      "Loss: 1.8745443879902048, epoch: 20000/20000\n",
      "Loss: 0.23833482795663846, epoch: 100/2000\n",
      "Loss: 0.31643024072877257, epoch: 200/2000\n",
      "Loss: 0.20970004754773122, epoch: 300/2000\n",
      "Loss: 0.21394028906818016, epoch: 400/2000\n",
      "Loss: 0.24638029462339053, epoch: 500/2000\n",
      "Loss: 0.27118022037493916, epoch: 600/2000\n",
      "Loss: 0.3154564186617313, epoch: 700/2000\n",
      "Loss: 0.22464396819530813, epoch: 800/2000\n",
      "Loss: 0.1854380125514832, epoch: 900/2000\n",
      "Loss: 0.21843441600525765, epoch: 1000/2000\n",
      "Loss: 0.19186231277159807, epoch: 1100/2000\n",
      "Loss: 0.42981157389310704, epoch: 1200/2000\n",
      "Loss: 0.3023462506173746, epoch: 1300/2000\n",
      "Loss: 0.29015091088552236, epoch: 1400/2000\n",
      "Loss: 0.308474013571512, epoch: 1500/2000\n",
      "Loss: 0.47671898763593157, epoch: 1600/2000\n",
      "Loss: 0.23477431660203885, epoch: 1700/2000\n",
      "Loss: 0.5309711311232109, epoch: 1800/2000\n",
      "Loss: 0.23874044364637861, epoch: 1900/2000\n",
      "Loss: 0.23714960723643747, epoch: 2000/2000\n",
      "Loss: 0.5198602360805846, epoch: 20000/20000\n",
      "Loss: 0.2676726092943028, epoch: 100/2000\n",
      "Loss: 0.2898642570515012, epoch: 200/2000\n",
      "Loss: 0.2593032922381405, epoch: 300/2000\n",
      "Loss: 0.21866751011088406, epoch: 400/2000\n",
      "Loss: 0.2257440402224577, epoch: 500/2000\n",
      "Loss: 0.22293086961596525, epoch: 600/2000\n",
      "Loss: 0.20047322526244843, epoch: 700/2000\n",
      "Loss: 0.23310164206753475, epoch: 800/2000\n",
      "Loss: 0.20627190727303932, epoch: 900/2000\n",
      "Loss: 0.22247997595990573, epoch: 1000/2000\n",
      "Loss: 0.20427566630787145, epoch: 1100/2000\n",
      "Loss: 0.20571477999547652, epoch: 1200/2000\n",
      "Loss: 0.1905343275379335, epoch: 1300/2000\n",
      "Loss: 0.19646286012202716, epoch: 1400/2000\n",
      "Loss: 0.1873673086714668, epoch: 1500/2000\n",
      "Loss: 0.212606986854736, epoch: 1600/2000\n",
      "Loss: 0.22281620863775514, epoch: 1700/2000\n",
      "Loss: 0.195087056704601, epoch: 1800/2000\n",
      "Loss: 0.18860814466867337, epoch: 1900/2000\n",
      "Loss: 0.2941404506839563, epoch: 2000/2000\n",
      "Loss: 0.7625816369435555, epoch: 20000/20000\n",
      "Loss: 0.3484133216554763, epoch: 100/2000\n",
      "Loss: 0.18379707397738715, epoch: 200/2000\n",
      "Loss: 0.18569791238889527, epoch: 300/2000\n",
      "Loss: 0.17698534023399995, epoch: 400/2000\n",
      "Loss: 0.19135271835969747, epoch: 500/2000\n",
      "Loss: 0.19894244276161982, epoch: 600/2000\n",
      "Loss: 0.16193347813080605, epoch: 700/2000\n",
      "Loss: 0.15081363588493385, epoch: 800/2000\n",
      "Loss: 0.170094908593006, epoch: 900/2000\n",
      "Loss: 0.13267080616821086, epoch: 1000/2000\n",
      "Loss: 0.13310477017101416, epoch: 1100/2000\n",
      "Loss: 0.13889964065473362, epoch: 1200/2000\n",
      "Loss: 0.1526385586386954, epoch: 1300/2000\n",
      "Loss: 0.15537671458836905, epoch: 1400/2000\n",
      "Loss: 0.17886880306610745, epoch: 1500/2000\n",
      "Loss: 0.14830491660385287, epoch: 1600/2000\n",
      "Loss: 0.16532917716058612, epoch: 1700/2000\n",
      "Loss: 0.15278083417055133, epoch: 1800/2000\n",
      "Loss: 0.13505170482613474, epoch: 1900/2000\n",
      "Loss: 0.12911918730681077, epoch: 2000/2000\n",
      "Loss: 1.6762975326488376, epoch: 20000/20000\n",
      "Loss: 0.30855478312571677, epoch: 100/2000\n",
      "Loss: 0.30759446231957044, epoch: 200/2000\n",
      "Loss: 0.19117868500214813, epoch: 300/2000\n",
      "Loss: 0.14474058401340895, epoch: 400/2000\n",
      "Loss: 0.17582238971779268, epoch: 500/2000\n",
      "Loss: 0.17875934685058548, epoch: 600/2000\n",
      "Loss: 0.18494993128883108, epoch: 700/2000\n",
      "Loss: 0.39219958286308365, epoch: 800/2000\n",
      "Loss: 0.16008449572346067, epoch: 900/2000\n",
      "Loss: 0.19887583423362423, epoch: 1000/2000\n",
      "Loss: 0.18131873469584703, epoch: 1100/2000\n",
      "Loss: 0.20778575173183347, epoch: 1200/2000\n",
      "Loss: 0.2041278733180157, epoch: 1300/2000\n",
      "Loss: 0.21194904937746148, epoch: 1400/2000\n",
      "Loss: 0.21251915981188513, epoch: 1500/2000\n",
      "Loss: 0.19719465545183942, epoch: 1600/2000\n",
      "Loss: 0.19989925514201135, epoch: 1700/2000\n",
      "Loss: 0.19333640071746866, epoch: 1800/2000\n",
      "Loss: 0.23792234125875972, epoch: 1900/2000\n",
      "Loss: 0.25247792744201136, epoch: 2000/2000\n",
      "Loss: 0.456731313256869, epoch: 20000/20000\n",
      "Loss: 0.2445124069267536, epoch: 100/2000\n",
      "Loss: 0.24032594307362923, epoch: 200/2000\n",
      "Loss: 0.22860419047376057, epoch: 300/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2157185688824182, epoch: 400/2000\n",
      "Loss: 0.2506934189398796, epoch: 500/2000\n",
      "Loss: 0.21586786537679262, epoch: 600/2000\n",
      "Loss: 0.15935867732101375, epoch: 700/2000\n",
      "Loss: 0.18190957682380948, epoch: 800/2000\n",
      "Loss: 0.2146523096829689, epoch: 900/2000\n",
      "Loss: 0.1879617823044434, epoch: 1000/2000\n",
      "Loss: 0.19168829504855966, epoch: 1100/2000\n",
      "Loss: 0.17865714313170042, epoch: 1200/2000\n",
      "Loss: 0.1986868959906313, epoch: 1300/2000\n",
      "Loss: 0.17737015705574494, epoch: 1400/2000\n",
      "Loss: 0.17048136830780597, epoch: 1500/2000\n",
      "Loss: 0.18701670530800604, epoch: 1600/2000\n",
      "Loss: 0.14495544462517038, epoch: 1700/2000\n",
      "Loss: 0.1794288943920821, epoch: 1800/2000\n",
      "Loss: 0.2155886181584458, epoch: 1900/2000\n",
      "Loss: 0.21818583691833143, epoch: 2000/2000\n",
      "Loss: 1.654492653557402, epoch: 20000/20000\n",
      "Loss: 0.30726548392711067, epoch: 100/2000\n",
      "Loss: 0.28276857624580953, epoch: 200/2000\n",
      "Loss: 0.47410277755413555, epoch: 300/2000\n",
      "Loss: 0.2309204041713032, epoch: 400/2000\n",
      "Loss: 0.19662280012608246, epoch: 500/2000\n",
      "Loss: 0.21339459712799722, epoch: 600/2000\n",
      "Loss: 0.1547516255841626, epoch: 700/2000\n",
      "Loss: 0.21691898857385983, epoch: 800/2000\n",
      "Loss: 0.2714215909557588, epoch: 900/2000\n",
      "Loss: 0.2838316606458804, epoch: 1000/2000\n",
      "Loss: 0.323833465963397, epoch: 1100/2000\n",
      "Loss: 0.2661902985820045, epoch: 1200/2000\n",
      "Loss: 0.2525691151024687, epoch: 1300/2000\n",
      "Loss: 0.21154188571787036, epoch: 1400/2000\n",
      "Loss: 0.2112101373563271, epoch: 1500/2000\n",
      "Loss: 0.2779456227617229, epoch: 1600/2000\n",
      "Loss: 0.2309307305102665, epoch: 1700/2000\n",
      "Loss: 0.25500076518147324, epoch: 1800/2000\n",
      "Loss: 0.2422580432400514, epoch: 1900/2000\n",
      "Loss: 0.2965345571173911, epoch: 2000/2000\n",
      "Loss: 0.473494130284288, epoch: 20000/20000\n",
      "Loss: 0.17756730869062917, epoch: 100/2000\n",
      "Loss: 0.1927716668018981, epoch: 200/2000\n",
      "Loss: 0.13091496187458662, epoch: 300/2000\n",
      "Loss: 0.1342263229954133, epoch: 400/2000\n",
      "Loss: 0.28914039942587577, epoch: 500/2000\n",
      "Loss: 0.20788569619133837, epoch: 600/2000\n",
      "Loss: 0.14058786933825163, epoch: 700/2000\n",
      "Loss: 0.1531008792170882, epoch: 800/2000\n",
      "Loss: 0.14746446635418298, epoch: 900/2000\n",
      "Loss: 0.2588628109268879, epoch: 1000/2000\n",
      "Loss: 0.19020974518601466, epoch: 1100/2000\n",
      "Loss: 0.161800386736425, epoch: 1200/2000\n",
      "Loss: 0.14539332672525934, epoch: 1300/2000\n",
      "Loss: 0.1612885065499288, epoch: 1400/2000\n",
      "Loss: 0.15570298706589486, epoch: 1500/2000\n",
      "Loss: 0.1470242493003357, epoch: 1600/2000\n",
      "Loss: 0.29122731591824136, epoch: 1700/2000\n",
      "Loss: 0.14426223782589878, epoch: 1800/2000\n",
      "Loss: 0.13836737589452192, epoch: 1900/2000\n",
      "Loss: 0.14778123375855434, epoch: 2000/2000\n",
      "Loss: 0.452785230099814, epoch: 20000/20000\n",
      "Loss: 0.3007407792044312, epoch: 100/2000\n",
      "Loss: 0.24191693102538686, epoch: 200/2000\n",
      "Loss: 0.20187206044502415, epoch: 300/2000\n",
      "Loss: 0.2428233329809631, epoch: 400/2000\n",
      "Loss: 0.20665315927497763, epoch: 500/2000\n",
      "Loss: 0.15899604379044013, epoch: 600/2000\n",
      "Loss: 0.16382665417057277, epoch: 700/2000\n",
      "Loss: 0.1592183653601315, epoch: 800/2000\n",
      "Loss: 0.18068319931896878, epoch: 900/2000\n",
      "Loss: 0.18993990055701965, epoch: 1000/2000\n",
      "Loss: 0.17209918961750859, epoch: 1100/2000\n",
      "Loss: 0.1735754772832134, epoch: 1200/2000\n",
      "Loss: 0.1637693876105571, epoch: 1300/2000\n",
      "Loss: 0.17186987042408314, epoch: 1400/2000\n",
      "Loss: 0.1529681341772478, epoch: 1500/2000\n",
      "Loss: 0.18679689065217348, epoch: 1600/2000\n",
      "Loss: 0.13451495352540385, epoch: 1700/2000\n",
      "Loss: 0.2019061148214399, epoch: 1800/2000\n",
      "Loss: 0.15470611553613495, epoch: 1900/2000\n",
      "Loss: 0.18888413082792838, epoch: 2000/2000\n",
      "Loss: 1.874306897928236, epoch: 20000/20000\n",
      "Loss: 0.1470294467862409, epoch: 100/2000\n",
      "Loss: 0.21488250126810282, epoch: 200/2000\n",
      "Loss: 0.22882238690100137, epoch: 300/2000\n",
      "Loss: 0.18238282745072731, epoch: 400/2000\n",
      "Loss: 0.1356298525042291, epoch: 500/2000\n",
      "Loss: 0.14553084117544962, epoch: 600/2000\n",
      "Loss: 0.21144269134451665, epoch: 700/2000\n",
      "Loss: 0.27474815152913157, epoch: 800/2000\n",
      "Loss: 0.279618034049088, epoch: 900/2000\n",
      "Loss: 0.17600839929087042, epoch: 1000/2000\n",
      "Loss: 0.14889687628282597, epoch: 1100/2000\n",
      "Loss: 0.21748459612043863, epoch: 1200/2000\n",
      "Loss: 0.1843698417429112, epoch: 1300/2000\n",
      "Loss: 0.1348259394213454, epoch: 1400/2000\n",
      "Loss: 0.11848513192484526, epoch: 1500/2000\n",
      "Loss: 0.17570116094803587, epoch: 1600/2000\n",
      "Loss: 0.10853447732725459, epoch: 1700/2000\n",
      "Loss: 0.13141567091622627, epoch: 1800/2000\n",
      "Loss: 0.1424371239195334, epoch: 1900/2000\n",
      "Loss: 0.10816076496736522, epoch: 2000/2000\n",
      "Loss: 0.9042405806730265, epoch: 20000/20000\n",
      "Loss: 0.26312682877157767, epoch: 100/2000\n",
      "Loss: 0.2521027830128081, epoch: 200/2000\n",
      "Loss: 0.2275206964683248, epoch: 300/2000\n",
      "Loss: 0.205332119975768, epoch: 400/2000\n",
      "Loss: 0.23130025095988804, epoch: 500/2000\n",
      "Loss: 0.21568450116300486, epoch: 600/2000\n",
      "Loss: 0.20568345219881662, epoch: 700/2000\n",
      "Loss: 0.1425953128544022, epoch: 800/2000\n",
      "Loss: 0.1341720074304713, epoch: 900/2000\n",
      "Loss: 0.1502415083851562, epoch: 1000/2000\n",
      "Loss: 0.12433843605729625, epoch: 1100/2000\n",
      "Loss: 0.10641627524690359, epoch: 1200/2000\n",
      "Loss: 0.12072541927880984, epoch: 1300/2000\n",
      "Loss: 0.15567530227344198, epoch: 1400/2000\n",
      "Loss: 0.19271565267045926, epoch: 1500/2000\n",
      "Loss: 0.16725289172224958, epoch: 1600/2000\n",
      "Loss: 0.13451156747937207, epoch: 1700/2000\n",
      "Loss: 0.1531549375088565, epoch: 1800/2000\n",
      "Loss: 0.13418021927164153, epoch: 1900/2000\n",
      "Loss: 0.1423505739356307, epoch: 2000/2000\n",
      "Loss: 0.3567274081739887, epoch: 20000/20000\n",
      "Loss: 0.5588833252385277, epoch: 100/2000\n",
      "Loss: 0.4969035482113206, epoch: 200/2000\n",
      "Loss: 0.5022888492233115, epoch: 300/2000\n",
      "Loss: 0.5044833908960029, epoch: 400/2000\n",
      "Loss: 0.5008136124386174, epoch: 500/2000\n",
      "Loss: 0.5013975820770368, epoch: 600/2000\n",
      "Loss: 0.5035901501555562, epoch: 700/2000\n",
      "Loss: 0.5093328356241805, epoch: 800/2000\n",
      "Loss: 0.5014410533435234, epoch: 900/2000\n",
      "Loss: 0.49429235747531985, epoch: 1000/2000\n",
      "Loss: 0.5043969286074422, epoch: 1100/2000\n",
      "Loss: 0.5017045935281816, epoch: 1200/2000\n",
      "Loss: 0.5151196939270336, epoch: 1300/2000\n",
      "Loss: 0.5005810946023984, epoch: 1400/2000\n",
      "Loss: 0.4973875413047317, epoch: 1500/2000\n",
      "Loss: 0.49420233923359697, epoch: 1600/2000\n",
      "Loss: 0.49684268328883985, epoch: 1700/2000\n",
      "Loss: 0.49483607119749173, epoch: 1800/2000\n",
      "Loss: 0.49567207457045237, epoch: 1900/2000\n",
      "Loss: 0.5015903093799159, epoch: 2000/2000\n",
      "Loss: 0.6849262278272635, epoch: 20000/20000\n",
      "Loss: 0.24089801108878803, epoch: 100/2000\n",
      "Loss: 0.209471137015327, epoch: 200/2000\n",
      "Loss: 0.17244315947415575, epoch: 300/2000\n",
      "Loss: 0.20637121746841997, epoch: 400/2000\n",
      "Loss: 0.1779306175484835, epoch: 500/2000\n",
      "Loss: 0.1552413220202786, epoch: 600/2000\n",
      "Loss: 0.13345483855746104, epoch: 700/2000\n",
      "Loss: 0.15407820597955113, epoch: 800/2000\n",
      "Loss: 0.15990914698470024, epoch: 900/2000\n",
      "Loss: 0.18664537109758245, epoch: 1000/2000\n",
      "Loss: 0.17097312488399383, epoch: 1100/2000\n",
      "Loss: 0.16793137729896196, epoch: 1200/2000\n",
      "Loss: 0.10925012024969039, epoch: 1300/2000\n",
      "Loss: 0.1180851215430341, epoch: 1400/2000\n",
      "Loss: 0.14863550522882318, epoch: 1500/2000\n",
      "Loss: 0.12130113590629296, epoch: 1600/2000\n",
      "Loss: 0.12153489930770289, epoch: 1700/2000\n",
      "Loss: 0.19818110946485973, epoch: 1800/2000\n",
      "Loss: 0.13815170011137395, epoch: 1900/2000\n",
      "Loss: 0.1481918531083374, epoch: 2000/2000\n",
      "Loss: 1.8676734310146248, epoch: 20000/20000\n",
      "Loss: 0.2801315667886441, epoch: 100/2000\n",
      "Loss: 0.21631102154056117, epoch: 200/2000\n",
      "Loss: 0.15534449987418988, epoch: 300/2000\n",
      "Loss: 0.19536302596820557, epoch: 400/2000\n",
      "Loss: 0.12123723625973745, epoch: 500/2000\n",
      "Loss: 0.16325736968225726, epoch: 600/2000\n",
      "Loss: 0.2072550770687394, epoch: 700/2000\n",
      "Loss: 0.3494913299457413, epoch: 800/2000\n",
      "Loss: 0.13466198026645504, epoch: 900/2000\n",
      "Loss: 0.1321623347826176, epoch: 1000/2000\n",
      "Loss: 0.19898957907214418, epoch: 1100/2000\n",
      "Loss: 0.11627664734816678, epoch: 1200/2000\n",
      "Loss: 0.13397085743826914, epoch: 1300/2000\n",
      "Loss: 0.12722873628100556, epoch: 1400/2000\n",
      "Loss: 0.16823720815153678, epoch: 1500/2000\n",
      "Loss: 0.1623886192800294, epoch: 1600/2000\n",
      "Loss: 0.1577113436974999, epoch: 1700/2000\n",
      "Loss: 0.25090094613080083, epoch: 1800/2000\n",
      "Loss: 0.15824863584449939, epoch: 1900/2000\n",
      "Loss: 0.22107024671363057, epoch: 2000/2000\n",
      "Loss: 1.850292036290418, epoch: 20000/20000\n",
      "Loss: 0.29247495898674036, epoch: 100/2000\n",
      "Loss: 0.25943200610060013, epoch: 200/2000\n",
      "Loss: 0.24159232081479548, epoch: 300/2000\n",
      "Loss: 0.21991516722327323, epoch: 400/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15677818622375622, epoch: 500/2000\n",
      "Loss: 0.23372419644959858, epoch: 600/2000\n",
      "Loss: 0.1732529906440526, epoch: 700/2000\n",
      "Loss: 0.22959982724624464, epoch: 800/2000\n",
      "Loss: 0.18974646404429985, epoch: 900/2000\n",
      "Loss: 0.13927186566558333, epoch: 1000/2000\n",
      "Loss: 0.25290386545468124, epoch: 1100/2000\n",
      "Loss: 0.29018674973493275, epoch: 1200/2000\n",
      "Loss: 0.2949228368577172, epoch: 1300/2000\n",
      "Loss: 0.22400831496983864, epoch: 1400/2000\n",
      "Loss: 0.12582101400179915, epoch: 1500/2000\n",
      "Loss: 0.22439460677475664, epoch: 1600/2000\n",
      "Loss: 0.1468320715064812, epoch: 1700/2000\n",
      "Loss: 0.18098437592858055, epoch: 1800/2000\n",
      "Loss: 0.10570261509520706, epoch: 1900/2000\n",
      "Loss: 0.15756055586164802, epoch: 2000/2000\n",
      "Loss: 0.8618364331290268, epoch: 20000/20000\n",
      "Loss: 0.2579929000538169, epoch: 100/2000\n",
      "Loss: 0.2325393980472923, epoch: 200/2000\n",
      "Loss: 0.23508794678342979, epoch: 300/2000\n",
      "Loss: 0.30125340467015826, epoch: 400/2000\n",
      "Loss: 0.1405731657462596, epoch: 500/2000\n",
      "Loss: 0.1691563155804413, epoch: 600/2000\n",
      "Loss: 0.19193699015698437, epoch: 700/2000\n",
      "Loss: 0.1701594687498245, epoch: 800/2000\n",
      "Loss: 0.2147052441353972, epoch: 900/2000\n",
      "Loss: 0.2569522274735439, epoch: 1000/2000\n",
      "Loss: 0.253831927952755, epoch: 1100/2000\n",
      "Loss: 0.2748926458759656, epoch: 1200/2000\n",
      "Loss: 0.24760378058488525, epoch: 1300/2000\n",
      "Loss: 0.24186857062374875, epoch: 1400/2000\n",
      "Loss: 0.23434556533922696, epoch: 1500/2000\n",
      "Loss: 0.2600996250554504, epoch: 1600/2000\n",
      "Loss: 0.23460317163317007, epoch: 1700/2000\n",
      "Loss: 0.23471395044454968, epoch: 1800/2000\n",
      "Loss: 0.2172255842834887, epoch: 1900/2000\n",
      "Loss: 0.20193486301971833, epoch: 2000/2000\n",
      "Loss: 0.5351509397647974, epoch: 20000/20000\n",
      "Loss: 0.19833194880575972, epoch: 100/2000\n",
      "Loss: 0.1543202852019589, epoch: 200/2000\n",
      "Loss: 0.1669075335295529, epoch: 300/2000\n",
      "Loss: 0.19221419423537026, epoch: 400/2000\n",
      "Loss: 0.16021016442241293, epoch: 500/2000\n",
      "Loss: 0.20248815292542927, epoch: 600/2000\n",
      "Loss: 0.19916395661258196, epoch: 700/2000\n",
      "Loss: 0.21557704752318432, epoch: 800/2000\n",
      "Loss: 0.2197344569069311, epoch: 900/2000\n",
      "Loss: 0.2453607191219802, epoch: 1000/2000\n",
      "Loss: 0.20496865478073042, epoch: 1100/2000\n",
      "Loss: 0.18566455349625444, epoch: 1200/2000\n",
      "Loss: 0.1633979582617488, epoch: 1300/2000\n",
      "Loss: 0.15790024055244942, epoch: 1400/2000\n",
      "Loss: 0.18275846989791145, epoch: 1500/2000\n",
      "Loss: 0.12866684445800455, epoch: 1600/2000\n",
      "Loss: 0.13692027870034823, epoch: 1700/2000\n",
      "Loss: 0.18678556810745414, epoch: 1800/2000\n",
      "Loss: 0.1557904565518387, epoch: 1900/2000\n",
      "Loss: 0.17694449182964603, epoch: 2000/2000\n",
      "Loss: 0.6289407261564272, epoch: 20000/20000\n",
      "Loss: 0.2337469041877366, epoch: 100/2000\n",
      "Loss: 0.17737449392405852, epoch: 200/2000\n",
      "Loss: 0.17592354892969841, epoch: 300/2000\n",
      "Loss: 0.16275922077737598, epoch: 400/2000\n",
      "Loss: 0.17043810700538597, epoch: 500/2000\n",
      "Loss: 0.17166907016948868, epoch: 600/2000\n",
      "Loss: 0.21048632578891766, epoch: 700/2000\n",
      "Loss: 0.16558556799946958, epoch: 800/2000\n",
      "Loss: 0.1674475421059704, epoch: 900/2000\n",
      "Loss: 0.2168985666669121, epoch: 1000/2000\n",
      "Loss: 0.15204422939405055, epoch: 1100/2000\n",
      "Loss: 0.1437931779080776, epoch: 1200/2000\n",
      "Loss: 0.12202300572251612, epoch: 1300/2000\n",
      "Loss: 0.1121257407547495, epoch: 1400/2000\n",
      "Loss: 0.11435131859702727, epoch: 1500/2000\n",
      "Loss: 0.11356691863786302, epoch: 1600/2000\n",
      "Loss: 0.11378730056006289, epoch: 1700/2000\n",
      "Loss: 0.12924205770325567, epoch: 1800/2000\n",
      "Loss: 0.12236862258130579, epoch: 1900/2000\n",
      "Loss: 0.13394926350861888, epoch: 2000/2000\n",
      "Loss: 1.5173645806377887, epoch: 20000/20000\n",
      "Loss: 0.3573289861903622, epoch: 100/2000\n",
      "Loss: 0.3115066897759519, epoch: 200/2000\n",
      "Loss: 0.2618220586690499, epoch: 300/2000\n",
      "Loss: 0.2684037338587974, epoch: 400/2000\n",
      "Loss: 0.25301940449110466, epoch: 500/2000\n",
      "Loss: 0.32024390947877557, epoch: 600/2000\n",
      "Loss: 0.26867258575506014, epoch: 700/2000\n",
      "Loss: 0.31810815470831355, epoch: 800/2000\n",
      "Loss: 0.2458892332629436, epoch: 900/2000\n",
      "Loss: 0.21127100084687944, epoch: 1000/2000\n",
      "Loss: 0.22178331202950702, epoch: 1100/2000\n",
      "Loss: 0.2644779336464026, epoch: 1200/2000\n",
      "Loss: 0.2378591966876375, epoch: 1300/2000\n",
      "Loss: 0.23770397475129162, epoch: 1400/2000\n",
      "Loss: 0.2766745483658276, epoch: 1500/2000\n",
      "Loss: 0.22790779867412972, epoch: 1600/2000\n",
      "Loss: 0.24349419458924765, epoch: 1700/2000\n",
      "Loss: 0.2443248388518881, epoch: 1800/2000\n",
      "Loss: 0.2137349541979255, epoch: 1900/2000\n",
      "Loss: 0.2255275359155085, epoch: 2000/2000\n",
      "Loss: 0.4825439627415456, epoch: 20000/20000\n",
      "Loss: 0.31070303157476026, epoch: 100/2000\n",
      "Loss: 0.2197127780051321, epoch: 200/2000\n",
      "Loss: 0.26746627488894636, epoch: 300/2000\n",
      "Loss: 0.22326271691276373, epoch: 400/2000\n",
      "Loss: 0.22454712514141112, epoch: 500/2000\n",
      "Loss: 0.2500447076172383, epoch: 600/2000\n",
      "Loss: 0.28464447226192674, epoch: 700/2000\n",
      "Loss: 0.21156162157014652, epoch: 800/2000\n",
      "Loss: 0.20354440045254463, epoch: 900/2000\n",
      "Loss: 0.21403410401765344, epoch: 1000/2000\n",
      "Loss: 0.23503633763308357, epoch: 1100/2000\n",
      "Loss: 0.2118760365542435, epoch: 1200/2000\n",
      "Loss: 0.2195125238138289, epoch: 1300/2000\n",
      "Loss: 0.2060593222183666, epoch: 1400/2000\n",
      "Loss: 0.23538478768987373, epoch: 1500/2000\n",
      "Loss: 0.1997986569210231, epoch: 1600/2000\n",
      "Loss: 0.1973538184682486, epoch: 1700/2000\n",
      "Loss: 0.23995549038675085, epoch: 1800/2000\n",
      "Loss: 0.20460738244726828, epoch: 1900/2000\n",
      "Loss: 0.20854177544718505, epoch: 2000/2000\n",
      "Loss: 0.6615378710684596, epoch: 20000/20000\n",
      "Loss: 0.1869051766337565, epoch: 100/2000\n",
      "Loss: 0.12971121316760822, epoch: 200/2000\n",
      "Loss: 0.15150795285075958, epoch: 300/2000\n",
      "Loss: 0.18735011610861207, epoch: 400/2000\n",
      "Loss: 0.21308750671515536, epoch: 500/2000\n",
      "Loss: 0.16342151049366738, epoch: 600/2000\n",
      "Loss: 0.21090819701089467, epoch: 700/2000\n",
      "Loss: 0.1966021177772673, epoch: 800/2000\n",
      "Loss: 0.17397619730196054, epoch: 900/2000\n",
      "Loss: 0.1502130398120709, epoch: 1000/2000\n",
      "Loss: 0.1737725055373843, epoch: 1100/2000\n",
      "Loss: 0.12786560125111227, epoch: 1200/2000\n",
      "Loss: 0.1390339346393472, epoch: 1300/2000\n",
      "Loss: 0.14085635731293736, epoch: 1400/2000\n",
      "Loss: 0.15680720040615814, epoch: 1500/2000\n",
      "Loss: 0.1681081250219432, epoch: 1600/2000\n",
      "Loss: 0.18148517646323697, epoch: 1700/2000\n",
      "Loss: 0.13667424878371906, epoch: 1800/2000\n",
      "Loss: 0.14923806911199813, epoch: 1900/2000\n",
      "Loss: 0.14807776592484304, epoch: 2000/2000\n",
      "Loss: 0.536763327748093, epoch: 20000/20000\n",
      "Loss: 0.18953311701356207, epoch: 100/2000\n",
      "Loss: 0.2096018415797126, epoch: 200/2000\n",
      "Loss: 0.2595402344827037, epoch: 300/2000\n",
      "Loss: 0.2191709424812233, epoch: 400/2000\n",
      "Loss: 0.2471269546640392, epoch: 500/2000\n",
      "Loss: 0.23318836285177008, epoch: 600/2000\n",
      "Loss: 0.26161862361307514, epoch: 700/2000\n",
      "Loss: 0.27040249600764354, epoch: 800/2000\n",
      "Loss: 0.22912656064011339, epoch: 900/2000\n",
      "Loss: 0.23568503618807995, epoch: 1000/2000\n",
      "Loss: 0.22008871537531313, epoch: 1100/2000\n",
      "Loss: 0.17643193171850563, epoch: 1200/2000\n",
      "Loss: 0.16662583625566224, epoch: 1300/2000\n",
      "Loss: 0.16330676016629583, epoch: 1400/2000\n",
      "Loss: 0.17447155604602543, epoch: 1500/2000\n",
      "Loss: 0.14262813398075683, epoch: 1600/2000\n",
      "Loss: 0.1889324098564995, epoch: 1700/2000\n",
      "Loss: 0.14621527627562297, epoch: 1800/2000\n",
      "Loss: 0.2120315750617059, epoch: 1900/2000\n",
      "Loss: 0.18836657073959062, epoch: 2000/2000\n"
     ]
    }
   ],
   "source": [
    "#Gillar\n",
    "taus = [.25, .25, 10]\n",
    "losses_gen = []\n",
    "losses_from_gen = []\n",
    "time_start = time.perf_counter()\n",
    "exp = ExperimentAnalytes(k0 = alists[0].k0.values, S = alists[0].S.values, h=0.001,run_time=10.0)\n",
    "for i in range(100):\n",
    "    pol = PolicyGeneral(\n",
    "                phi = nn.Sequential(\n",
    "                    PermEqui2_max(2, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                ),\n",
    "                rho = nn.Sequential(\n",
    "                    nn.Linear(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    nn.Linear(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    Rho(n_steps=len(taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "                )\n",
    "            )\n",
    "    reinforce_gen(\n",
    "        alists = alists[1:], \n",
    "        policy = pol, \n",
    "        delta_taus = taus, \n",
    "        num_episodes = 20_000, \n",
    "        sample_size = 10,\n",
    "        batch_size = 1, \n",
    "        lr = .05, \n",
    "        optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "        lr_decay_factor = 0.75,\n",
    "        lr_milestones = 2500,\n",
    "        print_every = 20_000,\n",
    "        baseline = .55,\n",
    "        max_norm = 1.5,\n",
    "        max_rand_analytes = 30,\n",
    "        min_rand_analytes = 15,\n",
    "        rand_prob = 0.7\n",
    "    )\n",
    "    mu, _ = pol(torch.Tensor(alists[0][['S', 'lnk0']].values))\n",
    "    exp.reset()\n",
    "    exp.run_all(mu.detach().numpy(), taus)\n",
    "    losses_gen.append(exp.loss())\n",
    "    _, _, mus, _ = reinforce_single_from_gen(\n",
    "        alist=alists[0], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=2000, \n",
    "        sample_size=10, \n",
    "        lr=.05, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=1000,\n",
    "        print_every=100,\n",
    "        baseline=0.55,\n",
    "        max_norm=2.\n",
    "    )\n",
    "    exp.reset()\n",
    "    exp.run_all(mus[-1,:], taus)\n",
    "    losses_from_gen.append(exp.loss())\n",
    "    \n",
    "time_end = time.perf_counter()\n",
    "# time 507.8653401895899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gillar\n",
    "alists = []\n",
    "alists.append(pd.read_csv(f'../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv(f'../data/GilarSample.csv'))\n",
    "\n",
    "alists.append(pd.read_csv(f'../data/Roca.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Controlmix2.csv'))\n",
    "\n",
    "taus = [.25, .25, 10]\n",
    "losses_gen_pp = []\n",
    "losses_from_gen_pp = []\n",
    "time_start_pp = time.perf_counter()\n",
    "exp = ExperimentAnalytes(k0 = alists[0].k0.values, S = alists[0].S.values, h=0.001,run_time=10.0)\n",
    "for i in range(100):\n",
    "    pol = PolicyGeneral(\n",
    "                phi = nn.Sequential(\n",
    "                    PermEqui2_max(2, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                ),\n",
    "                rho = nn.Sequential(\n",
    "                    nn.Linear(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    nn.Linear(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    Rho(n_steps=len(taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "                )\n",
    "            )\n",
    "    reinforce_gen(\n",
    "        alists = alists[1:], \n",
    "        policy = pol, \n",
    "        delta_taus = taus, \n",
    "        num_episodes = 20_000, \n",
    "        sample_size = 10,\n",
    "        batch_size = 1, \n",
    "        lr = .05, \n",
    "        optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "        lr_decay_factor = 0.75,\n",
    "        lr_milestones = 2500,\n",
    "        print_every = 20_000,\n",
    "        baseline = .55,\n",
    "        max_norm = 1.5,\n",
    "        max_rand_analytes = 30,\n",
    "        min_rand_analytes = 15,\n",
    "        rand_prob = 0.7\n",
    "    )\n",
    "    mu, _ = pol(torch.Tensor(alists[0][['S', 'lnk0']].values))\n",
    "    exp.reset()\n",
    "    exp.run_all(mu.detach().numpy(), taus)\n",
    "    losses_gen_pp.append(exp.loss())\n",
    "    _, _, mus, _ = reinforce_single_from_gen(\n",
    "        alist=alists[0], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=2000, \n",
    "        sample_size=10, \n",
    "        lr=.05, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=1000,\n",
    "        print_every=100,\n",
    "        baseline=0.55,\n",
    "        max_norm=2.\n",
    "    )\n",
    "    exp.reset()\n",
    "    exp.run_all(mus[-1,:], taus)\n",
    "    losses_from_gen_pp.append(exp.loss())\n",
    "    \n",
    "time_end_pp = time.perf_counter()\n",
    "# time 523.31177600672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523.31177600672"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(time_end_pp - time_start_pp)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Occurrences')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(losses_gen_pp, bins=50)\n",
    "plt.title(f\"Final Result Distribution for GenModel (PeterPeptides)\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Occurrences')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(losses_from_gen_pp, bins=50)\n",
    "plt.title(f\"Final Result Distribution for GenModel + FineTune(PeterPeptides)\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gillar\n",
    "taus = [.25, .25, 10]\n",
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "reinforce_gen(\n",
    "    alists = alists, \n",
    "    policy = pol, \n",
    "    delta_taus = taus, \n",
    "    num_episodes = 40_000, \n",
    "    sample_size = 10,\n",
    "    batch_size = 1, \n",
    "    lr = .05, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "    lr_decay_factor = 0.75,\n",
    "    lr_milestones = 5000,\n",
    "    print_every = 20_000,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.5,\n",
    "    max_rand_analytes = 30,\n",
    "    min_rand_analytes = 15,\n",
    "    rand_prob = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_over_equal_intervals(np.array(L8).mean(0), 500), label=\"L8\")\n",
    "plt.title(\"Loss (average of 500 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, sig = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "exp.run_all(mu.detach().numpy(), taus)\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Gen)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_gen(\n",
    "        alist=alists[0], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=2000, \n",
    "        sample_size=10, \n",
    "        lr=.05, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=1000,\n",
    "        print_every=100,\n",
    "        baseline=0.55,\n",
    "        max_norm=2.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(mus[-1,:], taus)\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Iso)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(B, taus)\n",
    "exp.print_analytes(title=f\"Best Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = RhoTime(n_steps=3, hidden=5, in_dim=3, sigma_max=.3, sigma_min=.02)\n",
    "        )\n",
    "losses = reinforce_delta_tau_gen(\n",
    "    alists = alists, \n",
    "    policy = pol,\n",
    "    num_episodes = 10000, \n",
    "    batch_size = 10, \n",
    "    lr = .1, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "    lr_decay_factor= 0.75,\n",
    "    lr_milestones=1000,\n",
    "    print_every = 100,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.2,\n",
    "    max_rand_analytes = 35,\n",
    "    min_rand_analytes = 18,\n",
    "    rand_prob = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 200000, 200),average_over_equal_intervals(losses[0], 1000))\n",
    "plt.title(\"Loss [variable delta tau] (average of 1000 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, _ = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "mu = mu.tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_delta_tau_gen(\n",
    "        alist=alists[i], \n",
    "        policy=pol,\n",
    "        num_episodes=5000, \n",
    "        batch_size=10, \n",
    "        lr=.1, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=500,\n",
    "        print_every=500,\n",
    "        baseline=0.65,\n",
    "        max_norm=1.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu = mus[-1].tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGeneralISO(nn.Module):\n",
    "    def __init__(self, \n",
    "            phi: nn.Module,\n",
    "            rho: nn.Module\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        phi: nn.Module\n",
    "            The network that encodes the analyte set to a single \n",
    "            vector (embedding)\n",
    "        rho: nn.Module\n",
    "            The network that outputs the programe for separation\n",
    "            returns mean and standard deviation of the action space\n",
    "\n",
    "        Ex:\n",
    "        For a 4 step solvent gradient programe the generalized policy \n",
    "        with 3 elements embedding for the analyte set and intermediate\n",
    "        layers of 5 neurons.\n",
    "        policy = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui1_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui1_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui1_max(5, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = Rho(4, 5, 3, .3, .05)\n",
    "        )\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.phi = phi\n",
    "        self.rho = rho\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        phi_output = self.phi(x)\n",
    "        sum_output = phi_output.sum(0, keepdim=True)\n",
    "        sum_output = torch.cat([sum_output, y], 1)\n",
    "        mu, sigma = self.rho(sum_output)\n",
    "        return mu, sigma\n",
    "\n",
    "#############################################################################\n",
    "def reinforce_gen_iso(\n",
    "        alists: Iterable[pd.DataFrame],\n",
    "        policy: PolicyGeneral, \n",
    "        delta_taus: Iterable[float], \n",
    "        num_episodes: int = 1000, \n",
    "        sample_size: int = 10,\n",
    "        batch_size : int = 10,\n",
    "        lr: float = 1., \n",
    "        optim = torch.optim.SGD,\n",
    "        lr_decay_factor: float = 1.,\n",
    "        lr_milestones: Union[int, Iterable[int]] = 1000,\n",
    "        rand_prob: float = .2,\n",
    "        max_rand_analytes: int = 30,\n",
    "        min_rand_analytes: int = 10,\n",
    "        print_every: int = 100,\n",
    "        baseline: float = 0.,\n",
    "        max_norm: float = None,\n",
    "        beta: float = .0,\n",
    "        weights: list = [1., 1.]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Run Reinforcement Learning for a single set learning.\n",
    "\n",
    "    alists: Iterable[pd.DataFrame]\n",
    "        A list with pd.Dataframes for each dataset used to train on. \n",
    "    policy: PolicyGeneral\n",
    "        The policy that learns the optimal values for the solvent\n",
    "        strength program.\n",
    "    delta_taus: Iterable[float]\n",
    "        Iterable list with the points of solvent strength change.\n",
    "        MUST be the same length as policy.n_steps\n",
    "    num_episodes = 1000\n",
    "        Number of learning steps.\n",
    "    sample_size = 10\n",
    "        Number of samples taken from the action distribution to perform \n",
    "        Expected loss for the distribution of actions.\n",
    "    batch_size:\n",
    "        Number of experiments to run in order to aproximate the true gradient.\n",
    "    lr = 1.\n",
    "        Learning rate.\n",
    "    optim = torch.optim.SGD\n",
    "        Optimizer that performs weight update using gradients.\n",
    "        By defauld is Stochastic Gradient Descent.\n",
    "    lr_decay_factor: float\n",
    "        Learning rate decay factor used for the LRScheduler.\n",
    "        lr is updated according to lr = lr ** lr_decay_factor.\n",
    "    lr_milestones: Union[int, Iterable[int]]\n",
    "        Milestone episode/s to update the learning rate.\n",
    "        If it is int StepLR is used where lr is changed every lr_milestones.\n",
    "        If it is a list of ints then at that specific episode the lr\n",
    "        will be changed.\n",
    "    rand_prob: float = .2\n",
    "        The probability to draw a random subset from all the analytes.\n",
    "        1 - rand_prob is the probability to use a \"real\" set (provided in\n",
    "        alists).\n",
    "    max_rand_analytes: int = 30\n",
    "        The maximum number of analytes in the randomly drawn set.\n",
    "    min_rand_analytes: int = 10\n",
    "        The minimum number of analytes in the randomly drawn set.\n",
    "    print_every = 100,\n",
    "        Number of episodes to print the average loss on.\n",
    "    weights = [1., 1.]\n",
    "        Weigths of the errors to consider, first one is for the Placement Error,\n",
    "        second one is for Overlap Error, By default both have the same wights.\n",
    "    baseline = 0.\n",
    "        Baseline value for the REINFORCE algorithm.\n",
    "    max_norm = None\n",
    "        Maximal value for the Neural Network Norm2.\n",
    "    beta = .0\n",
    "        Entropy Regularization term, is used for more exploration.\n",
    "        By defauld is disabled.\n",
    "    Returns\n",
    "    -------\n",
    "    (losses, best_program, mus, sigmas)\n",
    "    losses: np.ndarray\n",
    "        Expected loss of the action distribution over the whole learning\n",
    "        process.\n",
    "    \"\"\"\n",
    "\n",
    "    losses = []\n",
    "    perfect_loss = []\n",
    "    exps = []\n",
    "\n",
    "    # Make ExperimentAnalytes object for the given analyte sets for time saving purpose\n",
    "    for alist in alists:\n",
    "        exps.append(ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, run_time=10.0))\n",
    "\n",
    "    num_exps = len(alists)\n",
    "\n",
    "    all_analytes = pd.concat(alists, sort=True)[['k0', 'S', 'lnk0']]\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim(policy.parameters(), lr)\n",
    "\n",
    "    # LR sheduler\n",
    "    if isinstance(lr_milestones, list) or isinstance(lr_milestones, np.ndarray):\n",
    "        scheduler = MultiStepLR(optimizer, lr_milestones, gamma=lr_decay_factor)\n",
    "    else:\n",
    "        scheduler = StepLR(optimizer, lr_milestones, gamma=lr_decay_factor)\n",
    "\n",
    "    J_batch = 0\n",
    "\n",
    "    for n in range(num_episodes):\n",
    "        # the set to use for the experiment.\n",
    "        if random() < rand_prob:\n",
    "            dataframe = all_analytes.sample(randint(min_rand_analytes, max_rand_analytes))\n",
    "            input_data = torch.tensor(dataframe[['S', 'lnk0']].values, dtype=torch.float32)\n",
    "            exp = ExperimentAnalytes(k0 = dataframe.k0.values, S = dataframe.S.values, h=0.001, run_time=10.0)\n",
    "\n",
    "        else:\n",
    "            # Choose a random set\n",
    "            set_index = randint(0, num_exps - 1) \n",
    "            exp = exps[set_index]\n",
    "            input_data = torch.tensor(alists[set_index][['S', 'lnk0']].values, dtype=torch.float32)\n",
    "        \n",
    "        expected_loss = 10\n",
    "        for phi in np.linspace(0, 1, 100):\n",
    "            exp.reset()\n",
    "            exp.step(phi, 1.)\n",
    "            if exp.loss() < expected_loss:\n",
    "                phi_iso = phi\n",
    "                expected_loss = exp.loss()    \n",
    "        \n",
    "        # compute distribution parameters (Normal)\n",
    "        mu, sigma = policy.forward(input_data, torch.tensor([[phi_iso]]))\n",
    "\n",
    "        # Sample some values from the actions distributions\n",
    "        programs = sample(mu, sigma, sample_size)\n",
    "        \n",
    "        # Fit the sampled data to the constraint [0,1]\n",
    "        constr_programs = programs.clone()\n",
    "        constr_programs[constr_programs > 1] = 1\n",
    "        constr_programs[constr_programs < 0] = 0\n",
    "        \n",
    "        J = 0\n",
    "        expected_loss = 0\n",
    "        for i in range(sample_size):\n",
    "            exp.reset()            \n",
    "            exp.run_all(constr_programs[i].data.numpy(), delta_taus)\n",
    "\n",
    "            error = exp.loss(weights)\n",
    "            expected_loss += error\n",
    "            log_prob_ = log_prob(programs[i], mu, sigma)\n",
    "            J += (error - baseline) * log_prob_ - beta * torch.exp(log_prob_) * log_prob_\n",
    "        \n",
    "        losses.append(expected_loss/sample_size)\n",
    "        perfect_loss.append(exp.perfect_loss(weights))\n",
    "        if (n + 1) % print_every == 0:\n",
    "            print(f\"Loss: {losses[-1]}, epoch: {n+1}/{num_episodes}\")\n",
    "\n",
    "        J_batch += J/sample_size\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            J_batch /= batch_size\n",
    "            optimizer.zero_grad()\n",
    "            # Calculate gradients\n",
    "            J_batch.backward()\n",
    "\n",
    "            if max_norm:\n",
    "                torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm)\n",
    "\n",
    "            # Apply gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # learning rate decay\n",
    "            scheduler.step()\n",
    "\n",
    "            J_batch = 0\n",
    "        \n",
    "    return np.array(losses), np.array(perfect_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [.25, .25, 10]\n",
    "L5_b1_iso = []\n",
    "PL5_b1_iso = []\n",
    "for i in range(5):\n",
    "    pol = PolicyGeneralISO(\n",
    "                phi = nn.Sequential(\n",
    "                    PermEqui2_max(2, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                ),\n",
    "                rho = nn.Sequential(\n",
    "                    nn.Linear(6, 6),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    nn.Linear(6, 6),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    Rho(n_steps=len(taus), hidden=6, in_dim=6, sigma_max=.3, sigma_min=.01),\n",
    "                )\n",
    "            )\n",
    "    l, p = reinforce_gen_iso(\n",
    "        alists = alists, \n",
    "        policy = pol, \n",
    "        delta_taus = taus, \n",
    "        num_episodes = 20_000, \n",
    "        sample_size = 10,\n",
    "        batch_size = 1, \n",
    "        lr = .05, \n",
    "        optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "        lr_decay_factor = 0.75,\n",
    "        lr_milestones = 5000,\n",
    "        print_every = 5000,\n",
    "        baseline = .55,\n",
    "        max_norm = 1.7,\n",
    "        max_rand_analytes = 30,\n",
    "        min_rand_analytes = 10,\n",
    "        rand_prob = 0.7\n",
    "    )\n",
    "    L5_b1_iso.append(l)\n",
    "    PL5_b1_iso.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot((np.array(L5_b1) - np.array(PL5_b1)).reshape((10, 200, 100)).mean(2).T)\n",
    "plt.ylim((0.3, 1))\n",
    "plt.title(\"Simple batch one small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot((np.array(L5_b1_iso) - np.array(PL5_b1_iso)).mean(0).reshape(-1, 100).mean(1), label = \"ISO\")\n",
    "plt.plot((np.array(L5_b1) - np.array(PL5_b1)).mean(0).reshape(-1, 100).mean(1), label = \"Small NN\")\n",
    "#plt.plot((np.array(L5_b1_big) - np.array(PL5_b1_big)).mean(0).reshape(-1, 100).mean(1), label = \"Big NN\")\n",
    "plt.title(\"Small rho NN vs Big rho NN\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(L5_b1) - np.array(PL5_b1)).mean(0).reshape(-1, 100).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
