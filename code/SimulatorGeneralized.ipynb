{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from separation_utility import *\n",
    "from torch import optim, tensor\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alists = []\n",
    "alists.append(pd.read_csv(f'../data/GilarSample.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Roca.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv(f'../data/Controlmix2.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_field(exp, taus, N = 200):\n",
    "    phis = np.linspace(0, 1, N)\n",
    "    losses = np.zeros((N, N))\n",
    "    j = 0\n",
    "    for phi1 in phis:\n",
    "        i = 0\n",
    "        for phi2 in phis:\n",
    "            exp.reset()\n",
    "            exp.run_all([phi1, phi2], taus)\n",
    "            losses[i, j] = exp.loss()\n",
    "            i += 1\n",
    "        j += 1\n",
    "    X, Y = np.meshgrid(phis, phis)\n",
    "    \n",
    "    return X, Y, losses\n",
    "\n",
    "def average_over_equal_intervals(arr, interval):\n",
    "    return np.mean(arr.reshape(-1, interval), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7445388629086223, epoch: 100/2000\n",
      "Loss: 1.0170569816298722, epoch: 200/2000\n",
      "Loss: 0.68236809486308, epoch: 300/2000\n",
      "Loss: 0.6799520671579715, epoch: 400/2000\n",
      "Loss: 1.050534947262894, epoch: 500/2000\n",
      "Loss: 0.780386113035355, epoch: 600/2000\n",
      "Loss: 0.6988977648113541, epoch: 700/2000\n",
      "Loss: 0.9433440217073807, epoch: 800/2000\n",
      "Loss: 0.7154878737090586, epoch: 900/2000\n",
      "Loss: 0.8969268508482584, epoch: 1000/2000\n",
      "Loss: 0.674074411330176, epoch: 1100/2000\n",
      "Loss: 0.7293916001050033, epoch: 1200/2000\n",
      "Loss: 0.6881110535044157, epoch: 1300/2000\n",
      "Loss: 0.7079102378072241, epoch: 1400/2000\n",
      "Loss: 0.6875166655089711, epoch: 1500/2000\n",
      "Loss: 0.6579160588269175, epoch: 1600/2000\n",
      "Loss: 0.6907639568968329, epoch: 1700/2000\n",
      "Loss: 0.6696473818667967, epoch: 1800/2000\n",
      "Loss: 0.6788520841131311, epoch: 1900/2000\n",
      "Loss: 0.5842320194847973, epoch: 2000/2000\n",
      "Loss: 1.0699037513725527, epoch: 100/2000\n",
      "Loss: 1.0196179767170555, epoch: 200/2000\n",
      "Loss: 1.0057416851869987, epoch: 300/2000\n",
      "Loss: 1.0137692256415531, epoch: 400/2000\n",
      "Loss: 1.0064568321597251, epoch: 500/2000\n",
      "Loss: 1.0089995886748035, epoch: 600/2000\n",
      "Loss: 1.0138936014698028, epoch: 700/2000\n",
      "Loss: 1.0212961023115912, epoch: 800/2000\n",
      "Loss: 1.0127477829424596, epoch: 900/2000\n",
      "Loss: 1.0165426500621717, epoch: 1000/2000\n",
      "Loss: 0.9762964970164891, epoch: 1100/2000\n",
      "Loss: 0.990343385738619, epoch: 1200/2000\n",
      "Loss: 0.9967258240605258, epoch: 1300/2000\n",
      "Loss: 1.0299889713926287, epoch: 1400/2000\n",
      "Loss: 1.0425364146320153, epoch: 1500/2000\n",
      "Loss: 1.0875718279708875, epoch: 1600/2000\n",
      "Loss: 1.0377500099179584, epoch: 1700/2000\n",
      "Loss: 0.9240127934883885, epoch: 1800/2000\n",
      "Loss: 1.0375670556365333, epoch: 1900/2000\n",
      "Loss: 1.0264432754938153, epoch: 2000/2000\n",
      "Loss: 0.8476144506535672, epoch: 100/2000\n",
      "Loss: 0.6105833361420862, epoch: 200/2000\n",
      "Loss: 0.5726549638054169, epoch: 300/2000\n",
      "Loss: 0.5401503699639503, epoch: 400/2000\n",
      "Loss: 0.5842098984443621, epoch: 500/2000\n",
      "Loss: 0.5927065467239419, epoch: 600/2000\n",
      "Loss: 0.551134397290429, epoch: 700/2000\n",
      "Loss: 0.5807437350138817, epoch: 800/2000\n",
      "Loss: 0.5691127167306462, epoch: 900/2000\n",
      "Loss: 0.5600378183620724, epoch: 1000/2000\n",
      "Loss: 0.5861149514235028, epoch: 1100/2000\n",
      "Loss: 0.5896722453712652, epoch: 1200/2000\n",
      "Loss: 0.5989474816839703, epoch: 1300/2000\n",
      "Loss: 0.5838091361288777, epoch: 1400/2000\n",
      "Loss: 0.6049824484383357, epoch: 1500/2000\n",
      "Loss: 0.5874147289795284, epoch: 1600/2000\n",
      "Loss: 0.5891999962129716, epoch: 1700/2000\n",
      "Loss: 0.5850021959945717, epoch: 1800/2000\n",
      "Loss: 0.5902997321353547, epoch: 1900/2000\n",
      "Loss: 0.5502171257794329, epoch: 2000/2000\n",
      "Loss: 1.74613202456429, epoch: 100/2000\n",
      "Loss: 1.4368289937824734, epoch: 200/2000\n",
      "Loss: 1.9111253570724862, epoch: 300/2000\n",
      "Loss: 1.822167182039213, epoch: 400/2000\n",
      "Loss: 1.5778346439896498, epoch: 500/2000\n",
      "Loss: 1.9110696528745101, epoch: 600/2000\n",
      "Loss: 0.6909000854443775, epoch: 700/2000\n",
      "Loss: 0.620639602657018, epoch: 800/2000\n",
      "Loss: 0.734869322793964, epoch: 900/2000\n",
      "Loss: 0.8104852674079666, epoch: 1000/2000\n",
      "Loss: 0.7508570460042752, epoch: 1100/2000\n",
      "Loss: 0.7497792604441544, epoch: 1200/2000\n",
      "Loss: 0.7648579824106295, epoch: 1300/2000\n",
      "Loss: 0.744005530043959, epoch: 1400/2000\n",
      "Loss: 0.5602297190863117, epoch: 1500/2000\n",
      "Loss: 0.5967800332424154, epoch: 1600/2000\n",
      "Loss: 0.5759757935226514, epoch: 1700/2000\n",
      "Loss: 0.5630668126235903, epoch: 1800/2000\n",
      "Loss: 0.6106054820395929, epoch: 1900/2000\n",
      "Loss: 0.5942731202247362, epoch: 2000/2000\n",
      "Loss: 0.7651224769111045, epoch: 100/2000\n",
      "Loss: 0.7194330810790582, epoch: 200/2000\n",
      "Loss: 0.787202284500933, epoch: 300/2000\n",
      "Loss: 1.1659273513606017, epoch: 400/2000\n",
      "Loss: 0.6354588816163039, epoch: 500/2000\n",
      "Loss: 0.6122044598647708, epoch: 600/2000\n",
      "Loss: 0.5921855822078997, epoch: 700/2000\n",
      "Loss: 0.6127812561742505, epoch: 800/2000\n",
      "Loss: 0.6235320550138784, epoch: 900/2000\n",
      "Loss: 0.647684205736616, epoch: 1000/2000\n",
      "Loss: 0.5785896191765384, epoch: 1100/2000\n",
      "Loss: 0.5655964170412624, epoch: 1200/2000\n",
      "Loss: 0.5863871637667643, epoch: 1300/2000\n",
      "Loss: 0.5730024637505243, epoch: 1400/2000\n",
      "Loss: 0.5788746052550546, epoch: 1500/2000\n",
      "Loss: 0.5883806199695369, epoch: 1600/2000\n",
      "Loss: 0.6349922549692587, epoch: 1700/2000\n",
      "Loss: 0.6193445130295308, epoch: 1800/2000\n",
      "Loss: 0.5738940413412689, epoch: 1900/2000\n",
      "Loss: 0.5698868069839189, epoch: 2000/2000\n",
      "Loss: 1.7348805493287025, epoch: 100/2000\n",
      "Loss: 1.0613005020649409, epoch: 200/2000\n",
      "Loss: 1.008178504222049, epoch: 300/2000\n",
      "Loss: 1.0108563212679096, epoch: 400/2000\n",
      "Loss: 1.00813504605073, epoch: 500/2000\n",
      "Loss: 1.0115812780945437, epoch: 600/2000\n",
      "Loss: 1.0061926099773069, epoch: 700/2000\n",
      "Loss: 1.0080025716697703, epoch: 800/2000\n",
      "Loss: 1.009987741095312, epoch: 900/2000\n",
      "Loss: 1.0059614225042557, epoch: 1000/2000\n",
      "Loss: 1.008837286989776, epoch: 1100/2000\n",
      "Loss: 1.0068776768038257, epoch: 1200/2000\n",
      "Loss: 1.0129172576100092, epoch: 1300/2000\n",
      "Loss: 1.0067083384653954, epoch: 1400/2000\n",
      "Loss: 1.007528451746637, epoch: 1500/2000\n",
      "Loss: 1.0062467031236089, epoch: 1600/2000\n",
      "Loss: 1.0045696799716202, epoch: 1700/2000\n",
      "Loss: 1.0088870656877398, epoch: 1800/2000\n",
      "Loss: 1.0056132326987044, epoch: 1900/2000\n",
      "Loss: 1.0074451807281934, epoch: 2000/2000\n",
      "Loss: 0.6993011104937417, epoch: 100/2000\n",
      "Loss: 0.9982730181095125, epoch: 200/2000\n",
      "Loss: 1.689604630220123, epoch: 300/2000\n",
      "Loss: 1.9111214565906856, epoch: 400/2000\n",
      "Loss: 1.9098229429823927, epoch: 500/2000\n",
      "Loss: 1.4672814817116984, epoch: 600/2000\n",
      "Loss: 1.4739101970782014, epoch: 700/2000\n",
      "Loss: 1.1801373331276803, epoch: 800/2000\n",
      "Loss: 1.3667231243304827, epoch: 900/2000\n",
      "Loss: 1.1744531134641047, epoch: 1000/2000\n",
      "Loss: 1.223087252294317, epoch: 1100/2000\n",
      "Loss: 1.1806312193031427, epoch: 1200/2000\n",
      "Loss: 1.4268331482439636, epoch: 1300/2000\n",
      "Loss: 1.190490133565186, epoch: 1400/2000\n",
      "Loss: 1.193499470805384, epoch: 1500/2000\n",
      "Loss: 1.2733511877241088, epoch: 1600/2000\n",
      "Loss: 1.3972432699659436, epoch: 1700/2000\n",
      "Loss: 1.2978470282778474, epoch: 1800/2000\n",
      "Loss: 1.1560765069998946, epoch: 1900/2000\n",
      "Loss: 1.1900701738697557, epoch: 2000/2000\n",
      "Loss: 1.6648537900889342, epoch: 100/2000\n",
      "Loss: 1.861744617941564, epoch: 200/2000\n",
      "Loss: 1.8941261881185962, epoch: 300/2000\n",
      "Loss: 1.4834024325774053, epoch: 400/2000\n",
      "Loss: 1.02895437610783, epoch: 500/2000\n",
      "Loss: 0.7527039325372701, epoch: 600/2000\n",
      "Loss: 0.748804601697768, epoch: 700/2000\n",
      "Loss: 0.7402193461043305, epoch: 800/2000\n",
      "Loss: 0.7676165901985736, epoch: 900/2000\n",
      "Loss: 0.7475050042894835, epoch: 1000/2000\n",
      "Loss: 0.736401414617724, epoch: 1100/2000\n",
      "Loss: 0.8014975381130528, epoch: 1200/2000\n",
      "Loss: 0.756002693489369, epoch: 1300/2000\n",
      "Loss: 0.7551994179437461, epoch: 1400/2000\n",
      "Loss: 0.7545502566569582, epoch: 1500/2000\n",
      "Loss: 0.7245137186694993, epoch: 1600/2000\n",
      "Loss: 0.7106431813189011, epoch: 1700/2000\n",
      "Loss: 0.7508181992107736, epoch: 1800/2000\n",
      "Loss: 0.6995554207981192, epoch: 1900/2000\n",
      "Loss: 0.6365920340971173, epoch: 2000/2000\n",
      "Loss: 1.036935484947295, epoch: 100/2000\n",
      "Loss: 0.6868305034802983, epoch: 200/2000\n",
      "Loss: 0.7530800578555581, epoch: 300/2000\n",
      "Loss: 0.7166202750777145, epoch: 400/2000\n",
      "Loss: 0.6325747755380036, epoch: 500/2000\n",
      "Loss: 0.6346370700878334, epoch: 600/2000\n",
      "Loss: 0.7210200577114751, epoch: 700/2000\n",
      "Loss: 0.5835071605263588, epoch: 800/2000\n",
      "Loss: 0.5865059066313154, epoch: 900/2000\n",
      "Loss: 0.582500410550059, epoch: 1000/2000\n",
      "Loss: 0.5798915196744626, epoch: 1100/2000\n",
      "Loss: 0.5891243519782821, epoch: 1200/2000\n",
      "Loss: 0.5987332397538502, epoch: 1300/2000\n",
      "Loss: 0.5581554597690033, epoch: 1400/2000\n",
      "Loss: 0.5591943044121953, epoch: 1500/2000\n",
      "Loss: 0.5877408425005919, epoch: 1600/2000\n",
      "Loss: 0.5676396290197323, epoch: 1700/2000\n",
      "Loss: 0.5871042980635504, epoch: 1800/2000\n",
      "Loss: 0.5642459313266193, epoch: 1900/2000\n",
      "Loss: 0.5857073669832614, epoch: 2000/2000\n",
      "Loss: 1.5115670001638448, epoch: 100/2000\n",
      "Loss: 1.787941904269393, epoch: 200/2000\n",
      "Loss: 0.9417142330020869, epoch: 300/2000\n",
      "Loss: 0.9629359121666121, epoch: 400/2000\n",
      "Loss: 0.8927034224910981, epoch: 500/2000\n",
      "Loss: 0.7437838405764091, epoch: 600/2000\n",
      "Loss: 0.7038499149735007, epoch: 700/2000\n",
      "Loss: 0.9055284115706318, epoch: 800/2000\n",
      "Loss: 0.7232583187920418, epoch: 900/2000\n",
      "Loss: 0.7197948302879916, epoch: 1000/2000\n",
      "Loss: 0.633278105721964, epoch: 1100/2000\n",
      "Loss: 0.5966270180383603, epoch: 1200/2000\n",
      "Loss: 0.6442257847396622, epoch: 1300/2000\n",
      "Loss: 0.5937099609723873, epoch: 1400/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.583569068799548, epoch: 1500/2000\n",
      "Loss: 0.5776934827012188, epoch: 1600/2000\n",
      "Loss: 0.5722675845840844, epoch: 1700/2000\n",
      "Loss: 0.5856392612137542, epoch: 1800/2000\n",
      "Loss: 0.5486689668739066, epoch: 1900/2000\n",
      "Loss: 0.5722237074163632, epoch: 2000/2000\n",
      "Loss: 0.7614946405219418, epoch: 100/2000\n",
      "Loss: 0.7003723012051141, epoch: 200/2000\n",
      "Loss: 0.9818921602869899, epoch: 300/2000\n",
      "Loss: 0.6830127977484455, epoch: 400/2000\n",
      "Loss: 0.6068439418270161, epoch: 500/2000\n",
      "Loss: 0.6689394424702512, epoch: 600/2000\n",
      "Loss: 0.634258563702068, epoch: 700/2000\n",
      "Loss: 0.5839292949536745, epoch: 800/2000\n",
      "Loss: 0.5686169273840258, epoch: 900/2000\n",
      "Loss: 0.5997516996493941, epoch: 1000/2000\n",
      "Loss: 0.5533495394151489, epoch: 1100/2000\n",
      "Loss: 0.5989707094485731, epoch: 1200/2000\n",
      "Loss: 0.5976724911105992, epoch: 1300/2000\n",
      "Loss: 0.5680820994304331, epoch: 1400/2000\n",
      "Loss: 0.6035288551217378, epoch: 1500/2000\n",
      "Loss: 0.5662350125541302, epoch: 1600/2000\n",
      "Loss: 0.5494806450957767, epoch: 1700/2000\n",
      "Loss: 0.5802018998416566, epoch: 1800/2000\n",
      "Loss: 0.5772690367474838, epoch: 1900/2000\n",
      "Loss: 0.5694776589678741, epoch: 2000/2000\n",
      "Loss: 0.8147635517268152, epoch: 100/2000\n",
      "Loss: 0.7004995759306484, epoch: 200/2000\n",
      "Loss: 0.7323281857359658, epoch: 300/2000\n",
      "Loss: 0.7002712241240008, epoch: 400/2000\n",
      "Loss: 1.2279145824807745, epoch: 500/2000\n",
      "Loss: 1.0011919387461141, epoch: 600/2000\n",
      "Loss: 0.8731104807299579, epoch: 700/2000\n",
      "Loss: 0.7070182904056251, epoch: 800/2000\n",
      "Loss: 0.7508782518964268, epoch: 900/2000\n",
      "Loss: 0.7268496951733244, epoch: 1000/2000\n",
      "Loss: 0.6920671125234408, epoch: 1100/2000\n",
      "Loss: 0.6672397224574996, epoch: 1200/2000\n",
      "Loss: 0.6967484734445041, epoch: 1300/2000\n",
      "Loss: 0.6734722874227077, epoch: 1400/2000\n",
      "Loss: 0.698444348664416, epoch: 1500/2000\n",
      "Loss: 0.6998202548962033, epoch: 1600/2000\n",
      "Loss: 0.662719767946542, epoch: 1700/2000\n",
      "Loss: 0.6935063018766616, epoch: 1800/2000\n",
      "Loss: 0.6915615122026799, epoch: 1900/2000\n",
      "Loss: 0.6712431066242754, epoch: 2000/2000\n",
      "Loss: 1.0099007482401212, epoch: 100/2000\n",
      "Loss: 1.1472785639171792, epoch: 200/2000\n",
      "Loss: 0.8553503987026809, epoch: 300/2000\n",
      "Loss: 0.68304287131989, epoch: 400/2000\n",
      "Loss: 0.6110038649446317, epoch: 500/2000\n",
      "Loss: 0.5835780802218951, epoch: 600/2000\n",
      "Loss: 0.6113913747793154, epoch: 700/2000\n",
      "Loss: 0.6165964014925289, epoch: 800/2000\n",
      "Loss: 0.9085888402269593, epoch: 900/2000\n",
      "Loss: 0.5759178162121574, epoch: 1000/2000\n",
      "Loss: 0.5892850661994897, epoch: 1100/2000\n",
      "Loss: 0.5635416421111776, epoch: 1200/2000\n",
      "Loss: 0.5771258909511626, epoch: 1300/2000\n",
      "Loss: 0.5907425866833647, epoch: 1400/2000\n",
      "Loss: 0.5645456620650625, epoch: 1500/2000\n",
      "Loss: 0.5594415402286517, epoch: 1600/2000\n",
      "Loss: 0.6037334112577964, epoch: 1700/2000\n",
      "Loss: 0.5641600799010675, epoch: 1800/2000\n",
      "Loss: 0.590934307384789, epoch: 1900/2000\n",
      "Loss: 0.5610905620087039, epoch: 2000/2000\n",
      "Loss: 0.7160589172539006, epoch: 100/2000\n",
      "Loss: 1.0047733074301073, epoch: 200/2000\n",
      "Loss: 0.7542625648198801, epoch: 300/2000\n",
      "Loss: 0.6519790362716589, epoch: 400/2000\n",
      "Loss: 0.722166549595579, epoch: 500/2000\n",
      "Loss: 1.1425277903415605, epoch: 600/2000\n",
      "Loss: 0.7223293317982609, epoch: 700/2000\n",
      "Loss: 0.7190095848374828, epoch: 800/2000\n",
      "Loss: 0.69523611495979, epoch: 900/2000\n",
      "Loss: 0.6912402088797849, epoch: 1000/2000\n",
      "Loss: 0.705374062857316, epoch: 1100/2000\n",
      "Loss: 0.6869063149417072, epoch: 1200/2000\n",
      "Loss: 0.6719860771599444, epoch: 1300/2000\n",
      "Loss: 0.6738337392771828, epoch: 1400/2000\n",
      "Loss: 0.6634950741502836, epoch: 1500/2000\n",
      "Loss: 0.6712829148321796, epoch: 1600/2000\n",
      "Loss: 0.6975281318806597, epoch: 1700/2000\n",
      "Loss: 0.6780927661538987, epoch: 1800/2000\n",
      "Loss: 0.6799089406978454, epoch: 1900/2000\n",
      "Loss: 0.6968494408574608, epoch: 2000/2000\n",
      "Loss: 0.7506470645065604, epoch: 100/2000\n",
      "Loss: 0.7285269309335163, epoch: 200/2000\n",
      "Loss: 0.6508180115050557, epoch: 300/2000\n",
      "Loss: 0.6033418966022446, epoch: 400/2000\n",
      "Loss: 0.5976992540195943, epoch: 500/2000\n",
      "Loss: 0.5916652391387786, epoch: 600/2000\n",
      "Loss: 0.6439426446826229, epoch: 700/2000\n",
      "Loss: 0.586391709516425, epoch: 800/2000\n",
      "Loss: 0.5978115881891062, epoch: 900/2000\n",
      "Loss: 0.6822439908384009, epoch: 1000/2000\n",
      "Loss: 0.6263423521897409, epoch: 1100/2000\n",
      "Loss: 0.6241348377180137, epoch: 1200/2000\n",
      "Loss: 0.5671901535229305, epoch: 1300/2000\n",
      "Loss: 0.5448498565704162, epoch: 1400/2000\n",
      "Loss: 0.5533304041222793, epoch: 1500/2000\n",
      "Loss: 0.5667111621318359, epoch: 1600/2000\n",
      "Loss: 0.5395014392499913, epoch: 1700/2000\n",
      "Loss: 0.5763691996678899, epoch: 1800/2000\n",
      "Loss: 0.6005477212564424, epoch: 1900/2000\n",
      "Loss: 0.5635977322057208, epoch: 2000/2000\n",
      "Loss: 0.6863519758139469, epoch: 100/2000\n",
      "Loss: 0.5919191577566403, epoch: 200/2000\n",
      "Loss: 0.5848239126046927, epoch: 300/2000\n",
      "Loss: 0.5833342602352494, epoch: 400/2000\n",
      "Loss: 0.5721583547455801, epoch: 500/2000\n",
      "Loss: 0.5608588952528543, epoch: 600/2000\n",
      "Loss: 0.6095035287570347, epoch: 700/2000\n",
      "Loss: 0.5770595148235051, epoch: 800/2000\n",
      "Loss: 0.570639020407985, epoch: 900/2000\n",
      "Loss: 0.5996939468576394, epoch: 1000/2000\n",
      "Loss: 0.5695114430054177, epoch: 1100/2000\n",
      "Loss: 0.5728957334084046, epoch: 1200/2000\n",
      "Loss: 0.5742663397596701, epoch: 1300/2000\n",
      "Loss: 0.5604737835002409, epoch: 1400/2000\n",
      "Loss: 0.5852516467887, epoch: 1500/2000\n",
      "Loss: 0.582269906180926, epoch: 1600/2000\n",
      "Loss: 0.5511067822556949, epoch: 1700/2000\n",
      "Loss: 0.5473432372613833, epoch: 1800/2000\n",
      "Loss: 0.5671147979022154, epoch: 1900/2000\n",
      "Loss: 0.5880892469538664, epoch: 2000/2000\n",
      "Loss: 0.872382683542843, epoch: 100/2000\n",
      "Loss: 1.0446205305544194, epoch: 200/2000\n",
      "Loss: 1.0101824019043124, epoch: 300/2000\n",
      "Loss: 1.0090286051358586, epoch: 400/2000\n",
      "Loss: 1.0075645196643592, epoch: 500/2000\n",
      "Loss: 1.0036169237822086, epoch: 600/2000\n",
      "Loss: 1.0142303896317286, epoch: 700/2000\n",
      "Loss: 1.0061106754934126, epoch: 800/2000\n",
      "Loss: 1.08974419236352, epoch: 900/2000\n",
      "Loss: 1.0955978372960404, epoch: 1000/2000\n",
      "Loss: 1.0314973341377973, epoch: 1100/2000\n",
      "Loss: 1.022455819815488, epoch: 1200/2000\n",
      "Loss: 1.0218067925343925, epoch: 1300/2000\n",
      "Loss: 1.034175709951242, epoch: 1400/2000\n",
      "Loss: 1.0711696756651263, epoch: 1500/2000\n",
      "Loss: 1.0283841980745254, epoch: 1600/2000\n",
      "Loss: 1.0301112275029738, epoch: 1700/2000\n",
      "Loss: 0.9954345879939244, epoch: 1800/2000\n",
      "Loss: 1.0397233758440358, epoch: 1900/2000\n",
      "Loss: 1.013660335670528, epoch: 2000/2000\n",
      "Loss: 1.4978244720313845, epoch: 100/2000\n",
      "Loss: 1.2751995336386288, epoch: 200/2000\n",
      "Loss: 0.7388189227950084, epoch: 300/2000\n",
      "Loss: 0.5740862990627752, epoch: 400/2000\n",
      "Loss: 0.5575030643352805, epoch: 500/2000\n",
      "Loss: 0.553787893241825, epoch: 600/2000\n",
      "Loss: 0.6250622067288458, epoch: 700/2000\n",
      "Loss: 0.5781463884143562, epoch: 800/2000\n",
      "Loss: 0.5986927626656262, epoch: 900/2000\n",
      "Loss: 0.6806542642711415, epoch: 1000/2000\n",
      "Loss: 0.5560678473629679, epoch: 1100/2000\n",
      "Loss: 0.5695450427205144, epoch: 1200/2000\n",
      "Loss: 0.5747927366274449, epoch: 1300/2000\n",
      "Loss: 0.5920341003684497, epoch: 1400/2000\n",
      "Loss: 0.5722123360494561, epoch: 1500/2000\n",
      "Loss: 0.5713640120694852, epoch: 1600/2000\n",
      "Loss: 0.5447127363606099, epoch: 1700/2000\n",
      "Loss: 0.5803149784161192, epoch: 1800/2000\n",
      "Loss: 0.5762530729557201, epoch: 1900/2000\n",
      "Loss: 0.5797336435509433, epoch: 2000/2000\n",
      "Loss: 0.8499363867141797, epoch: 100/2000\n",
      "Loss: 0.8699978700341899, epoch: 200/2000\n",
      "Loss: 0.7896153452280759, epoch: 300/2000\n",
      "Loss: 0.7455233078217179, epoch: 400/2000\n",
      "Loss: 1.0648836498427867, epoch: 500/2000\n",
      "Loss: 0.5932462906681601, epoch: 600/2000\n",
      "Loss: 0.6042928241428782, epoch: 700/2000\n",
      "Loss: 0.6025747111717218, epoch: 800/2000\n",
      "Loss: 0.5488351890243346, epoch: 900/2000\n",
      "Loss: 0.6285984780142176, epoch: 1000/2000\n",
      "Loss: 0.5895104037548873, epoch: 1100/2000\n",
      "Loss: 0.6054520451655211, epoch: 1200/2000\n",
      "Loss: 0.5708776565238589, epoch: 1300/2000\n",
      "Loss: 0.6324589515512234, epoch: 1400/2000\n",
      "Loss: 0.5943331578743871, epoch: 1500/2000\n",
      "Loss: 0.5754615103901342, epoch: 1600/2000\n",
      "Loss: 0.5912481473100568, epoch: 1700/2000\n",
      "Loss: 0.5604592300026253, epoch: 1800/2000\n",
      "Loss: 0.5636695443763649, epoch: 1900/2000\n",
      "Loss: 0.6339757549914617, epoch: 2000/2000\n",
      "Loss: 0.7616301031861666, epoch: 100/2000\n",
      "Loss: 1.1916488296227101, epoch: 200/2000\n",
      "Loss: 0.8513558164660211, epoch: 300/2000\n",
      "Loss: 0.8190027787806453, epoch: 400/2000\n",
      "Loss: 0.7144341226310853, epoch: 500/2000\n",
      "Loss: 0.5976463356928419, epoch: 600/2000\n",
      "Loss: 0.5983028496271569, epoch: 700/2000\n",
      "Loss: 0.5831655101486982, epoch: 800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6099782446482876, epoch: 900/2000\n",
      "Loss: 0.6099015180492293, epoch: 1000/2000\n",
      "Loss: 0.5561390654747, epoch: 1100/2000\n",
      "Loss: 0.5726311905564787, epoch: 1200/2000\n",
      "Loss: 0.5815248616861004, epoch: 1300/2000\n",
      "Loss: 0.5672312440890783, epoch: 1400/2000\n",
      "Loss: 0.6109365015995468, epoch: 1500/2000\n",
      "Loss: 0.5746759059936306, epoch: 1600/2000\n",
      "Loss: 0.572588051518008, epoch: 1700/2000\n",
      "Loss: 0.552369311427044, epoch: 1800/2000\n",
      "Loss: 0.5681415402451359, epoch: 1900/2000\n",
      "Loss: 0.5963962841447517, epoch: 2000/2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "taus = [.25, .25, 10]\n",
    "\n",
    "time_start_pp = time.perf_counter()\n",
    "exp = ExperimentAnalytes(k0 = alists[0].k0.values, S = alists[0].S.values, h=0.001,run_time=10.0)\n",
    "for i in range(20):\n",
    "    _, _, mus, _ = reinforce_single_from_gen(\n",
    "        alist=alists[0], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=2000, \n",
    "        sample_size=10, \n",
    "        lr=.05, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=1000,\n",
    "        print_every=100,\n",
    "        baseline=0.55,\n",
    "        max_norm=2.\n",
    "    )\n",
    "    exp.reset()\n",
    "    exp.run_all(mus[-1,:], taus)\n",
    "    \n",
    "time_end_pp = time.perf_counter()\n",
    "# time 523.31177600672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.665162367281697"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.514 - (time_end_pp - time_start_pp)/1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Occurrences')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(losses_gen_pp, bins=50)\n",
    "plt.title(f\"Final Result Distribution for GenModel (PeterPeptides) Not in Training\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Occurrences')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(losses_from_gen_pp, bins=50)\n",
    "plt.title(f\"Final Result Distribution for GenModel + FineTune(PeterPeptides) Not in Training\")\n",
    "plt.xlabel(\"Loss\")\n",
    "plt.ylabel(\"Occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gillar\n",
    "taus = [.25, .25, 10]\n",
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "reinforce_gen(\n",
    "    alists = alists, \n",
    "    policy = pol, \n",
    "    delta_taus = taus, \n",
    "    num_episodes = 40_000, \n",
    "    sample_size = 10,\n",
    "    batch_size = 1, \n",
    "    lr = .05, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "    lr_decay_factor = 0.75,\n",
    "    lr_milestones = 5000,\n",
    "    print_every = 20_000,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.5,\n",
    "    max_rand_analytes = 30,\n",
    "    min_rand_analytes = 15,\n",
    "    rand_prob = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(average_over_equal_intervals(np.array(L8).mean(0), 500), label=\"L8\")\n",
    "plt.title(\"Loss (average of 500 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, sig = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "exp.run_all(mu.detach().numpy(), taus)\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Gen)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_gen(\n",
    "        alist=alists[0], \n",
    "        policy=pol, \n",
    "        delta_taus=taus, \n",
    "        num_episodes=2000, \n",
    "        sample_size=10, \n",
    "        lr=.05, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=1000,\n",
    "        print_every=100,\n",
    "        baseline=0.55,\n",
    "        max_norm=2.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(mus[-1,:], taus)\n",
    "exp.print_analytes(title=f\"Solvent Strength Program(Iso)\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "exp.run_all(B, taus)\n",
    "exp.print_analytes(title=f\"Best Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(3, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = RhoTime(n_steps=3, hidden=5, in_dim=3, sigma_max=.3, sigma_min=.02)\n",
    "        )\n",
    "losses = reinforce_delta_tau_gen(\n",
    "    alists = alists, \n",
    "    policy = pol,\n",
    "    num_episodes = 10000, \n",
    "    batch_size = 10, \n",
    "    lr = .1, \n",
    "    optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "    lr_decay_factor= 0.75,\n",
    "    lr_milestones=1000,\n",
    "    print_every = 100,\n",
    "    baseline = .55,\n",
    "    max_norm = 1.2,\n",
    "    max_rand_analytes = 35,\n",
    "    min_rand_analytes = 18,\n",
    "    rand_prob = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 200000, 200),average_over_equal_intervals(losses[0], 1000))\n",
    "plt.title(\"Loss [variable delta tau] (average of 1000 random sets)\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 6\n",
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu, _ = pol(torch.Tensor(alists[i][['S', 'lnk0']].values))\n",
    "mu = mu.tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, B, mus, sigmas = reinforce_single_from_delta_tau_gen(\n",
    "        alist=alists[i], \n",
    "        policy=pol,\n",
    "        num_episodes=5000, \n",
    "        batch_size=10, \n",
    "        lr=.1, \n",
    "        optim=torch.optim.SGD,\n",
    "        lr_decay_factor=.5,\n",
    "        lr_milestones=500,\n",
    "        print_every=500,\n",
    "        baseline=0.65,\n",
    "        max_norm=1.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ExperimentAnalytes(k0 = alists[i].k0.values, S = alists[i].S.values, h=0.001,run_time=10.0)\n",
    "mu = mus[-1].tolist()\n",
    "mu.append(10.)\n",
    "exp.run_all(mu[0:3], mu[3:])\n",
    "\n",
    "exp.print_analytes(title=f\"Solvent Strength Program\\nLoss:{round(exp.loss(), 4)}\", rc=(10,10), angle=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGeneralISO(nn.Module):\n",
    "    def __init__(self, \n",
    "            phi: nn.Module,\n",
    "            rho: nn.Module\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        phi: nn.Module\n",
    "            The network that encodes the analyte set to a single \n",
    "            vector (embedding)\n",
    "        rho: nn.Module\n",
    "            The network that outputs the programe for separation\n",
    "            returns mean and standard deviation of the action space\n",
    "\n",
    "        Ex:\n",
    "        For a 4 step solvent gradient programe the generalized policy \n",
    "        with 3 elements embedding for the analyte set and intermediate\n",
    "        layers of 5 neurons.\n",
    "        policy = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui1_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui1_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui1_max(5, 3),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = Rho(4, 5, 3, .3, .05)\n",
    "        )\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.phi = phi\n",
    "        self.rho = rho\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        phi_output = self.phi(x)\n",
    "        sum_output = phi_output.sum(0, keepdim=True)\n",
    "        sum_output = torch.cat([sum_output, y], 1)\n",
    "        mu, sigma = self.rho(sum_output)\n",
    "        return mu, sigma\n",
    "\n",
    "#############################################################################\n",
    "def reinforce_gen_iso(\n",
    "        alists: Iterable[pd.DataFrame],\n",
    "        policy: PolicyGeneral, \n",
    "        delta_taus: Iterable[float], \n",
    "        num_episodes: int = 1000, \n",
    "        sample_size: int = 10,\n",
    "        batch_size : int = 10,\n",
    "        lr: float = 1., \n",
    "        optim = torch.optim.SGD,\n",
    "        lr_decay_factor: float = 1.,\n",
    "        lr_milestones: Union[int, Iterable[int]] = 1000,\n",
    "        rand_prob: float = .2,\n",
    "        max_rand_analytes: int = 30,\n",
    "        min_rand_analytes: int = 10,\n",
    "        print_every: int = 100,\n",
    "        baseline: float = 0.,\n",
    "        max_norm: float = None,\n",
    "        beta: float = .0,\n",
    "        weights: list = [1., 1.]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Run Reinforcement Learning for a single set learning.\n",
    "\n",
    "    alists: Iterable[pd.DataFrame]\n",
    "        A list with pd.Dataframes for each dataset used to train on. \n",
    "    policy: PolicyGeneral\n",
    "        The policy that learns the optimal values for the solvent\n",
    "        strength program.\n",
    "    delta_taus: Iterable[float]\n",
    "        Iterable list with the points of solvent strength change.\n",
    "        MUST be the same length as policy.n_steps\n",
    "    num_episodes = 1000\n",
    "        Number of learning steps.\n",
    "    sample_size = 10\n",
    "        Number of samples taken from the action distribution to perform \n",
    "        Expected loss for the distribution of actions.\n",
    "    batch_size:\n",
    "        Number of experiments to run in order to aproximate the true gradient.\n",
    "    lr = 1.\n",
    "        Learning rate.\n",
    "    optim = torch.optim.SGD\n",
    "        Optimizer that performs weight update using gradients.\n",
    "        By defauld is Stochastic Gradient Descent.\n",
    "    lr_decay_factor: float\n",
    "        Learning rate decay factor used for the LRScheduler.\n",
    "        lr is updated according to lr = lr ** lr_decay_factor.\n",
    "    lr_milestones: Union[int, Iterable[int]]\n",
    "        Milestone episode/s to update the learning rate.\n",
    "        If it is int StepLR is used where lr is changed every lr_milestones.\n",
    "        If it is a list of ints then at that specific episode the lr\n",
    "        will be changed.\n",
    "    rand_prob: float = .2\n",
    "        The probability to draw a random subset from all the analytes.\n",
    "        1 - rand_prob is the probability to use a \"real\" set (provided in\n",
    "        alists).\n",
    "    max_rand_analytes: int = 30\n",
    "        The maximum number of analytes in the randomly drawn set.\n",
    "    min_rand_analytes: int = 10\n",
    "        The minimum number of analytes in the randomly drawn set.\n",
    "    print_every = 100,\n",
    "        Number of episodes to print the average loss on.\n",
    "    weights = [1., 1.]\n",
    "        Weigths of the errors to consider, first one is for the Placement Error,\n",
    "        second one is for Overlap Error, By default both have the same wights.\n",
    "    baseline = 0.\n",
    "        Baseline value for the REINFORCE algorithm.\n",
    "    max_norm = None\n",
    "        Maximal value for the Neural Network Norm2.\n",
    "    beta = .0\n",
    "        Entropy Regularization term, is used for more exploration.\n",
    "        By defauld is disabled.\n",
    "    Returns\n",
    "    -------\n",
    "    (losses, best_program, mus, sigmas)\n",
    "    losses: np.ndarray\n",
    "        Expected loss of the action distribution over the whole learning\n",
    "        process.\n",
    "    \"\"\"\n",
    "\n",
    "    losses = []\n",
    "    perfect_loss = []\n",
    "    exps = []\n",
    "\n",
    "    # Make ExperimentAnalytes object for the given analyte sets for time saving purpose\n",
    "    for alist in alists:\n",
    "        exps.append(ExperimentAnalytes(k0 = alist.k0.values, S = alist.S.values, h=0.001, run_time=10.0))\n",
    "\n",
    "    num_exps = len(alists)\n",
    "\n",
    "    all_analytes = pd.concat(alists, sort=True)[['k0', 'S', 'lnk0']]\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim(policy.parameters(), lr)\n",
    "\n",
    "    # LR sheduler\n",
    "    if isinstance(lr_milestones, list) or isinstance(lr_milestones, np.ndarray):\n",
    "        scheduler = MultiStepLR(optimizer, lr_milestones, gamma=lr_decay_factor)\n",
    "    else:\n",
    "        scheduler = StepLR(optimizer, lr_milestones, gamma=lr_decay_factor)\n",
    "\n",
    "    J_batch = 0\n",
    "\n",
    "    for n in range(num_episodes):\n",
    "        # the set to use for the experiment.\n",
    "        if random() < rand_prob:\n",
    "            dataframe = all_analytes.sample(randint(min_rand_analytes, max_rand_analytes))\n",
    "            input_data = torch.tensor(dataframe[['S', 'lnk0']].values, dtype=torch.float32)\n",
    "            exp = ExperimentAnalytes(k0 = dataframe.k0.values, S = dataframe.S.values, h=0.001, run_time=10.0)\n",
    "\n",
    "        else:\n",
    "            # Choose a random set\n",
    "            set_index = randint(0, num_exps - 1) \n",
    "            exp = exps[set_index]\n",
    "            input_data = torch.tensor(alists[set_index][['S', 'lnk0']].values, dtype=torch.float32)\n",
    "        \n",
    "        expected_loss = 10\n",
    "        for phi in np.linspace(0, 1, 100):\n",
    "            exp.reset()\n",
    "            exp.step(phi, 1.)\n",
    "            if exp.loss() < expected_loss:\n",
    "                phi_iso = phi\n",
    "                expected_loss = exp.loss()    \n",
    "        \n",
    "        # compute distribution parameters (Normal)\n",
    "        mu, sigma = policy.forward(input_data, torch.tensor([[phi_iso]]))\n",
    "\n",
    "        # Sample some values from the actions distributions\n",
    "        programs = sample(mu, sigma, sample_size)\n",
    "        \n",
    "        # Fit the sampled data to the constraint [0,1]\n",
    "        constr_programs = programs.clone()\n",
    "        constr_programs[constr_programs > 1] = 1\n",
    "        constr_programs[constr_programs < 0] = 0\n",
    "        \n",
    "        J = 0\n",
    "        expected_loss = 0\n",
    "        for i in range(sample_size):\n",
    "            exp.reset()            \n",
    "            exp.run_all(constr_programs[i].data.numpy(), delta_taus)\n",
    "\n",
    "            error = exp.loss(weights)\n",
    "            expected_loss += error\n",
    "            log_prob_ = log_prob(programs[i], mu, sigma)\n",
    "            J += (error - baseline) * log_prob_ - beta * torch.exp(log_prob_) * log_prob_\n",
    "        \n",
    "        losses.append(expected_loss/sample_size)\n",
    "        perfect_loss.append(exp.perfect_loss(weights))\n",
    "        if (n + 1) % print_every == 0:\n",
    "            print(f\"Loss: {losses[-1]}, epoch: {n+1}/{num_episodes}\")\n",
    "\n",
    "        J_batch += J/sample_size\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            J_batch /= batch_size\n",
    "            optimizer.zero_grad()\n",
    "            # Calculate gradients\n",
    "            J_batch.backward()\n",
    "\n",
    "            if max_norm:\n",
    "                torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm)\n",
    "\n",
    "            # Apply gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # learning rate decay\n",
    "            scheduler.step()\n",
    "\n",
    "            J_batch = 0\n",
    "        \n",
    "    return np.array(losses), np.array(perfect_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = [.25, .25, 10]\n",
    "L5_b1_iso = []\n",
    "PL5_b1_iso = []\n",
    "for i in range(5):\n",
    "    pol = PolicyGeneralISO(\n",
    "                phi = nn.Sequential(\n",
    "                    PermEqui2_max(2, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    PermEqui2_max(5, 5),\n",
    "                    nn.ELU(inplace=True),\n",
    "                ),\n",
    "                rho = nn.Sequential(\n",
    "                    nn.Linear(6, 6),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    nn.Linear(6, 6),\n",
    "                    nn.ELU(inplace=True),\n",
    "                    Rho(n_steps=len(taus), hidden=6, in_dim=6, sigma_max=.3, sigma_min=.01),\n",
    "                )\n",
    "            )\n",
    "    l, p = reinforce_gen_iso(\n",
    "        alists = alists, \n",
    "        policy = pol, \n",
    "        delta_taus = taus, \n",
    "        num_episodes = 20_000, \n",
    "        sample_size = 10,\n",
    "        batch_size = 1, \n",
    "        lr = .05, \n",
    "        optim = lambda a, b: torch.optim.SGD(a, b),\n",
    "        lr_decay_factor = 0.75,\n",
    "        lr_milestones = 5000,\n",
    "        print_every = 5000,\n",
    "        baseline = .55,\n",
    "        max_norm = 1.7,\n",
    "        max_rand_analytes = 30,\n",
    "        min_rand_analytes = 10,\n",
    "        rand_prob = 0.7\n",
    "    )\n",
    "    L5_b1_iso.append(l)\n",
    "    PL5_b1_iso.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot((np.array(L5_b1) - np.array(PL5_b1)).reshape((10, 200, 100)).mean(2).T)\n",
    "plt.ylim((0.3, 1))\n",
    "plt.title(\"Simple batch one small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#plt.plot((np.array(L5_b1_iso) - np.array(PL5_b1_iso)).mean(0).reshape(-1, 100).mean(1), label = \"ISO\")\n",
    "plt.plot((np.array(L5_b1) - np.array(PL5_b1)).mean(0).reshape(-1, 100).mean(1), label = \"Small NN\")\n",
    "#plt.plot((np.array(L5_b1_big) - np.array(PL5_b1_big)).mean(0).reshape(-1, 100).mean(1), label = \"Big NN\")\n",
    "plt.title(\"Small rho NN vs Big rho NN\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(L5_b1) - np.array(PL5_b1)).mean(0).reshape(-1, 100).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
