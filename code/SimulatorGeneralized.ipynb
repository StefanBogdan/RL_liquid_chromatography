{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from chromatography import *\n",
    "from separation_utility import *\n",
    "from torch import optim, tensor\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alists = []\n",
    "alists.append(pd.read_csv('../data/GilarSample.csv'))\n",
    "alists.append(pd.read_csv('../data/Alizarin.csv'))\n",
    "alists.append(pd.read_csv('../data/Peterpeptides.csv'))\n",
    "alists.append(pd.read_csv('../data/Roca.csv'))\n",
    "alists.append(pd.read_csv('../data/Peter32.csv'))\n",
    "alists.append(pd.read_csv('../data/Eosin.csv'))\n",
    "alists.append(pd.read_csv('../data/Controlmix2.csv'))\n",
    "alists.append(pd.read_csv('../data/Gooding.csv'))\n",
    "# GilarSample - 8 analytes\n",
    "# Peterpeptides - 32 analytes\n",
    "# Roca - 14 analytes\n",
    "# Peter32 - 32 analytes\n",
    "# Eosin - 20 analytes\n",
    "# Alizarin - 16 analytes\n",
    "# Controlmix2 - 17 analytes\n",
    "# Gooding - 872 analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_field(exp, taus, N = 200):\n",
    "    phis = np.linspace(0, 1, N)\n",
    "    losses = np.zeros((N, N))\n",
    "    j = 0\n",
    "    for phi1 in phis:\n",
    "        i = 0\n",
    "        for phi2 in phis:\n",
    "            exp.reset()\n",
    "            exp.run_all([phi1, phi2], taus)\n",
    "            losses[i, j] = exp.loss()\n",
    "            i += 1\n",
    "        j += 1\n",
    "    X, Y = np.meshgrid(phis, phis)\n",
    "    \n",
    "    return X, Y, losses\n",
    "\n",
    "def average_over_equal_intervals(arr, interval):\n",
    "    return np.mean(arr.reshape(-1, interval), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: Performance vs n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 7\n",
    "M = 15\n",
    "\n",
    "losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "losses_100 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "for n in range(0, N):\n",
    "    print(n)\n",
    "    delta_taus = np.ones(n + 1) * 1/(n + 1)\n",
    "    \n",
    "    for i in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {i}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        pol_100 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "        loss_100, _ = reinforce_gen(\n",
    "            alists = [all_analytes], \n",
    "            test_alist = None,\n",
    "            policy = pol_100, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        losses_50_50[n,i] = loss\n",
    "        test_losses_50_50[n,i] = loss_test\n",
    "        losses_100[n,i] = loss_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez_compressed(\"../results/general_perf_vs_n_steps\", losses_50_50=losses_50_50, test_losses_50_50=test_losses_50_50, losses_100=losses_100)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_losses_50\", losses_50_50=losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_test_losses_50_50\", test_losses_50_50=test_losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_n_steps_losses_100\", losses_100=losses_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs number of analytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 5\n",
    "M = 30\n",
    "\n",
    "losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_50_50 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "losses_100 = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for n in range(N):\n",
    "    for i in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {i}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        pol_100 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus,\n",
    "            min_rand_analytes = 8 * (n + 1),\n",
    "            max_rand_analytes = 8 * (n + 1),\n",
    "            **kwargs\n",
    "        )\n",
    "        loss_100, _ = reinforce_gen(\n",
    "            alists = [all_analytes], \n",
    "            test_alist = None,\n",
    "            policy = pol_100, \n",
    "            delta_taus = delta_taus,\n",
    "            min_rand_analytes = 8 * (n + 1),\n",
    "            max_rand_analytes = 8 * (n + 1),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_50_50[n,i] = loss\n",
    "        test_losses_50_50[n,i] = loss_test\n",
    "        losses_100[n,i] = loss_100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_losses_50\", losses_50_50=losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_test_losses_50_50\", test_losses_50_50=test_losses_50_50)\n",
    "np.savez_compressed(\"../results/general_perf_vs_nr_analytes_losses_100\", losses_100=losses_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs architecture DeepSet(phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "1\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefan/Thesis/code/chromatography.py:251: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return delta_tau_phi * (1 + self.k(phi)) / self.k(phi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=10, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=20, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "3\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "4\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=10, bias=False)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "5\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=20, bias=False)\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (3): ReLU()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "6\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): Tanh()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): Tanh()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=10, bias=False)\n",
      "    )\n",
      "    (1): Tanh()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (3): Tanh()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (Lambda): Linear(in_features=10, out_features=10, bias=False)\n",
      "    )\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "8\n",
      "  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=20, bias=False)\n",
      "    )\n",
      "    (1): Tanh()\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (3): Tanh()\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (Lambda): Linear(in_features=20, out_features=20, bias=False)\n",
      "    )\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): Rho(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "activations = [nn.ELU, nn.ReLU, nn.Tanh]\n",
    "width = [5, 10, 20]\n",
    "kwargs = {\n",
    "    'num_episodes' : 1, #25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 9\n",
    "M = 20\n",
    "\n",
    "losses_deep_set = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_deep_set = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for i in range(N):\n",
    "    print(f\"{i}\")\n",
    "    for m in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {m}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                PermEqui2_max(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                PermEqui2_max(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(width[i % 3], 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                nn.Linear(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                Rho(n_steps=len(delta_taus), hidden=5, in_dim=5, sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_deep_set[i, m] = loss\n",
    "        test_losses_deep_set[i, m] = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_deep_set_arch_loss_50_50\", losses_50_50=losses_deep_set)\n",
    "np.savez_compressed(\"../results/general_perf_deep_set_arch_test_losses_50_50\", test_losses_50_50=test_losses_deep_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance vs architecture Program(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoReLU(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = F.relu(self.fc_mu_1(x))\n",
    "        sigma = F.relu(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoELU(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = F.elu(self.fc_mu_1(x))\n",
    "        sigma = F.elu(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhoTanh(nn.Module):\n",
    "    def __init__(self, \n",
    "            n_steps: int, \n",
    "            hidden: int, \n",
    "            in_dim: int = 2, \n",
    "            sigma_max: float = .3, \n",
    "            sigma_min: float = .1\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor for PolicyTime torch Module.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_steps: int\n",
    "            Number of steps for piece-wise constant solvent strength program.\n",
    "        hidden: int\n",
    "            Number of nodes for the hidden layers\n",
    "        in_dim: int\n",
    "            length of the encoded analyte set (embedding), it is the input \n",
    "            to this network.\n",
    "        sigma_min: float\n",
    "            Minimal standard deviation of the solvent strength search space.\n",
    "            Default value .0. (max value < 1.0)\n",
    "        sigma_max: float\n",
    "            Maximal standard deviation of the solvent strength search space.\n",
    "            Default value .2. (max value is 1.0)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_steps = n_steps\n",
    "        self.hidden = hidden\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.fc_mu_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_mu_2 = nn.Linear(hidden, n_steps)\n",
    "        self.fc_sig_1 = nn.Linear(in_dim, hidden)\n",
    "        self.fc_sig_2 = nn.Linear(hidden, n_steps)\n",
    "          \n",
    "    def forward(self, x):\n",
    "        mu = torch.tanh(self.fc_mu_1(x))\n",
    "        sigma = torch.tanh(self.fc_sig_1(x))\n",
    "        \n",
    "        mu = self.sig(self.fc_mu_2(mu)).squeeze(0)\n",
    "        # limit sigma to be in range (sigma_min; sigma_max)\n",
    "        sigma = self.sig(self.fc_sig_2(sigma)).squeeze(0) * (self.sigma_max - self.sigma_min) + self.sigma_min\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): RhoELU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "1\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): RhoELU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (1): ELU(alpha=1.0)\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): ELU(alpha=1.0)\n",
      "    (4): RhoELU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "3\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): RhoReLU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "4\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): RhoReLU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "5\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): RhoReLU(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "6\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): RhoTanh(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=5, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "7\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): RhoTanh(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=10, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "8\n",
      "  0\n",
      "  1\n",
      "  2\n",
      "  3\n",
      "  4\n",
      "  5\n",
      "  6\n",
      "  7\n",
      "  8\n",
      "  9\n",
      "  10\n",
      "  11\n",
      "  12\n",
      "  13\n",
      "  14\n",
      "  15\n",
      "  16\n",
      "  17\n",
      "  18\n",
      "  19\n",
      "PolicyGeneral(\n",
      "  (phi): Sequential(\n",
      "    (0): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=2, out_features=5, bias=False)\n",
      "    )\n",
      "    (1): ELU(alpha=1.0, inplace=True)\n",
      "    (2): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (3): ELU(alpha=1.0, inplace=True)\n",
      "    (4): PermEqui2_max(\n",
      "      (Gamma): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (Lambda): Linear(in_features=5, out_features=5, bias=False)\n",
      "    )\n",
      "    (5): ELU(alpha=1.0, inplace=True)\n",
      "  )\n",
      "  (rho): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): RhoTanh(\n",
      "      (sig): Sigmoid()\n",
      "      (fc_mu_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_mu_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "      (fc_sig_1): Linear(in_features=20, out_features=20, bias=True)\n",
      "      (fc_sig_2): Linear(in_features=20, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "all_analytes = pd.concat(alists, sort=True).reset_index()[['k0', 'S', 'lnk0']]\n",
    "activations = [nn.ELU, nn.ReLU, nn.Tanh]\n",
    "width = [5, 10, 20]\n",
    "Rhos = [RhoELU, RhoReLU, RhoTanh]\n",
    "kwargs = {\n",
    "    'num_episodes' : 25_000, \n",
    "    'sample_size' : 10,\n",
    "    'batch_size' : 1, \n",
    "    'lr' : .05, \n",
    "    'optim' : torch.optim.SGD,\n",
    "    'lr_decay_factor' : 0.75,\n",
    "    'lr_milestones' : 5000,\n",
    "    'print_every' : 25_001,\n",
    "    'baseline' : .55,\n",
    "    'max_norm' : 1.5,\n",
    "    'max_rand_analytes' : 40,\n",
    "    'min_rand_analytes' : 8,\n",
    "    'rand_prob' : 1.,\n",
    "    'h' : 0.001,\n",
    "    'run_time' : 1.\n",
    "}\n",
    "N = 9\n",
    "M = 20\n",
    "\n",
    "losses_rho = np.zeros((N, M, kwargs['num_episodes']))\n",
    "test_losses_rho = np.zeros((N, M, kwargs['num_episodes']))\n",
    "\n",
    "delta_taus = np.ones(10) * 1/(10)\n",
    "for i in range(N):\n",
    "    print(f\"{i}\")\n",
    "    for m in range(M):\n",
    "        alist_train = all_analytes.sample(frac=0.5)\n",
    "        alist_test = all_analytes.loc[lambda a: ~a.index.isin(alist_train.index.values)]\n",
    "        print(f\"  {m}\")\n",
    "        #Policies\n",
    "        pol_50_50 = PolicyGeneral(\n",
    "            phi = nn.Sequential(\n",
    "                PermEqui2_max(2, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "                PermEqui2_max(5, 5),\n",
    "                nn.ELU(inplace=True),\n",
    "            ),\n",
    "            rho = nn.Sequential(\n",
    "                nn.Linear(5, width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                nn.Linear(width[i % 3], width[i % 3]),\n",
    "                activations[i // 3](),\n",
    "                Rhos[i // 3](n_steps=len(delta_taus), hidden=width[i % 3], in_dim=width[i % 3], sigma_max=.3, sigma_min=.01),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Run Exp\n",
    "        loss, loss_test = reinforce_gen(\n",
    "            alists = [alist_train], \n",
    "            test_alist = alist_test,\n",
    "            policy = pol_50_50, \n",
    "            delta_taus = delta_taus, \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        losses_rho[i, m] = loss\n",
    "        test_losses_rho[i, m] = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"../results/general_perf_rho_arch_loss_50_50\", losses_50_50=losses_rho)\n",
    "np.savez_compressed(\"../results/general_perf_rho_arch_test_losses_50_50\", test_losses_50_50=test_losses_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_50_50 = np.load('../results/general_perf_vs_n_steps_losses_50.npz')['losses_50_50']\n",
    "test_losses_50_50 = np.load('../results/general_perf_vs_n_steps_test_losses_50_50.npz')['test_losses_50_50']\n",
    "losses_100 = np.load('../results/general_perf_vs_n_steps_losses_100.npz')['losses_100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_100  = []\n",
    "for i in range(10):\n",
    "    data_100.append([])\n",
    "    for j in range(20):\n",
    "        data_100[i].append(average_over_equal_intervals(losses_100[i,j], 500))\n",
    "data_100 = np.array(data_100)\n",
    "\n",
    "data_50_50  = []\n",
    "for i in range(10):\n",
    "    data_50_50.append([])\n",
    "    for j in range(20):\n",
    "        data_50_50[i].append(average_over_equal_intervals(losses_50_50[i,j], 500))\n",
    "data_50_50 = np.array(data_50_50)\n",
    "\n",
    "data_50_50_t  = []\n",
    "for i in range(10):\n",
    "    data_50_50_t.append([])\n",
    "    for j in range(20):\n",
    "        data_50_50_t[i].append(average_over_equal_intervals(test_losses_50_50[i,j], 500))\n",
    "data_50_50_t = np.array(data_50_50_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "gs = gridspec.GridSpec(1, 2, width_ratios=[4, 1]) \n",
    "\n",
    "func = np.mean\n",
    "D = data_100\n",
    "\n",
    "plt.subplot(gs[0])\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "for i in range(10):\n",
    "\n",
    "    plt.plot(np.linspace(0, 25000, 50),func(D, 1)[i], label=\"nr_steps: \"+str(i+1), linewidth=2.)\n",
    "    #plt.plot(np.linspace(0, 25000, 50),data_50_50[i], label=\"Train\"+str(i+1))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of episodes\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.subplot(gs[1])\n",
    "#plt.rcParams['figure.figsize'] = (5, 5)\n",
    "for i in range(10):\n",
    "\n",
    "    plt.plot(np.linspace(10000, 25000, 10), func(D, 1)[i][40:], label=\"nr_steps: \"+str(i+1), linewidth=2.)\n",
    "    #plt.plot(np.linspace(0, 25000, 50),data_50_50[i], label=\"Train\"+str(i+1))\n",
    "#plt.legend()\n",
    "plt.xlabel(\"Number of episodes\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.suptitle(\"Train Loss(no test set). Each nr_steps is the mean of 20 runs.\", fontsize=14)\n",
    "plt.savefig(\"train_100_loss_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 25000, 50),data_100[9].T, color=\"r\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_100[4].T, color=\"b\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_100[0].T, color=\"g\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_100[0,0], color=\"g\", label=\"nr_steps: 1\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_100[4,0], color=\"b\", label=\"nr_steps: 5\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_100[9,0], color=\"r\", label=\"nr_steps: 10\")\n",
    "plt.xlabel(\"Number of episodes\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim((0, 1.8))\n",
    "plt.legend()\n",
    "plt.title(\"Loss(no test set) for the 20 runs for each nr_steps.\", fontsize=14)\n",
    "plt.savefig(\"losses_20_data_100.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[9].T, color=\"r\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[4].T, color=\"b\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[0].T, color=\"g\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[0,0], color=\"g\", label=\"nr_steps: 1\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[4,0], color=\"b\", label=\"nr_steps: 5\")\n",
    "plt.plot(np.linspace(0, 25000, 50),data_50_50[9,0], color=\"r\", label=\"nr_steps: 10\")\n",
    "plt.xlabel(\"Number of episodes\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim((0, 1.8))\n",
    "plt.legend()\n",
    "plt.title(\"Loss(50/50 train/test split) for the 20 runs for each nr_steps.\", fontsize=14)\n",
    "plt.savefig(\"losses_20_data_50_50.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
